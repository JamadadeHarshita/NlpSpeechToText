{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamadadeHarshita/NlpSpeechToText/blob/main/Mini_Project_Harshita.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Speech Recognition and NLP Analysis of Academic Lectures**\n"
      ],
      "metadata": {
        "id": "Hso5Ygk7G94w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project transcribes spoken lectures using speech-to-text models and applies NLP techniques for analysis, making academic content easier to understand."
      ],
      "metadata": {
        "id": "3RrL57ToJI47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**USE CASE** : This project is for students, educators, and researchers who need to quickly review and understand academic lectures. By converting speech into text and summarizing key points, it makes complex content easier to digest."
      ],
      "metadata": {
        "id": "J3sYU1JIM2QH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Libraries"
      ],
      "metadata": {
        "id": "8XgFIbzkLljr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkGE0avnNHfM",
        "outputId": "f210e89c-43c6-4c7f-a2eb-cc80a0f1695e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp\n",
        "!apt-get install ffmpeg\n",
        "!pip install pydub\n",
        "!pip install ffmpeg\n",
        "!pip install SpeechRecognition\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!apt-get install ffmpeg\n",
        "!pip install gensim\n",
        "!pip install keybert\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GIbBAFFKPd7V",
        "outputId": "d568fa88-d44e-4677-f196-ffa3ca7d1afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.11.4-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/172.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.11.4-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.11.4\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=473d6423a4ab24132012e7dfb78d46b1f5ba0e90202b1e867ff7469b410a2eaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
            "Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.11.0\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-gzwqkd4v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-gzwqkd4v\n",
            "  Resolved https://github.com/openai/whisper.git to commit 271445b2f24f00f8175c4fb7ae91876f7451dfc1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803558 sha256=c272722656df18deab50b42ca1dba9f37e66f7736a41df7da7cb735872b25b15\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pyepj432/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Collecting keybert\n",
            "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.5.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (3.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (4.12.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.8.30)\n",
            "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: keybert\n",
            "Successfully installed keybert-0.8.5\n",
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h_X4itMKJlKI",
        "outputId": "15c3e3ce-ffb8-4ca1-f11a-0b5f890c5965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# Audio Download and File Handling\n",
        "import yt_dlp\n",
        "import os\n",
        "import soundfile as sf\n",
        "\n",
        "# Speech Recognition and Whisper Model\n",
        "import speech_recognition as sr\n",
        "import whisper\n",
        "\n",
        "# NLP and Text Processing\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import ngrams\n",
        "nltk.download(\"punkt\")\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Transformers for NLP Models\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "     BartTokenizer,\n",
        "    BartForConditionalGeneration\n",
        ")\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Visualization Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keybert import KeyBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Collection**\n",
        "Audio Source: The audio data is collected using the **yt-dlp** package\n",
        "\n",
        "\n",
        "\n",
        "*   With the yt_dl package we can download audio and video files from a URL and convert to a .wav file\n",
        "*   Youtube_dl supports an extensive collection (~ 240) of websites\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p81V8fCBVuDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_audio_from_youtube(url, output_file='audio_yt'):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'extractaudio': True,  # Only download audio\n",
        "        'audioformat': 'wav',  # Convert to wav format\n",
        "        'outtmpl': output_file,  # Output file name\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "    print(f\"Downloaded and saved as {output_file}\")\n",
        "\n",
        "# Get user input for the URL\n",
        "url = input(\"Please enter a URL from which you want to download a video: \")\n",
        "download_audio_from_youtube(url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECTj5geyQuEO",
        "outputId": "520fdba0-2957-43b8-9e8d-e502ff877481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter a URL from which you want to download a video: https://youtu.be/9vM4p9NN0Ts?si=QT3I2az_6l1b1UkK\n",
            "[youtube] Extracting URL: https://youtu.be/9vM4p9NN0Ts?si=QT3I2az_6l1b1UkK\n",
            "[youtube] 9vM4p9NN0Ts: Downloading webpage\n",
            "[youtube] 9vM4p9NN0Ts: Downloading ios player API JSON\n",
            "[youtube] 9vM4p9NN0Ts: Downloading mweb player API JSON\n",
            "[youtube] 9vM4p9NN0Ts: Downloading m3u8 information\n",
            "[info] 9vM4p9NN0Ts: Downloading 1 format(s): 251\n",
            "[download] Destination: audio_yt\n",
            "[download] 100% of   75.27MiB in 00:00:01 at 41.53MiB/s  \n",
            "[ExtractAudio] Destination: audio_yt.wav\n",
            "Deleting original file audio_yt (pass -k to keep)\n",
            "Downloaded and saved as audio_yt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It prompts the user to input a URL. For this project, I provided https://www.youtube.com/watch?v=9vM4p9NN0Ts, which is a Stanford lecture about Large Language Models (LLMs) . The audio is then converted into a .wav format for further processing."
      ],
      "metadata": {
        "id": "2xWjYmz0YR3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/audio_yt.wav\"\n",
        "f = sf.SoundFile(file_path)\n",
        "\n",
        "# Calculate the video length in seconds\n",
        "video_length = int(len(f) / f.samplerate) + (len(f) % f.samplerate > 0)\n",
        "print(f\"Video Length: {video_length} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ0zOAV-RuMb",
        "outputId": "7ad0d4c2-bb68-479a-d9eb-d1096165766b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Length: 6271 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Speech Recognition**\n",
        "**Transcription Method**: For transcribing the audio, I used OpenAI’s **Whisper**, Whisper is trained on a large and diverse dataset, making it effective at transcribing speech across various languages and audio qualities."
      ],
      "metadata": {
        "id": "l2JviNZLZglp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bf5hz4KuUiMN",
        "outputId": "2aa514e2-6239-47f4-9dd5-d02b2a9c9039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 96.3MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the \"base\" model of Whisper because The \"base\" model is smaller and faster compared to larger models, making it suitable for this project where quick transcription is needed."
      ],
      "metadata": {
        "id": "P-7gXSc6a-_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio_in_chunks(file_path):\n",
        "    # Read the audio file\n",
        "    data, samplerate = sf.read(file_path)\n",
        "    audio_length = int(len(data) / samplerate)\n",
        "\n",
        "    # Set the chunk duration (in seconds)\n",
        "    chunk_duration = 60\n",
        "    number_of_chunks = int(audio_length / chunk_duration) + (audio_length % chunk_duration > 0)\n",
        "\n",
        "    print(f\"Total audio length: {audio_length} seconds\")\n",
        "    print(f\"Number of chunks: {number_of_chunks}\")\n",
        "\n",
        "    complete_transcription = \"\"\n",
        "\n",
        "    # Loop through the audio file in chunks\n",
        "    for i in range(number_of_chunks):\n",
        "        start = i * chunk_duration\n",
        "        end = (i + 1) * chunk_duration\n",
        "        if end > audio_length:\n",
        "            end = audio_length\n",
        "\n",
        "        # Extract the chunk\n",
        "        start_frame = int(start * samplerate)\n",
        "        end_frame = int(end * samplerate)\n",
        "        chunk = data[start_frame:end_frame]\n",
        "\n",
        "        # Save the chunk as a temporary file\n",
        "        temp_filename = \"temp_chunk.wav\"\n",
        "        sf.write(temp_filename, chunk, samplerate)\n",
        "\n",
        "        # Transcribe the chunk using Whisper\n",
        "        result = model.transcribe(temp_filename)\n",
        "        complete_transcription += result[\"text\"] + \" \"\n",
        "\n",
        "        print(f\"Transcribed chunk from {start} to {end} seconds.\")\n",
        "\n",
        "    return complete_transcription\n"
      ],
      "metadata": {
        "id": "e_VZZntnU-9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transcribing Audio in Chunks:\n",
        " For long audio files, transcribing the entire content at once can be inefficient and may cause memory issues. To handle this,Implementation of a function that breaks the audio into smaller chunks, transcribes each chunk using the Whisper model, and then combines the results into a complete transcription."
      ],
      "metadata": {
        "id": "xa1RdeIQbuFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = transcribe_audio_in_chunks(file_path)\n",
        "print(\"Complete Transcription: \", transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBVMjOaoVCIL",
        "outputId": "a520993e-c146-4635-873a-4624b526b795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total audio length: 6270 seconds\n",
            "Number of chunks: 105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 0 to 60 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 60 to 120 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 120 to 180 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 180 to 240 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 240 to 300 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 300 to 360 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 360 to 420 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 420 to 480 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 480 to 540 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 540 to 600 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 600 to 660 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 660 to 720 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 720 to 780 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 780 to 840 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 840 to 900 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 900 to 960 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 960 to 1020 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1020 to 1080 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1080 to 1140 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1140 to 1200 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1200 to 1260 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1260 to 1320 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1320 to 1380 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1380 to 1440 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1440 to 1500 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1500 to 1560 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1560 to 1620 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1620 to 1680 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1680 to 1740 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1740 to 1800 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1800 to 1860 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1860 to 1920 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1920 to 1980 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 1980 to 2040 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2040 to 2100 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2100 to 2160 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2160 to 2220 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2220 to 2280 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2280 to 2340 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2340 to 2400 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2400 to 2460 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2460 to 2520 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2520 to 2580 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2580 to 2640 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2640 to 2700 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2700 to 2760 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2760 to 2820 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2820 to 2880 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2880 to 2940 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 2940 to 3000 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3000 to 3060 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3060 to 3120 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3120 to 3180 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3180 to 3240 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3240 to 3300 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3300 to 3360 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3360 to 3420 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3420 to 3480 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3480 to 3540 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3540 to 3600 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3600 to 3660 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3660 to 3720 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3720 to 3780 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3780 to 3840 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3840 to 3900 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3900 to 3960 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 3960 to 4020 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4020 to 4080 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4080 to 4140 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4140 to 4200 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4200 to 4260 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4260 to 4320 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4320 to 4380 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4380 to 4440 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4440 to 4500 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4500 to 4560 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4560 to 4620 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4620 to 4680 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4680 to 4740 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4740 to 4800 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4800 to 4860 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4860 to 4920 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4920 to 4980 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 4980 to 5040 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5040 to 5100 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5100 to 5160 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5160 to 5220 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5220 to 5280 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5280 to 5340 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5340 to 5400 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5400 to 5460 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5460 to 5520 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5520 to 5580 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5580 to 5640 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5640 to 5700 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5700 to 5760 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5760 to 5820 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5820 to 5880 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5880 to 5940 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 5940 to 6000 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 6000 to 6060 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 6060 to 6120 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 6120 to 6180 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 6180 to 6240 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed chunk from 6240 to 6270 seconds.\n",
            "Complete Transcription:   So let's get started. So I'll be talking about building LLMS today. So I think a lot of you have heard of LLMS before. But just as a quick recap, LLMS, standing for large language models are basically all the chat bots that you've been hearing about recently. So Chad GPT from OpenAI, Cloud, from UnTropic, Gemini, and Lama and other type of models like this. And today we'll be talking about how do they actually work. So it's going to be an overview, because it's only one lecture, and it's hard to compress everything. But hopefully, I'll touch a little bit about all the components that are needed to train some of these LLMS. Also, if you have questions, please interrupt me and ask. If you have a question, most likely, other people in the room or on Zoom have the same question. So please ask. Great. So what matters when training LLMS?  So there are a few key components that matter. One is the architecture. So as you probably all know, LMs are neural networks. And when you think about neural networks, you have to think about what architecture you're using. And another component which is really important is the training loss and the training algorithm. So how you actually train these models, then it's data. So what do you train these models on? The evaluation, which is how do you know whether you're actually making progress towards the goal of LLMs? And then the system component. So that is like how do you actually make these models run on modern hardware, which is really important because these models are really large. So now more than ever, systems are actually really an important topic for LLMs. So those five components, you probably all know that LLMs, and if you don't know, LMs are all based on transformers, or at least some version of transformers. I'm actually not going to talk about the architecture.  today, one because I gave us here a lecture on transformers a few weeks ago, and two because you can find so much information online on transformers. But I think it's, there's much less information about the other four topics. I really want to talk about those. Another thing to say is that most of academia actually focuses on architecture and training algorithm and losses. As academics, and I've done that for a lot, big part of my career is simply, we like thinking that this is like we make new architectures, new models, and it seems like it's very important. But in reality, honestly, what matters in practice is mostly the three other topics. So data of evaluation and systems, which is one of most of industry actually focuses on. So that's also one of the reasons why I don't want to talk too much about architecture, because really the rest is super important. Great. So overview of the lecture, I'll be talking about pre-training. So pre-training, you probably...  heard that word, this is the general word, this is kind of the classical language modeling paradigm, where you basically train a language model to essentially model all of internet. And then there's a post training, which is a more recent paradigm, which is taking these large language models and making them essentially AI assistants. So this is more of a recent trend since ChatGPT. So if you ever heard of GPT-3 or GPT-2, that's really pre-training land. If you heard of ChatGPT, which you probably have, this is really post training land. So we talk about both, but I'll start with pre-training. And specifically, I'll talk about what is the task of pre-training LMS and what is the laws that people will actually use. So language modeling, this is a quick recap. Language models at a high level are simply models of probability distribution over sequences of tokens or words. So it's basically some model of P of X1 to Excel, where X1 is basically word wanted.  Excel is the last word in the sequence or in the sentence. So very concretely, if you have a sentence like the mouse, eight of the cheese, what the language model gives you is simply a probability of this sentence being uttered by a human or being found online. So if you have another sentence like the mouse, eight cheese, here there's grammatical mistakes. So the model should have some syntactic knowledge. So it should know that this has less likelihood of appearing online. If you have another sentence like the cheese, eight, the mouse, then the model should hopefully know about the fact that usually cheese don't eat mouse. So there's some semantic knowledge, and this is less likely to be the first sentence. So this is basically at a high level what language models are. One word that you've probably have been hearing a lot in the news are generative models. So this is just something that can generate models, that can generate sentences or can generate some data. The reason.  So what we know why we say language models are genitive models is that once you have a model of a distribution, you can simply sample from this model and then we can generate data. So you can generate sentences using a language model. So the type of models that people are all currently using are what we call autoregressive language models. And the key idea of autoregressive language models is that you take this distribution over words and you basically decompose it into the distribution of the first word, multiply it by the distribution of the likelihood of the second word, given the first word, multiply it by P of the third word, given the first two words. So there's no approximation here. This is just a chain rule of probability, which you hopefully all know about. Really no approximation. This is just one way of modeling a distribution. So slightly more concisely, you can write it as a product of P's of the next word, given everything which happened in the past, so of the context.  So this is what we call autoregressive language models. Again, this is really not the only way of modeling distribution. This is just one way. It has some benefits and some downsides. One downside of autoregressive language models is that when you actually sample from this autoregressive language model, you basically have a full loop, which generates the next word, then conditions on that next word, and then regenerate in other words. So basically, if you have a longer sentence that you want to generate, it takes more time to generate it. So there are some downsides of this current paradigm, but that's what we currently have. So I'm going to talk about this one. Great. So autoregressive language models. At a high level, what the task of autoregressive language model is is simply predicting the next word, as I just said. So if you have a sentence like she likely prefers one potential next word, it might be dogs. And the way we do it is that we first tokenize. So you take these words or sub words. You tokenize them. And then you give an ID.  for each token. So here I have one, two, three. Then you pass it through this black box, as I already said. We're not going to talk about the architecture. You just pass it through a model. And you then get a distribution, a probability distribution, over the next word, or over the next token. And then you sample from this distribution, you get a new token. And then you detokenize. So you get a new ID. You get detokenize. And that's how you basically sample from a language model. One thing which is important to note is that the last two steps are actually only needed during inference. When you do training, you just need to predict the most likely token. And you can just compare to the real token, which happened in practice. And then you basically change the weights of your model to increase the probability of generating that token. Great. So our progressive neural language models. So to be slightly more specific, still, without talking about the architecture, the first thing we do is that we have all of these. Yes.  So here, predicting the probability of the next token. So this may be that your final output vector has to be the same dimensionality as the number of tokens that you have. Yes. How do you deal with like, if you have more to increase adding more tokens to your tokens? Is it a private sample? Yeah. So we're going to talk about tokenization actually later. So you will get some sense of this. You basically can deal with adding new tokens. I'm kind of exaggerating. There are methods for doing it, but essentially people don't do it. So it's really important to think about how you tokenize your text, and that's why we'll talk about that later. But it's a very good point to notice that you basically the vocabulary size to the number of tokens that you have is essentially the output of your language model. So it's actually pretty large. OK. So autoregressive new language models. First thing you do is that you take every word or every token. You embed them. So you get some vector representation for each of these tokens. You pass them through some neural network.  we said it's the transformer, then you get a representation for all the words in the context. So it's basically representation of the entire sentence. You pass it through a linear layer, as you just said, to basically map it to the number so that the output, the number of outputs is the number of tokens. You then pass it through some softmax and you basically get probability distribution over the next words, given every word in the context. And the last that you use is basically, it's essentially a task of classifying the next token. So it's a very simple kind of machine learning task. So you use the cross-central P loss where you basically look at the actual target that happened, which is a target distribution, which is a one-hot encoding, which here in this case says, I saw the real one that happened is cat. So one-hot distribution over cat. And here this is the actual, do you see my mouse? Oh yeah, this is the distribution that you generate.  generated and we see you do cross entropy which really just increases the probability of generating cat and decreases all the The probability of generating all the other tokens one thing to notice is that as you all know again This is just equivalent to maximizing the text log like the text log likelihood because you can just rewrite the Max over the probability of This autogressive language modeling task as just being this minimum over I just added the log here and Minus which is just the minimum of the loss which is the cross entropy loss so basically minimizing the loss is the same thing as Maximizing the likelihood of your text any question questions Okay tokenizer So this is one thing that people usually don't talk that much about tokenizers are extremely important So it's really important that you kind of understand at least what they do at a high level so why do we need tokenizers in the first place  First, it's more general than words. So one simple thing that you might think is, oh, we're just going to take every word that we will have, you just say every word is a token in its own. But then what happens is if there's a typo in your word, then you might not have any token associated with this word with a typo, and then you don't know how to actually pass this word with a typo into a large language model. So what do you do next? And also, even if you think about words, words is a very, like words are fine with Latin-based languages. But if you think about a language like Thai, you won't have a simple way of tokenizing by spaces because there are no spaces between words. So really tokens are much more general than words. First thing, the second thing that you might think is that you might tokenize every sentence character by character. You might say, A is one token, B is another token. That would actually work and probably very well. The issue is that then your sequence becomes super long. And as you probably remember from...  the lecture on transformers, the complexity grows quadratically with the length of sequences. So you really don't want to have a super long sequence. So tokenizers basically try to deal with those two problems and give common sub sequences a certain token. And usually how you should be thinking about is around an average of every token is around three, four letters. And there are many algorithms for tokenization. I'll just talk about one of them to give you a high level, which is what we call byte-paying coding, which is actually pretty common, one of the two most common tokenizers. And the way that you train a tokenizer is that first you start with a very large corpus of text. And here I'm really not talking about training a large language model yet. This is purely for the tokenization step. So this is my large corpus of text with these five words. And then you associate every character in this corpus of text, different token. So here I just split it up.  character with a different token and I just call it all of those tokens. And then what you do is that you go through your text and every time you see pairs of tokens that are very common, the most common pair of token, you just merge them. So here you see three times the tokens T and O next to each other. So you're just gonna say this is a new token and then you continue, you repeat that. So now you have T okay, talk, which happens three times, talk with an E that happens, sorry, two times, and token, which happens twice and an EX, which also happened twice. So this is that if you were to train a tokenizer on this corpus of text, which is very small, that's how you would finish with a token with a treat like a trained tokenizer. In reality, you do it on on much larger corpus of text. And this is the real tokenizer of actually I think this is GPT3 or CHGPD. And here you see how it would actually separate these  words. So basically you see the same thing as what we gave in the previous example. Token becomes its own token. So tokenizer is actually split up into two tokens. Token andizer. So yeah, that's all about tokenizers. Any question on that? Yeah. Yeah. Yeah. So actually there's a step before tokenizers, which is what we call pre tokenizers, which is exactly what you just said. So this is mostly in theory, there's no reason to deal with spaces and punctuation separately. You could just say every space gets its own token, every punctuation gets its own token, and you could just do all the merging. The problem is that so there's an efficiency question. Actually training these tokenizers takes a long time. So you're better because you have to consider every pair of token. So what you end up doing is saying if there's a space, this is very like pre tokenizers are very English specific. You say if there's a space, we're not going to start looking at  the token that came before and the token that came afterwards. So you're not merging in between spaces. But this is just like a computation optimization. You could theoretically just deal with it the same way as you do with any other character. Yeah. When you merge tokens to the top, the tokens that you merged are very at the same height as the smaller token. You actually keep the smaller tokens. I mean, in reality, it doesn't matter much because usually on large corpus of text, you will have actually everything. But you usually keep the small ones. And the reason why you want to do that is because if, in case there's a, as we said before, you have some grammatical mistakes or some typos, you still want to be able to represent these words by character. So yeah. Yes. Yes. Are the tokens unique? So I mean, say in this case, T-O-K-E-N, is there only one occurrence so that you need to need multiple occurrence so they can have it?  Take on different meetings, you see? Oh, I see what you would say. No, it's every token has its own unique ID. So this is a great question. For example, if you think about bank, which could be bank for money or bank like water, it will have the same token. But the model will learn, the transformer will learn that based on the words that are around it, it will should associate that. I'm saying I'm being very hindrower of you here, but associate that with a representation that is either more like the bank money side or the bank water side. But that's the transformer that does that. It's not a tokenizer. Yes? Yes, we mentioned during tokenization, too, there's smaller tokens. It's not that we're trying to say. Like, we just have it at the T, we keep the T, and then you don't need to tokenize out to the external icon out and tokenize it. So let's say maybe you didn't even tokenize it like in your data, you are trying to encode token. So how does the tokenizer know to code it with token or to react? Yes.  The great question, you basically, when you tokenize, so that's after training of the tokenizer, when you actually apply to tokenizer, you basically always choose the largest token that you can apply. So if you can do token, you will never do T, you will always do token. But there's actually, so people don't really talk that much about tokenizers, but there's a lot of computational benefits or computational tricks that you can do for making these things faster. So I really don't think we, and honestly, I think a lot of people think that we should just get away from tokenizers and just kind of tokenize character by character or bytes by bytes. But as I said right now, it's this issue of length. But maybe one day, like in five or 10 years, we'll have different architectures that don't scale credetically with the length of the sequence and maybe we'll move away from tokenizers. So are you sure with us the drawback? Why do you give people one and move away from the tokenizer? Oh, yeah. So think.  One good example is math. If you think about math, actually numbers right now are not tokenized. So for example, 327 might have its own token, which means that models, when they see numbers, they don't see them the same way as we do. And this is very annoying because the reason why we can kind of generalize with math is because we can deal with every letter separately and we can then do composition, where you know that basically if you add stuff, it's just the same thing as adding every one separately plus whatever the unit that you add. So they can do that. So then you have to do like special tokenization. And like one of the big changes that GPT forwarded is changed the way that they tokenize code. So for example, if you have code, you know you have often in Python these four spaces at the beginning, those were dealt with kind of strangely before. And as a result, the model couldn't really understand how to deal with code. So tokenization actually matters a lot.  Okay, so I'll move on right now, but we can come back later on tokenizers. Great. So we talked about the task, the last tokenizer. Let's talk a little bit about evaluation. So the way that LLMs are usually evaluated is what we call, is using what we call Poplexity. At a high level, it's basically just your validation loss. The slight difference with Poplexity is that we use something that is slightly more vulnerable, which is that we use the average per token loss, and then you exponentiate it. And the reason why you exponentiate it is because you want, I mean, the loss has a log inside, and you, like, one human's are actually pretty bad at thinking in log space, but two logs depend on the base of the log. While when you exponentiate, you basically have everything in the kind of the vocabulary size unit. And the average for token is just so that your Poplexity is independent of the length of your sequence. So Poplexity is just too to the power average of the loss of the sequence.  So, perplexity is between one and the length of the vocabulary of your tokenizer. One, it's simply, well, if you predict perfectly the thing which every word, then every word will have basically product of ones. So, the best perplexity you can have is one. If you really have no idea, you basically predict with one divided by size of vocabulary, and then you do simple math and you basically get perplexity of size of vocabulary. So, then tuition of perplexity is that it's basically the number of tokens that you're model is kind of hesitating between. So, if you're model is perfect, it doesn't hesitate, it no exactly the word. If it really has no idea, then it hesitates between all of the vocabulary. So, perplexity really improved. That's perplexity on a standard data set between 2017 and 2023. It went from a kind of 70 tokens to less than 10 tokens over these five six years. So, that means that the models were previously as dated between 70.  words every time it was generating a word and now it's as dating between like less than 10 words. So that's much better. But complexity is actually not used anymore in academic benchmarking. More sick is it depends on the tokenizer that you use. It depends on the actual data that people are evaluating on. But it's still very important for development of LLMs. So when you actually train your own LLM, people will still really look at the complexity. One common other way and now more common in academia of evaluating these LLMs is just by taking all the classical NLP benchmarks. And I'll give you a few examples later and just kind of aggregating everything. So collect as many automatically evaluable benchmarks and just evaluate across all of them. So one such or actually two such benchmarks of what we call Helm which is from Stanford. Another one is the hugging face open LLM lead award which are probably two most common ones right now.  So just to give you an idea in how they are all of these type of tasks, which are mostly things that can be easily evaluated like question answering. So think about many different question answering tasks. The benefit with question answering is that you usually know what is the real answer. So you can the way that you evaluate these models, I'll give you a concrete example in one second, is that you can just look at how likely the language model is to generate the real answer compared to some other answers. And that's essentially at a high level how you evaluate these models. So to give you a specific example, MMLU is probably the most common academic benchmark for LMS. And this is just a collection of many question and answers in all of those domains. For example, college, medicine, college physics, astronomy, and these type of topics. And the questions are things like, so this is an astronomy. What is true for type 1a supernova, then you give 4.  different potential answers and you just ask the model which one is more likely. So there are many different ways of doing it. Either you can look at the likelihood of generating all these answers or you can ask the model which one is the most likely. So there are different ways that you can prompt the model but at a high level you know which one is correct and there are three other mistakes. Yes. Creating is like unconstrained text that's not funny. Yeah. How do you do a down-to-the-model? It gives something that's you know semantically completely identical but is not the exact totalist that you expect. Yeah so that's a great question. I'll talk more about that later. Here in this case we don't do unconstrained. So the way you would evaluate MMLU is basically either you look you as the first question and then you look at the likelihood of the model generating A, the likelihood of the model generating B, C and D and you look at which one is the most likely. Oh you can ask the model out of ABCD which one is the most likely and you look at the model.  look at what the most like in extokin is a b c o d. So you can stream the model to say it can only answer these four things. Can you say you can stream the model? Yeah. You can stream it with the prompt or do you mean of its whole probability distribution there outfits? You're only comparing the outfits up like you're only comparing the A-tunkin. Yeah. So in the second case I gave you, you would do exactly the, I will actually you would do both. In the first model saying a b c o d plus you would consume to only look at these four tokens. In the first case you don't even need to generate anything. So in the first case you literally just look given it's a language model. It can give a distribution over sentences. You just look at what is the likelihood of generating all of these words. What is the likelihood of generating the second choice? And you just look at whether the most likely sentence is actually the real answer. So if you're actually sample from it you really just use p of x1 to xl. Does that make sense?  sense? That being said, evaluation of open-ended questions is something we're going to talk about later and it's actually really important and really challenging. Yes? Earlier I mentioned that metrics like complexity are not usually used because it depends on how you do it. Some design choices, I also want to speak more to that. Oh, yeah. So, think about complexity. I told you, complexity is between one and vocabulary size. So now I imagine that ChatGPT uses a tokenizer that has like 10,000 tokens, but Gemini from Google uses a tokenizer that had 100,000 potential tokens. Then actually the Gemini one will have like the upper bound of the the complexity that you can get is actually worse for Gemini than for ChatGPT. Does that make sense? So that's just an idea. It's actually a little bit more complicated now, but there's just like one first or the bit of where you can see that the tokenizer.  actually matters. Great. OK, so evaluation challenges. There are many. I'll just talk about two really briefly. One, as I told you, there are two ways of doing evaluation for these MML views. Actually, there are many more than two, but I give you two examples. And it happens that for a long time, even though that was a very classical benchmark, that everyone used actually different companies and different organization were actually using different ways of evaluating MML view. And as a result, you get completely different results. For example, LAMAS 65B, which was the first model of meta in the LAMAS series, had on helm 63.7 accuracy, but on this other benchmark had like 48.8. So really, the way that you evaluate, and this is not even talking about prompting, this is really just kind of the way that you evaluate.  the models. Promoting is another issue. So really there are a lot of inconsistencies. It's not as easy as it looks. First thing, yeah, sorry. How do we make sure that all these models aren't trained on the bench model? Okay, second thing. This is a great question. Train test contamination. This is something which I would say is really important in academia. In, given that the talk is mostly about training large language models, for companies it's maybe not that important because they know what they trained on. For us, we have no idea. So far, it's a real problem. So there are many different ways of trying to test set, sorry, whether the test set was actually in the training set. One kind of cut trick that people in the lab, in Tetsu's lab have found is that what you can do is that given that most of the data set online are not randomized, you can just look at  And in that language models what they do is just predict the next word. You can just look at the entire test set. What if you generate all the examples in order versus all the examples in a different order? And if it's more likely to generate the thing in order given that there's no real order there, then it means that probably was in the training set. Does that make sense? So there are many, that's like one of them. There are many other ways of doing it. Train test contamination, again, not that important for development, really important for academic benchmarking. Great. So there are many other challenges, but I'll move on for now. Great. Data. So data is another really big topic. At a high level people just say, oh, you basically train large language models on all of internet. What does that even mean? So people sometimes say all of clean internet, which is even less fun. So internet is very dirty and really not representative of what we were.  one in practice. If I download a random website right now, you would be shocked at what is in there. It's definitely not your Wikipedia. So I'll go really briefly on what people do. I can answer some questions, but data is on its own. It's a huge topic. Basically, first, what you do is download all of internet. What that means is that you use web crawlers that will go on every web page on internet, or every web page that is on Google. And that is around 250 billion pages right now. And that's around one petabyte of data. So this is actually a common crawl is one web crawler. So people will usually write their own web crawlers. What they do is that they use standard web crawlers. And a common crawl is one of them that basically every month adds all the new websites that were added on internet are found by Google. And they put it in a big, basically a big data set.  So that's on Common Quall you have around 250 billion pages right now. So 1 e6 gigabytes of data. Once you have this, so this is a random web page, like literally random from this Common Quall. What you see is I'm one and really doesn't look at the type of things that you would usually see. But actually, so this is an HTML page. It's hard to see, but if you look through, you will see some content. For example, here, test King World is your ultimate source for the system X-high performance server, and then you have three dots. So you don't even, the sentence is not even finished. That's how a random internet looks like. So of course, it's not that useful if you just train a large language model to generate things like this. So what are some of the steps that I needed? First one, you extract the text from the HTML. So that's what I just tried to do by looking at basically the correct text. There are a lot of challenges by this. For example, extracting math is actually very common.  complicated, but pretty important for training large language models. Or for example boilerplates, a lot of your forums will have the same type of headers, the same type of footers. You don't want to repeat all of this in your data. Then you will filter undesirable content. So not safe for work, harmful content, PII. So usually every company has basically as a blacklist of websites that they don't want to train their models on. That blacklist is very long. And you basically say, if it comes from there, we don't train on this. There are other ways of doing these things is that you can train a small model for classifying what is PII, removing these things. It's hard. Every point here that I'm going to show you is like a hard amount of work. But I'm going to go quickly through it. So filter undesirable content. Second or fourth is the duplication. As I said, you might have things like headers and footers in forums that are always the same.  want to remove that. Another thing that you might have is a lot of URLs that are different, but actually show the same website. And you might also have a lot of paragraphs that come from common books that are basically de-doubligated a thousand times or 10,000 times on internet. So you need to have to de-doubligate also very challenging because you have to do that at scale. Once you do de-doubligation, you will do some heuristic filtering. You will try to remove low-quality documents. The way you do that are things like rules-based filtering. For example, if you see that there are some outlier tokens. If the distribution of tokens in the website is very different than the usual distribution of tokens, then it's probably some outlier. If you see that the length of the words in this website is super long, there's something strange going on on that website. If you see that the website has only three words, maybe is it worth training on it? Maybe not. If it has 10 million words, maybe there's something also wrong going on that page.  So a lot of rules like this, yes? What are our undesirable content from our data set instead of kind of... ...it's like a supervised mass. Can we not just say like, here's this hate speech website that's actively trying to... ...but to actively penalize them up for data. We'll do exactly that, but not at this step. That's where the post training will come from. Pre-training, the idea is just to say, I want to model kind of how humans speak, essentially. And I want to remove all these like, headers, photos and menus and things like this. But it's a very good, like, idea that you just had in it. That's exactly what we'll do later. Next step, model base field training. So once you've filtered a lot of data, what you will do... ...and that's actually a very cute trick. You will take all of Wikipedia and you will look at all the links... ...that are linked through Wikipedia pages. Because probably if something is...  by Wikipedia, it's probably some high-quality website. And you will train a classifier to predict whether something comes from, whether a document comes from one of these references from Wikipedia, or whether it's from the random web. And you will try to basically say, I want more of the things that come from Wikipedia references. Does that make sense? So yeah, so you will train a machine learning model. Usually also very simple models, because you need to do that really at scale. I mean, just think about the 250 billion pages. Next one, you will try to classify your data into different domains. You will say, OK, this is entertainment, this is books, this is code, this is like these type of domains. And then you will try to either up or downweight some of the domains. For example, you might say, you might see that actually, if you train more on code, then actually your model becomes better on reasoning. So that's something that people...  people usually say in a very hand-waver way, if you train your model on code, actually it helps reasoning. So you want to up-weight the coding distribution because that helps for general language modeling skills. Books is usually also another one that people usually up-weight. Entertainment, they usually down-weight. So things like this. Of course you want to do it, so people used to do it maybe kind of heuristically. Now there's entire pipelines that we'll talk about of how to do these things slightly more automatically. And then at the end of training, usually training on all of this data that we saw, usually train on very high-quality data at the end of training your large language model, where you decrease your learning rate. And that basically means that you're kind of overfitting your model on a very high-quality data. So usually what you do there is like Wikipedia. You basically overfit on Wikipedia. And you overfit on like...  human data that was collected. The other thing is like, continue pre-training, forgetting longer context. I'm going to skip over all of these things. But I just to give you a sense of how hard it is when people just say, oh, I'm going to train on internet, that's a lot of work. Really, we haven't figured it out yet. So collecting well data is a huge part of practical large language model. Some might say it's actually the key. Yes. No more data. So there's a question. So usually you would install the term, where I write on data. After I go to your master's suppose it's a typical amount of you that you have been in. And then how large it seems that it's a big deal to go through all the data steps you took out. So is a question, how large is the data after you filter? Yes, so you feel that it's good to go through. How large it seems you need to go through the field, the order of future systems. How slow is it? How many people would you need? Oh.  What are you going to do this video? OK, that's a great question. I'm going to somewhat answer about the data, how large is the dataset at the end of this slide, for number of people that work on it. That's a great question. I'm actually not quite sure, but I would say, yeah, I actually don't quite know, but I would say it's probably even bigger than number of people that work on kind of the tuning of the pre-training of the model. So the data is bigger than kind of the modeling aspect. Yeah, I don't think I have a good sense. I would say probably in Lama's team, which have like 70 HP, people I would say maybe 15 work on data. Yeah. All these things, you don't need that many people. You need a lot of computer also, because for data, you need a lot of CPUs. So yeah, and I'll answer the second question at the end of this slide. So as I just kind of alluded to, really, we  have installed data at all for pre-training. So there's a lot of research that has to be done. First, how do you process these things super efficiently? Second, how do you balance all of these different domains? Can you do synthetic data generation? That's actually a big one right now. Because we don't have, we'll talk about that later, we don't have enough data on the internet. Can you use multimodal data instead of just text data? And how does that improve even your text performance? There's a lot of secrecy. Because really, this is the key of most of the pre-trained large language models. So for competitive dynamics, usually these companies don't talk about how they do the data collection. And also, there's a copyright liability issue. They definitely don't want to tell you that they've trained on books even though they did, because if not, you can sue them. Common academic benchmarks. So that will kind of answer what you asked. So those are the smaller ones. The names are not that important, but it you decide from a head-  around 150 billion tokens, which are around 800 gigabytes of data. And now it's around 15 trillion tokens, which is also the size of the models that are, right now the best models are probably trained on that amount of data. So 15 trillion tokens, which is probably, I guess, two more to my bigger than that. So 80 E3 gigabyte. So that would be around 100 to 1000 times the filtering of the common crawl, if I'm not mistaken. So yeah, one very famous one is the pile. So this is an academic benchmark of the pile. And we can just look at what distribution of the data they have. It sings like archive, PubMed Central, which is all the biology stuff. Here it's Wikipedia. You see stack exchange, some GitHub, and some books, and things like this. Again, this is on the smaller side.  So this is, if we look at here, this is on 280B. So in reality, it's like 100 times bigger. So you cannot have that much of GitHub and on Wikipedia. In terms of closed source models, just to give you an idea, Lamat 2, it was trained on two trillion tokens. Lamat 3, 15 trillion tokens, which is currently the best model that we know on how much it was trained on, which is the same thing as the best academic, or the biggest academic benchmark, which is 15 trillion tokens. In the GPD 4, we don't really know, but it's probably in the same order of magnitude. Or it's probably around that, actually, it's probably around 13 from leaks, if the leaks are true. Great. So scaling loss, any other questions on data before you go to scaling loss? Sorry, I know I'm giving you a lot of information, but there's a lot into training and large language models. Great. Scaling loss. So the idea is that what people saw,  around 2020 or at least from a long time, but they've been able to kind of theoretically show it or impurity show it since 2020 is that the more data you train your models on and the larger the models, the better the performance. This is actually pretty different than what you've seen in this class. In this class, we teach you about overfitting. Overfitting doesn't happen with large language models. Larger models, better performance. It's something that really took a long time for the community who took this type of class to realize. But for the exam, overfitting exists. So, okay, the idea of scaling loss is that if given that you know that more data and larger models will always give you better performance, can we predict how much better your performance will be if you increase the amount of data and the size of your model? And surprisingly, it works. So here you see three plus from a very famous paper called scaling loss from OpenAI. Here you see on the x-axis compute.  So how much did you train, like, how much compute that you spent for training? And here you see test loss. So this is essentially, I mean, some perplexity, but it's your validation loss. So it's a log of the perplexity. And if you put these two on log scale, then you see that the performance, like the, sorry, the scaling law is linear. That means that if you increase your compute by a certain amount, you can say by how much your test loss will actually decrease. Same thing with data and same thing for parameters. If you increase the data set size, your loss will decrease by an amount that is somewhat predictable. If you increase the number of parameters, it will decrease, the loss will decrease by a amount which is somewhat predictable. This is really amazing, very surprising. I mean, it looks innocuous when you look at these type of plots, but that's crazy because it means that you can predict how well we're going to perform in two, three years, depending on how much compute we will add.  assuming that these things will hold. There's nothing theoretical about it. Yes? What is the loss of the user here as a proplexity? So I said proplexity was like 2 to the power of the loss. So this is the power of the proplexity. And the second thing is, when you don't increase the number of parameters, so you increase the total data set size and the number of the application. Time doesn't that just increase your compute? So all of this work is not just how many. You do data? Oh, yes. No, this is a great question. So the compute here is actually a factor of two things. The data and the parameter. What I'm showing here is that you can, well, actually, we're going to talk about that in details. But basically, if you increase the number of parameters, you should increase the number of data that you have. So you actually don't go multiple times through the same data set. No one does epochs at least not yet, because we haven't still kind of enough data.  So yeah, this is all the same trend which is increased compute decreased loss. Yes. Have we seen the numbers for the last two years? Or is it still holding? It is still holding. I don't have like good numbers to show you, but it is still holding, surprisingly. Yes. Is there a draw evidence like a procoevent that you've never thought of? But you can't draw it with expected value, right? No empirical evidence of plateauing any time soon. Why? We don't know. Well, it happened. Probably. I mean, it doesn't need to because it's actually in log scale. So it's not like as if it had to go, it had to plateau like mathematically. It could continue decreasing like this. I mean, most people think that it will probably plateau at some point. We don't know when. Okay, so that's, I will talk more about scaling loss now. So why are scaling loss really cool?  Imagine that I give you, you're very fortunate, I give you 10,000 GPUs for this month. What model will you train? How do you even go about answering that question? I mean, this is a hypothetical, but that's exactly what these companies are faced with. The old pipeline, which was basically two high parameters on the big models. So let's say I have 30 days, I will train 30 models for one day, each I will pick the best one, and that will be the final model that I will use in production. That means that the model that I actually used was only trained for one day. The new pipeline is that you first find a scaling recipe. So you find something that tells you, for example, one common thing is that if you increase the size of your model, you should decrease your learning rate. So you find a scaling recipe such that you know, if I increase the size of my model, here's what I should do with some high parameters, then you tune your high parameters on smaller models of different sizes.  Let's say I will say for three days of my 30 days I will train many different models and I will do high-preparameter tuning on these small models each of different sizes Then I will fit a scaling law and try to extrapolate from these smaller models Which one will be the best if I if I train it for much longer? Oh, sorry if I train it for a larger model and Then I will train the final huge model for 27 days instead of just one day So the new pipeline is not train things or do high-preparameter tuning on the real scale of the model that you're going to use in practice But do things on smaller ones At different scales try to predict how well they will perform once you make them bigger I will give that I will give you a very concrete example right now Let's say transformers versus LSTMs and let's say you're you have you's 10,000 GPUs You're not sure which one you should be using should I be using transformable base model and an SCM base model What I will do is I will train transformers at different scales  So here you see different parameters on the x-axis, y-axis is my test source. I will then show you different LSTMs at different scales. Once I have these points, I will see, oh, it kind of fits a scaling law. I will fit my scaling law, and then I will be able to predict, oh, if I had 10 times more compute, here's how well I would perform for the LSTM. It's actually slightly less linear for the LSTM, but like you could probably try to predict where you would end up. And clearly from this plot, you would see that transformers are better. One thing to notice when you read these types of scaling laws is that there are two things that are important. One is really your scaling rate, which is kind of the slope of the scaling law. The other thing is your intercept. Like you could start worse, but actually become better over time. It just happens that LSTMs are worse for both. But I could show you another one where things you can predict that actually...  like after certain scale you're better off using that type of model than others. So that's why scaling laws are actually really useful. Any questions on that? Yeah. So these are all kind of very, how sensitive art is to like small difference in architecture like one light transfer of architecture versus another transfer of architecture? You basically have to like pick your own curve and basically say like, oh, scaling does tell you that should be some like logarithmic function. Yeah. Yeah. So usually for example, if you're an academic and you want to now at least that's like pretty recent and you want to propose a new like activation, that's exactly what you will do. You will fit a scaling law, show another scaling law with the standard like I don't know Gailu and you will say that it's better. In reality, once you start thinking about it in scaling laws terms, you really realize that actually all the architecture differences that we can make like the small minor ones, all they do is maybe...  We changed a little bit the intercept, but really that doesn't matter. Just train it for 10 hours longer or wait for the next GPUs and these things are really secondary. Exactly why I was telling you originally people spend too much time on the architecture and losses in reality these things don't matter as much. Data though, if you use good data, you will have much better scaling loss than if you use bad data. That really matters. Another really cool thing you can do with scaling loss is that you can ask yourself how to optimally allocate training resources. Should I train larger models? Because we thought it's better when you train larger models, but we thought it's also better when you use more data. Which one should I do? Should I just train on more data, a smaller model or should I train a larger model on less data? So Chintilla is a very famous paper that first showed this. The way they did it, I want to give you a little bit of a sense of what these plots are. Here you see training loss again.  On the x-axis, you see parameter differences, as sorry, number of parameters, so the size of the model. And here, all these curves are what we call isoflops, which is that all the models on this curve have been trained with the same amount of compute. The way that you do that is that you change, so you vary the number of tokens that we're trained on, and the size of the models. But you vary in such a way that a total compute is constant. So all these curves that you see with different colors have different amount of compute that we're trained on. Then you take the best one for each of those curves. Once you have the best one for each of those curves, you can plot how much flops it was, and on which curve were you on, and how much parameters did you actually use for training that specific point? You put that on the log log scale again, and now you fit a scaling log again. So now I have something which tells me if-  If I want to train a model of 10 to the power 23 flops, here's exactly the number of parameters that I should be using, 100 B. And you can do the same thing with flops and tokens. So now you can predict if I tell you exactly, I have one month of compute. What size of model should I be training? Figure scaling law, and I tell you. Of course, that all looks beautiful. In reality, there's a lot of small things of, should you be counting embedding parameters. There's a lot of complexities. But if you do things well, these things actually do hold. So the optimal number of parameters that Shinchilla people have found is to use 20 tokens for every parameter that you train. So if you add one more parameter, you should train your thing on your model on 20 more tokens. So one caveat here is that this is optimal training resources. So that is telling me, if you have 10 to the power 23 flops, or if you have like 100, I don't know how much that is. 100 million.  $5 million or $10, no, that would smudge less actually. I'd say I have $5 million to train my best model that gets the lowest loss. What would I train on? In reality, these companies need to think about inference also. If you have a smaller model, they will spend less over time. So actually, if you consider the inference cost, you have other papers that try to show that. It's around 150 parameters, sorry, tokens per parameters. Because you prefer having a smaller model, because over time, you're going to actually spend less money on inference of these models. So 150 to one, that's around what the best models are trained on right now. At least the ones that are used in practice in production. Great. Any question on Chichol? Great. I'm sorry. How expensive is it?  or it's really small and it's really good to train. Actually, very expensive. I will not talk about it first, because that would be another entire lecture. But just think about Chat GPT. When they have, I don't know how much it is now, like 600 million people that use it. Like, that's a lot. So it's actually very expensive. There's a lot of optimization you can do for inference, though. And that's an entire other lecture. So I'm going to skip that this time. But it's very interesting. OK, two things. As I said, there are many things that you can answer with scaling loss. I just try to give you two examples, but really there are many things. What data do you use? What mixer? What data mixing? Waiting? You use the data mixers. That's what we talked about before. What architecture you use? Whether you should make your models wider or deeper. Should you be paying for more GPUs? Or actually collecting more data? All these things are things.  you can try to answer with scaling loss. One thing I want to say is the bitter lesson. If you ever heard of Richard Sutton, a very famous blog post in 2019, what he realized, which I think not enough people realized, I didn't definitely did not realize at that time, is that once you see these type of scaling loss, you know that the more compute you have, the better models you will get. So with scale, you will get better model. And you also know by Mozilla or these type of variants of Mozilla, that you will always have better compute. Then the only thing that matters is just to have architectures that can leverage computation. So what matters is basically systems, data, and less so the architecture, like the small architecture differences like your activation and things like this. So I think that's one of the reasons why most of research focuses on some things that for industry matters less. And I was one of those researchers for a large part of me.  My career. So don't spend time over-complicating. Do you do the simple things? Do it well, seal them. That's really what OpenAI taught us with ChatGPT and with all the GPs before. OK, I want to give you some back-of-the-envelope computations. So I might be off by a few factors here, but I just want to give you a sense of how costly it is to train some of these models. I'll give as an example, a Lamat 300B, which is currently the best open source model that you can get. It was trained on 15.6 tokens. It has 405 billion parameters. So just now that you know what is like this optimal tokens parameter, that's around 40. So that's a little bit more than Chinchilla, but less than this inference optimal model. So they went for training optimality. Flops for this model. So one simple way to compute flops is six times the number.  of parameters times the number of data that you train on. So if you do the simple calculation here, it's 3.8E25 flops. The reason why this is important is that if you follow the little bit of the news, there's an executive order from Biden that basically says I want you have 1E26 parameters, sorry, flops, then you have special scrutiny on your models. So they went 2x less than that. So they really went right below this to not have special scrutiny. So 3, 8, I might be off by a little bit, but it's definitely under the 1E26. So P is parameters, N is data, number of tokens. This is just an approximation. Yeah. Okay, compute, we know that they train it on 16,000 H100s, and we know the throughput they set it to. So if you do the computation.  It takes around 70 days, or 26 million GPU hours. At least that's with my back-of-the-envelope computation. They actually said that they used 30 million instead of 26 million GPU hours. So maybe they had like some challenges. I don't really know. But if you follow the simple computation, it's around 70 days. Cost, I mean, this is hard to approximate, but I'm just going to say it's kind of the rent. Like, what if I were to rent H100s? That many, H100s for that many days. How much will I pay? H100, a lower bound on the renting cost of H100 is around two hours, a $2 per hour. So if you multiply this by 26 million hours, you get $52 million. So they probably pay less than that, but not actually much less, because all these services that actually rent GPUs, they don't make that much.  money. So it's probably slightly less but not that much less. Now salary, I said 50 employees, 500k per year. Yeah, it's probably the right bullpock, 25 million. So if you put all together, around 75 million dollars for training this slammer model. I'm probably out by like 10 million, but that's kind of right bullpock. Carbon emitted, a lot of people might ask, like also the cost is not the only thing that is important. So I did the computation. It's around 4,000 tons of CO2 equivalent. That is actually only 2000 return tickets from JFK to London. So right now carbon emitted is actually not, I mean it's huge, but it's not like meaningful yet. I think in maybe GPT 6 GPT  Once you multiply this by 100, that might become a real issue. Right now, it's still not, I think, an issue in the grand scheme of things. Next model, the way you should be thinking about these models, is that every new generation, the number of flops essentially multiplies 10x. Well, at least that's what they try, if they have enough energy and if they can buy enough GPUs. Great. Any question on these backup DNA envelope math? Okay. So, now we talked about pre-training. I wanted to also chat about systems, because now we know compute is really important. So there's a question of how do you optimize your compute? I will leave that for the end, because I'm not sure how much time we will have. I think it's important, but hopefully I'll be able to talk about it later. It's slightly different than what we've been talking about right now. So I'll move on to post-training for now. So the task of post-training, the reason why we need to...  to do post-training is as I told you before, it's to make AI assistance. So language modeling is not really the thing that you want when you have an AI assistant. For example, if you ask to GPT-3, which is a purely language model, a pure language model, not an aligned one, if you ask a question, I explain the moon landing to a six-year-old, the conclusion that you would get is something like explain the theory of gravity to a six-year-old. Because what it learned is that on internet, if you have one question, you usually have maybe another bullet point of other similar questions. You don't usually have question in an answer later. This is not what you want from an AI assistant. So how do we do this alignment, which is this post-training and making these models assistance? So the goal of this alignment is to basically get LMS, follow the instructions that are given by users. Sign and maybe some designers.  kind of desires. So think about moderation. You don't want the model like, open-air definitely doesn't want the model to say stuff that is very toxic. So here you see on the left hand side that when you ask a question it actually provides a real answer so it's not like before the LLM and on the right hand side you see that it would if you ask to write a tweet describing how as certain part of the population or evil it will say that it cannot do that. So that's kind of this alignment. The background here is that basically the data that you want for training some of these models is like we know what we want which is just asking humans this is a question this is the answer that you want but the thing is that it's very expensive to collect that data and it's hard to find it online. In contrast pre-training data is not what you want but there's a lot of it. So what we will do or the main idea is simply take a  pre-trained large language model, pre-trained all of internet, and then you just fine tune. So you just change a little bit of weights on the type of data that you actually want. And hopefully given it, you're already pre-trained on all of internet. It basically learns or knows how to speak in English and knows standard language syntax. Then you can really fine tune it with very little data. OK, SFT. So supervised fine tuning is really exactly what I just said, which is the idea of fine tuning the large language model on basically the desired answers that are collected from humans. So why is it called supervised fine tuning? Because you basically want to do language modeling on the real answers. So language modeling is this like next word prediction. And that's the fine tuning part. And then you want to do it on desired answers given by humans. So that's why we call it supervised. So how do we collect this data? Well, I just said it. You can just ask humans to tell you, this is the question. This is the answer that you would want from something.  of these models. So this is an example. I can't read very well on my computer, but my kid needs to do a science, no, let's read this one. Can you write a short introduction about the relevance of the term monopsony? And then it says monopsony refers to a market structure blah, blah, blah. And that's a human number with that. So actually this is open assistant, which was a way to collect data online by humans. So this type of supervised fine tuning while I'm in is really the key of chat GPT. This is what made the big jump from GPT3, which was mostly something that was known by AI researchers to chat GPT, which became known by basically everyone. So the problem with human data is that it's very slow to collect and very expensive. So one percent possible simple idea.  is to use LMS to scale data collection. So that's exactly what we did with Alpaca one year ago. What we did is we asked humans, or we use a data set of human question answers. So there were 175 question answers here. And we asked the best more at the time. So Texas Vincis user three to basically generate many more of these question and answers. So all we did is like, this is what humans would write, now write similar answers and similar questions. And we collected 52,000 LLM generated question answers. And then what we did is simply we took LAMAS 7B, which was the best pre-trained model at the time. And we just fine tuned this with supervised fine tuning as I told you. And that's how we got the Alpaca 7B model. And this is the type of data that we collected. So things like what does algorithm mean? And algorithm is a step by step set of instruction. You used to solve a problem or achieve a goal, blah, blah, blah. So the data is not actually, it's actually pretty good, given it was LM gen.  generated by LLMs from essentially two generations ago. So that really started at least for us kind of as an academic replication of ChatGPT. Now it really is a big field of synthetic data generation of how to use LLMs to basically make development of LLMs faster and basically by decreasing the amount of human hours that you need. Quantity of data. So we talked about what type of data and how we collected. One thing which is surprising with SFT is that you don't need that much data. So what this paper showed, this is called Lima, is that if you have, if you scale the amount of data that you use from supervised fine training from 2000 to 32,000, it really doesn't help much. So here scaling loss definitely don't help. So the intuition here is that all you learn is you learn how to format your desired answers. Another way of seeing it.  is that your pre-trained models, they essentially model the distribution of every user on internet. One that might write bullet points, another one that might answer question with an answer. So all you tell your model is like, wait, you should actually be optimizing more for this type of user than another one. So you're not actually teaching anything through this SFT, so supervised fine tuning. All you do is you tell the model to kind of optimize for one type of user that it's already in a pre-trained dataset. So the knowledge is already in a pre-trained LLM, and you basically just specialize to one type of user. Great, any question on SFT? Yes. So, I know it's a big issue with synthetic data where if you keep generating data from the same distribution, eventually you're not learning a new distribution, you're essentially playing with it. It just puts track of that. Surely you can't scale that for a way you can keep going on in generating from the same data.  and hope to learn something new. So it's an active area of research. And you've thought that you have around how people are maybe thinking around this and better ways to bootstrap or to give up on this idea and realize that the chart shows you don't need that many, so just get humans to generate 2,000 radiability. Yeah. So that's a very good question. So for the data stuff, so I'm saying it's not that important for SETT, but there will be another thing we'll talk about right after, where actually data does matter. My intuition based on not that much empirical results is that you can still get even though you use your LMS, if you use purely LM generated text, and you do that for like three, four generations of LMS, I agree with you that probably you won't improve much. But for me, what is important is how do you use human in the loop with LMS? Not purely LMS, not purely humans, but maybe what you can do is just have the model generate some new text and just humans write a few edits. And it's not much f-.  faster than writing the entire text. And I think that if you have that type of collaboration, then from an information theoretical point of view, you still get additional information, but you're so much faster than if you use humans. And I think that as a field, we'll probably move towards these type of things, which is really just finding the examples that are important and asking humans, it's kind of active learning, just asking humans exactly when you need to get their inputs. Yes? So, you're just trying to make the same loss function, the same general training after the supervised learning that we do for the pre-training, right? Because the examples you showed, I think the important thing for good examples is that they're super action-oriented. There's these more complex things. Still just like changing. Same loss. So that's why here, I didn't maybe didn't emphasize enough. This is just language modeling. Fine-tune the language model on the desired answers. So this is literally the same loss. It will be different.  in two seconds. But the first step of SFT is literally the same loss where you just say, okay, I want to actually specialize on that type of data. So there's even a question of like, what is pre-training, what is post-training? Because in reality, it's just like a different data that you use. The reason why we can usually call it post-training is that the way we collect that data is very different. Great, great questions. Yes. Maybe it's the same question, but why would these 2000 examples have such a over-weighted influence of the internet? So that's why we, also that's another reason why we call it post-training is that we use different type of hyper parameters. So you know, I told you basically at the end of pre-training, you essentially end up with a learning rate of zero. And here you're going to increase your learning rate to like 1 e minus 5, 1 e minus, yeah. And so the way that you give to them is actually different. OK, second step or second part of this post-training is what we call reinforcement learning.  from human feedback or all HF, some of you might have heard of that. The idea is that SFT has a problem, namely that you do behavioral cloning, which means that you just try to clone what the humans would say. And that has many issues. One of them is that you're bound by human abilities. So if humans actually, humans won't generate the things that they think is actually the best thing to generate. So if you ask me to write a book, I mean, I can definitely enjoy a book. I can probably say one book is better than another, but I'm definitely not going to be as good as writing the book that I want to read. So you're going to be bound by the human ability to generate things, even though the humans might be better at distinguishing between things. That's one issue. Issue number two, I find that actually pretty interesting, is that if you ever heard of the word house Cination, so this is LLM's generating false information, house Cination might or these people have hypothesized that that can  come from the supervised fine tuning, even if you do supervised fine tuning on data that is correct. And the reason why that is is that if, given I told you that basically SFT is with very little data and it's with data that doesn't, the model doesn't learn anything new. So what if the human gives an answer that the model didn't know was true? From the model perspective, the human basically is telling the model, generate this thing that seems plausible, but actually I have no idea if it's true or not. So just to give you a very concrete example, if we go back to this monopsony example, can you write blah blah blah about monopsony, imagine that there were human rotor reference on this type of book. And that book might exist, that might be a correct reference. But what if the LLM never saw this reference during pre-training? Then it doesn't know that it's a correct reference. To really what you tell the model is to generate a make up, some plausibly sounding reference.  rather than actually tell the real reference that it's arguing pre-training. So hallucination might be, like, might be caused by this SFT. That's problem number two. Does that all make sense? Great. Problem number three, price. Generating the ideal answers is very pricing. And that comes back to your question of, like, humans writing an entire answer is actually pretty expensive. So that's where all HF comes in. The idea is that instead of cloning the behaviors of humans, we're going to maximize human preference. And the way we're going to do that, so the pipeline, is that for a certain, for every instruction, you're going to ask a model to generate two answers. And usually you use a pretty good model. So you usually don't use an LLM here. You use a SFT fine tune, you use a fine tune LLM already to give, like, pretty good answers. And then you ask labelers, which of these two...  answers was better. So select the preferred one. And then with different type of algorithms, we're going to talk about the algorithms. You just fine tune the model to generate more of the green thing than the red thing. So more of the good stuff. So now the question is how. And we're going to talk about that right now. So there are two ways that we're going to talk about and two that are mainly using the community. The first one is simply the idea of using reinforcement learning. So hopefully you all know what reinforcement learning is now. So when you think about using reinforcement learning, one important question is like what is the reward that we are optimizing? So in this case, there are really two options that I can think about. The first one you could just say, I'm going to compare the output generated by some baseline, the output generated by my model. And I'm just going to ask the human to say which one is better. And I'm going to use this as a reward. So if I'm better than the baseline, this is a plus one. If not, that's a minus one. So now it's binary reward. The problem of binary reward is that it's very sparse.  you don't get much information out of it. Like maybe you answered was slightly better, maybe it was way better, and you don't really know from this how much better it was. So option two is that you can train what we call a reward model, which is simply a classifier. So you use machine learning to classify how much better two outputs are from the perspective of the human. So there's a little bit of better, but what you basically do is that you train, you take a real model R, which is just a large, also a large classifier, and you basically ask this reward model, you give it the input and the actual output that you have, one of the two outputs, and you just exponentially that's the softmax class that you all know about, and now you divide by the, the exponentialed reward on the first example, sorry, on the first output.  and it's on the second output. And you basically train, so the reason why you do that is that you train your model, you train this reward model to be able to classify how much better one output is to another one. So another slightly less-converted way of seeing it is that your reward model will output some reward that will be used as the logits of your softmax. So now if you have high logits in your softmax, it means that highly likely this output is better. So that's what we call Bradley Terry model. Yes. Is this your reward model going to be the entire output? Or is it going to be like that? So this takes the entire output at one. So it takes all the input and all the output, and it gives one number. Yes? So I'm going to be talking about the value of an a human being. So with the reward model, where would that human be? Oh, why so? And...  Sorry, maybe I wasn't clear. You train this reward model to fit this green and red preference from humans. So basically, you train a classifier to say whether the humans prefer red or green. But instead of using the binary reward, which is what the human will tell you, you basically use the large bits of the softmax. And the thing with the large bits is that large bits are continuous. So now you know that if your reward model said it has high logents, then in some ways the human highly preferred this answer to some other answer. Great. So as I just said, continuous information says better. So that's what people use in practice. Or at least, use to use in practice. I'll tell you about the other algorithm later. So what you do at the end is that you basically try to just use reinforcement learning that you know about. Now we know we have our reward. What you sample through is the generation from your large language model.  Then you just use some regularization terms. The reason why we do this regularization term is for avoiding what we call over-optimization. This reward model might not be really represent, like might not perfectly model human preferences. So you don't want to maximize this thing to essentially infinity. You do it using PPO, which is a common reinforcement learning algorithm. One thing to note here because it will be important for later, is that when we use maximum likelihood, I'm sorry, now the large language models are actually a policy for your reinforcement learning. It's not maximizing maximum likelihood anymore, which means that you're not modeling any distribution anymore. And the reason why this is important is that models that went through this type of PPO actually don't give you likelihoods of text that are meaningful. Because what you optimize them to do is basically just optimize for generating the most likely thing. Not optimized for modeling.  like all the answers that humans might say. Another way of saying that is that there's nothing that incentivizes here the model to not give like a single possible generation. Nothing here says it's good if you have some distribution with some entropy. Okay, if you haven't followed, it's not that important, but just good to know. Great. So PPO is exactly what Chad G.P.T. did originally. So here's the on their blog posts or what they have, is step one, do supervised fine training, which now you all know about. Step two, train a reward model on human preferences. Step three, do PPO multiple steps, which is where you see this blue arrow. So you train the model once with the PPO, you collect new data, you continue. And that's exactly what Chad G.P.T. did. And that was a big breakthrough between GP3 and Chad G.P.T. One thing to note is that PPO has many challenges. Reinforce learning.  something as super nice theoretically. In practice, anyone who ever worked with reinforcement learning knows it's such a mess. There's a lot of things like roll outs, out-of-loop slipping, so many complications. So it's messy. This is the idealized PPO-use4LM setting. So that's already much more complicated than this expectation we saw before. And in practice, it's actually much more complicated. So we have one implementation of it that we had to do, and I'm not going to go through it. But basically, you have like so much stuff that you have to think about when you implement that type of PPO algorithm. So you have clipping everywhere. You have a lot of complexities and things are not well documented. All this to say that there was a new method that was proposed also from Sanford one year ago called DPO, which is essentially a simplification of PPO. And the way what they did or the idea that they have is that instead of using reinforcement learning, you can just maximize the probability of generating the stuff that you like and minimum.  the probability of the stuff that you don't like. So if you think about the human preference, the red and green maximize green minimize red. So the loss is actually this one. What you see, this is simply some log of the model. So this is the likelihood of the model generating the things that the human preferred given the inputs. And what you try to do is basically maximize the likelihood of generating the things that you like, minimize the likelihood of the things that you don't like. All the rest of the terms here, it's not too important. It's actually really not that complicated to understand. But at the high level, it's really just maximizing the things you like minimizing the rest. And one thing to note, which I was going to say just here, is that actually all the rest is chosen such that the global minima of PPO and the global minima of this DPO under some assumptions.  essentially equivalent. So this is the right thing to do mathematically. I'm not going to go through the derivations, but that's the right thing to do. It's pretty different with PPO in the sense that now, with PPO what you had to do is collect their human preferences, then train your reward model with maximum likelihood, then use reinforcement learning. Now all you do is basically maximum likelihood. Much simpler, yes. I mean, yeah, it's a simple thing. This is a much simpler thing, like what you just do to do with your business. Why did they start with this reward model? What about them doing that? I think it's a great question. I don't really know. What I can tell you is that I don't put in the people who did basically this, sorry, who did Chagy PT initially, other ones who actually wrote PPO. And I think there were just, like, there are a lot of reinforcement learning people. And I think that for them, it was very intuitive. So there's also some additional potential benefits. For example, they don't...  Yeah, for example, if you use the reward model, the cool thing here we have reinforced learning is that you can use unlabeled data with the reward model. So here you can only use the label data for doing DPO. For PPO, you first train your reward model and then you can use unlabeled data where the reward model will basically label this unlabeled data. So there's additional kind of potential, there could be potential improvements. In practice, it happens that they are known and I think just that a lot of people in this team were reinforcement learning experts, including the main author of PPO, which I'm told me. So much simpler in PPO and it basically performs as well. So now this is the standard thing that people use. At least in the open source community, I believe it's actually the standard also in industry. That's called DPO. Gains, so those are older papers on the left. Here this is on a summarization task. You see.  All I want to show you is that basically the pre-trained models were okay and they approve of scale. If you do supervised fine tuning, you improve them a little bit more. If you do PPO or something with all HF with human feedback, you get performance that are as oftentimes depending on a benchmark, even better than humans. So this is the human reference summaries. Same thing is done on a paper that we have alpaca farm where we see the evaluation here is not too important, but basically you see pre-trained model. You jump to SFT and then you jump to PPO, DPO and PPO have the exact same performance. So basically all HF helps. That's kind of the conclusion and DPO is simple. Data, the way that you collect that type of data, first idea is just use humans as we already talked about. Guidelines are very complicated for what humans should be labeling and it's really not that easy. See if you ever do some of the labeling, you will see that it's...  Extremely complicated. Like if I zoom into this, here I have a question, tell me about self-driving cars. And you read both self-driving cars of vehicles that are capable of detecting the surroundings blah, blah, blah, blah. Self-driving cars are cars that are equipped with sensors, blah, blah, blah, to navigate without the need for a driver. And we both seem OK. Like which one is better? It's actually hard to say at the glance. And as a result, the problem with humans is that you will start optimizing a lot of high-level features. For example, the second one is longer. I can guarantee you that most humans will choose the second one. Even though I may do first one is better, I don't know. I haven't read it carefully. So challenges of humans, first, slow and expensive. Second, as I just mentioned, it's hard to focus on things that matter, like correctness. And people usually look at things that don't matter as much, like to form, like length. And as a result, so what I show here is that when you do RHF, the more you do have RHF, the longer the output of the...  models become. So if you've ever been annoyed at chat GPT answering you super long sentences, this is because of all HF. Annotated distribution shift. Like the distribution of annotators that use matters a lot. And you have to think like what is what is even the humans that we want to represent in these models. Another question is like crowdsourcing ethics. Like usually these basically a lot of the labeling that is done. Like the people who do them are not paid well and they have to go through a lot of toxic data because you're basically one the model to avoid saying the toxic data. So crowdsourcing ethics too. So many challenges with human data. So what we did also last year is again the same thing as alpaca just the idea of like oh well now challenges with humans maybe we can just replace them with lm's. So what we did is simply replace oh I see that I'm just realizing that the slides are not centered. Anyways you  replace human preference with LM preferences. So here on this figure, you see on the X-axis the price that we paid for collecting human data. It's around $300 for 1,000 examples. And this is on mechanical turquoise, which are usually like cheaper than maybe some of the other companies that you could go through. And on the Y-axis, it's basically the agreement with other humans, with the mode of other humans. And what you see is that actually, as I told you before, labeling is really complicated. Humans agree with themselves only around 66% of the time. I'm a binary task. And it's not that the humans are not good here, because we were five main authors on this paper. We tried to label this data ourselves, and we only had like, say, 67 or 68% accuracy, even though we talked for like three hours of how we should be doing labeling. But really, it's complicated. It's not an easy task. And here I just showed many different models. And basically, you see that models are much cheaper, and they can actually...  get higher agreement of the mode of humans than humans themselves. The reason why is because humans have a lot of variants, models have no variants. They might be a little bit more biased, but have less variants. It works surprisingly well. Now it's kind of the standard and open source community. I think even in an industry, a lot of people use both humans and LLMs for improving the collection of all HF data. This is the paper from last year, but honestly, now it's more like that LLMs would be around this agreement and this cost. So around, I would say 50X cheaper than humans and better agreement with humans than humans themselves. Okay, so that gets us to evaluation of post-training. And that goes back to your initial question at the beginning of the lecture. How do you evaluate something like charge-up? The answers that charge-up could give are basically unbounded. And it's not that there's one right answer. There are many answers that are just as good. So the main topic.  One, you can't use validation loss because one method might use PPO, the other one might use DPO, validation loss is not comparable. Second, you can't use, sorry, perplexity. That's the thing I told you before. These models are not calibrated. They don't give distributions. They just optimize for one thing. So you can't use perplexity for actually evaluating these type of models. Once they're aligned. Sorry, once they're aligned. Third, there's a lot of diversity of questions that human might ask to these models. Generation, open QA, like some question answering, some summarization, and all of these things. So there's so many things you have to cover. Then the tests are really open-ended. So it's very hard to automate. So that's what you were alluding to before. So the idea is that instead of trying to come up with really easily automated benchmarks, it's just we're going to ask questions that users actually asked to these models in practice. And we're just going to ask annotators to say between these...  two models, which one is better? Like what's the, what's the better output? So basically you do the exact same thing as basically the data from all HF, but you use it now for evaluation. Yes? I'm not sure I understand that. I mean, can't use procllexity not calibrated, really. Hello, I'm still doing like an exit token prediction. So, IPI procllexity, please. So think about the optimal solution after doing PPO is basically one model that gives you essentially a delta like basically says that there's only one sentence that is, that could be generated for that question. So now if you use it on something that is slightly semantically differently, different, it would actually give a likelihood of zero for that answer. So in reality, it's not that extreme, because as you say, it's still a distribution, but it just shows you that there's a fundamental issue with procllexity once these models are not LLMs anymore, they were not trained, at least with PPO, they were not trained to do maximum likelihood anymore. They were trained to be PPO.  policies. Okay, so probably the most common, or the most, yeah, the most common benchmark or the most trusted one is what we call chatbot arena, which is basically go on internet, have random users on the internet blindly talk with two chatbots, just ask many questions, see the two answers, and rate which one is better, and you do that over 100,000 of users, and then you get the actual preferences and you get rankings of models. So you can go right now on chatbot arena and actually interact with these models. One potential issue just to highlight is that while people who want to do these type of things are usually more like tech driven, or like tech savvy, so a lot of the questions that you will ask are more like tech stuff, discussing software errors, inquiries about AI tools, and all these things. So another issue is cost and speed. If you really want to use something like this for development process, it will be too costly.  you will need to basically pay a lot of humans to do that. So one simple idea is, again, as we said many times, just use LM instead of humans. You probably know the drill at this point. Steps for every instruction generate outputs by some baseline and a model that you want to evaluate. So he imagined that I am comparing an answer from Chad G.P.T. and from Mistro. I'm just asking another model, which one is better? And I just basically averaged that out. Yeah, I asked you, G.P.T. for which one is better. I averaged that out of my entire distribution over my entire benchmark or data set. And that gives me a win rate, so win probability for one model compared to another one. And now you can rank models. And this is the Alpeque-Eval leaderboard. So the benefits of this is that actually we show we get 98% correlation with Chad Baragwina, so very high correlation with humans. So this is...  comparison with correlation with other benchmarks and it takes less than three minutes and less than $10 to run. So it's pretty cheap. There are downsides though. One of them is purist correlation. So as we already saw before, LMS prefer, this is one spurious correlation. Not many. I'll just talk about one. LMS prefer longer outputs. Actually humans also prefer longer outputs but the problem or the issue once you use LMS is that once there is bias you will continue optimizing that. Humans at some point I can guarantee you if I ask a simple question and you give me five pages of answers. I'll be like no I don't like that answer. But LMS if they have this bias and they were trained for that, they will continue preferring longer outputs. So here we see the preference just showing that humans and models prefer longer outputs and here is another view of the initial Apache VAL data set benchmark when when we asked when we rank GPT4 when we look at the run rate of GPT4 versus actually GPT4 itself if we  If we use the standard GPD4, it gets 50% by definition if we're comparing GPD4 versus GPD4. But if we ask a GPD4 to be slightly more verbose, so we just say in the prompt, be verbose in your answers, then it gets a reinway of 64.4%. So really, there's a huge variance. And if you ask it to be concise, it gets 20%. So there's a huge variance depending on whether you ask it to be concise of verbose. That's very annoying. So one possible solution, which is what we did, is just use some regression analysis. I'm not going to go into details, but basically use causal inference tools to control for length. And right now, actually, length matters much less. So if you ask it to be verbose, you still get some gains, but much less. Great. So that's all about post-training. And now for the next eight minutes, might talk about systems or just answer questions. Yes. OK. Go back to your post-training. In terms of post-training, how did we tune those parameters using?  a small body of fine-tuning data and have such big effect on the model. You mentioned earlier that there's a different set of hypergrammers. Are we changing just some of the weights, the later weights or all the weights? What's actually happening? Yeah, I kind of skimmed through all of this. You change all the weights. Actually, industry would change all the weights. In open source land, you might have heard of Laura, which is going to change it basically only some of the weights. Or it actually, to be more specific, it's going to add some differences to the output of every layer. But in industry, you're going to just fine-tune all the weights. Also to say something else about the data, actually this last step, RLHF, you're usually going to collect a lot more data than with SFT. So if SFF 50 is like 5,000, 10,000, maybe 50,000 with RLHF, I think you're going to be more unlike the 1 million, or the magnitude. It's still much less than pre-training though. 15 trillion tokens.  I mean, this is like, that's not even a drop. And then you influence the weight of the wall. So you do it. I mean, you have to think that how you do it is you use, I mean, as I said, the learning way that you're going to use is going to be different. But also, you only do that. So just imagine if I trained, even if I trained on one sentence, but over and over again, at some point in my model will only generate that sentence, even if it was just one sentence instead of the 15 trillion tokens. So if you use a large enough learning rate and for enough time, you will basically overfit that sentence. So the key thing to remember is that the data is not I'd, it's not as if you mix some post-training data and some pre-training data. You do pre-training. And then you just start fine-tuning only on a post-training. So another way, maybe another perspective, is that the pre-training is just an initialization of your model. And once you view it that way, that this is just initialization of weights, then there's nothing special.  You don't need to remember that you trained a lot of data before. The only thing that matters is that you had initialization, and now I actually trained a model. So maybe think about it that way. Like there's a mark of property in some ways. It's just like, you had your weights. This is my initialization. Now I'm training that one. Does that kind of answer your question? Kind of, but you said something just now about it's almost a equivalent of just re-running the fine tuning data many times. Is it actually, is that what actually happens in order to give so much more preference? You might have. I actually don't know right now how they do it in industry. When we did our packet, we had to do three blocks. So you did run it three times to it. But I mean, even the number of times that you run it through, it's actually not important. The only thing is the effective learning rate. That what matters. So yeah. Great. So I think.  five minutes, right? Okay, I might try to give a high level overview, at least from one of the systems trick. Systems, as we said, for everyone, bottleneck is a, sorry, compute is the huge bottleneck. One question you might ask is why not buy more GPUs? GPUs are expensive but also as case, even if you have $10 million right now, you cannot buy the best GPUs. There's also some physical limitations. When you have multiple GPUs, you have to communicate between them. That takes time. So just buying more GPUs is not that easy. So it's really important to think about how do you allocate resources and how do you optimize your pipeline? So system. 101 on GPUs, I'm sorry, I'm going slightly faster. I hope that some of you at least can follow. GPUs are basically optimized for throughput. CPUs are optimized.  for latency. So GPUs, the way you have to think about it is that there's one command that is run on many, many cores at the same time on different type of data. So this is how you see GPU. You see there are many different cores. We call them streaming multi-processes, which is very different than the usual CPU architecture. So just think high throughput, powerization for GPUs. GPUs are optimized for fast matrix multiplication. So every time you will do something on GPU, if you can do it with a matrix multiplication, it's going to be 10 times faster than with anything else. That is a little bit annoying, because it means that we are kind of bottlenecked to doing anything with matrix multiplications. Another thing to note with GPUs is that compute has been improving faster than memory and communication. So right now GPUs usually are hard to keep, like the data that you send at CPUs is actually hard to keep up with.  the process. So most of your GPUs are actually going to be idle if you just run normal code. If you don't optimize your code. So communication and this will continue over time. Another thing to know about GPUs is that there's a memory hierarchy. This is the same thing I actually with CPUs. But basically, the closer you are to your cores, the less memory there is, but the faster things run. If you are further, more memory slower. OK, I'm going to skip that. OK, actually, I'm going to say it. I told you about this defective communication. The metric that people usually look at is model flop utilization. So what is the theoretical maximum that GPU could run at? No more flops that it could use per second. Divide the number of observes through per divided by this theoretical maximum. And in general, if you reach 50%, you're very happy. Like Facebook, I looked at Lama was at 45% for something like this. So that means that data doesn't come fast enough, even for these big companies. So one simple thing.  trick and that might be the only one I'm going to tell you about is low precision. One simple idea is that, well, if I'm going to put my floats in low precision, then there's going to be fewer bits that I have to send to my GPUs. If there's fewer bits, it's faster communication, lower memory consumption, things are going to go faster. And for deep planning, it just happens that decimal is not that important. So when you do matrix multiplication, when you do, like, for example, SGD, it is already so much noise that if you update something by 0.01 or 0.015, who cares? So basically, instead of using 32 bits per float, which is what people use to use, or 64, for example, which is what we would use in other domains, you use 16 bits for matrix multiplication. So for every float, you use 16 bits. And for training, you have this type of, like, what we call automatic mix precision, which is that some of the things are in 32 bits, others are in 16 bits.  Generally, the way you should be thinking about it is that your weights are stored of your model are stored in 32 bits But just before the computation you put everything in 16 16 bits like this you do computation super fast and at the end You update your weights in 32 bits and the reason why you do all the updates in 32 bits It's just think that if you're learning weight for example is very small You still want to be able to like make a difference in your weights So all the computation is done in 16 bits, but the weights are actually stored in 32 bits So that's like the standard way that people are doing it Okay, I'll actually talk just about this and then I'll skip all the rest operate a fusion because I think it's actually pretty cool As I just said communication is very slow and actually every time you use a pie torch line It basically moves variable to global memory of your GPU So when you have something like this X dot cosine Equal X1 and then you do X1 dot cosine what is happening behind the scenes is that you take the X which is data  you ship it to your actual processes of your GPUs. You apply the cosine, you ship it back to the main memory of your GPU, and then you see the next line, you ship it back to the GPU processor, you apply another cosine, and you ship it back again. Another way to see that is that you go from your DRAM which is your global memory in your GPU, and you ship it to compute, you ship it back for every line. This is a naive way of doing it. This seems very wasteful. So the idea, simple idea of operating a fusion is just communicate, do all the computation, ship it backwards. And this is exactly what a few kernels are. So if you ever want to make your computations in PyTorch much faster, just apply torch.com.com on your model. This is going to make your model around two times faster. And what it does is simply that it rewrites your code, your PyTorch code, basically NC++.  in CUDA to do the communication only once, then do all the operations, then ship it back. Okay, I'm not going to have time to talk about tiling. Tiling is important, powerization, powerization is important, and mixture of experts, mixture of experts is important. Outlook, there are many things we haven't talked about. We haven't talked about architectures, we definitely haven't talked about inference. There are many other things that are important with LLMs. What is the UI that you use? I mean, arguably, ChatGPT, the big novelty was just have a simple UI to use it. Multi-modality, what are all the misuses you could have, the fact that they might not be enough data on the internet to train all these models, the quality of data collection, so many other things. If you are interested in all these topics, I would suggest three classes. CS224N is probably the one that touches the least on LLMs, they give some background in historical context of all the LLMs that give kind of some  some at Jason Matillo. CS324, I think it's called, I think it's called large language models. More in-depth reading and lectures on everything I talked about. CS336, which is large language model from scratch, you actually build your own LLM. It's an amazing class, also given by my two supervisors, very heavy workloads, so be careful. Great. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the transcription to a text file\n",
        "output_file = \"transcription.txt\"\n",
        "with open(output_file, \"w\") as file:\n",
        "    file.write(transcription)"
      ],
      "metadata": {
        "id": "a1f3fht9d9tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "bwFrFPibe5bx",
        "outputId": "e8903408-be34-4538-8e98-bcf66317915d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" So let's get started. So I'll be talking about building LLMS today. So I think a lot of you have heard of LLMS before. But just as a quick recap, LLMS, standing for large language models are basically all the chat bots that you've been hearing about recently. So Chad GPT from OpenAI, Cloud, from UnTropic, Gemini, and Lama and other type of models like this. And today we'll be talking about how do they actually work. So it's going to be an overview, because it's only one lecture, and it's hard to compress everything. But hopefully, I'll touch a little bit about all the components that are needed to train some of these LLMS. Also, if you have questions, please interrupt me and ask. If you have a question, most likely, other people in the room or on Zoom have the same question. So please ask. Great. So what matters when training LLMS?  So there are a few key components that matter. One is the architecture. So as you probably all know, LMs are neural networks. And when you think about neural networks, you have to think about what architecture you're using. And another component which is really important is the training loss and the training algorithm. So how you actually train these models, then it's data. So what do you train these models on? The evaluation, which is how do you know whether you're actually making progress towards the goal of LLMs? And then the system component. So that is like how do you actually make these models run on modern hardware, which is really important because these models are really large. So now more than ever, systems are actually really an important topic for LLMs. So those five components, you probably all know that LLMs, and if you don't know, LMs are all based on transformers, or at least some version of transformers. I'm actually not going to talk about the architecture.  today, one because I gave us here a lecture on transformers a few weeks ago, and two because you can find so much information online on transformers. But I think it's, there's much less information about the other four topics. I really want to talk about those. Another thing to say is that most of academia actually focuses on architecture and training algorithm and losses. As academics, and I've done that for a lot, big part of my career is simply, we like thinking that this is like we make new architectures, new models, and it seems like it's very important. But in reality, honestly, what matters in practice is mostly the three other topics. So data of evaluation and systems, which is one of most of industry actually focuses on. So that's also one of the reasons why I don't want to talk too much about architecture, because really the rest is super important. Great. So overview of the lecture, I'll be talking about pre-training. So pre-training, you probably...  heard that word, this is the general word, this is kind of the classical language modeling paradigm, where you basically train a language model to essentially model all of internet. And then there's a post training, which is a more recent paradigm, which is taking these large language models and making them essentially AI assistants. So this is more of a recent trend since ChatGPT. So if you ever heard of GPT-3 or GPT-2, that's really pre-training land. If you heard of ChatGPT, which you probably have, this is really post training land. So we talk about both, but I'll start with pre-training. And specifically, I'll talk about what is the task of pre-training LMS and what is the laws that people will actually use. So language modeling, this is a quick recap. Language models at a high level are simply models of probability distribution over sequences of tokens or words. So it's basically some model of P of X1 to Excel, where X1 is basically word wanted.  Excel is the last word in the sequence or in the sentence. So very concretely, if you have a sentence like the mouse, eight of the cheese, what the language model gives you is simply a probability of this sentence being uttered by a human or being found online. So if you have another sentence like the mouse, eight cheese, here there's grammatical mistakes. So the model should have some syntactic knowledge. So it should know that this has less likelihood of appearing online. If you have another sentence like the cheese, eight, the mouse, then the model should hopefully know about the fact that usually cheese don't eat mouse. So there's some semantic knowledge, and this is less likely to be the first sentence. So this is basically at a high level what language models are. One word that you've probably have been hearing a lot in the news are generative models. So this is just something that can generate models, that can generate sentences or can generate some data. The reason.  So what we know why we say language models are genitive models is that once you have a model of a distribution, you can simply sample from this model and then we can generate data. So you can generate sentences using a language model. So the type of models that people are all currently using are what we call autoregressive language models. And the key idea of autoregressive language models is that you take this distribution over words and you basically decompose it into the distribution of the first word, multiply it by the distribution of the likelihood of the second word, given the first word, multiply it by P of the third word, given the first two words. So there's no approximation here. This is just a chain rule of probability, which you hopefully all know about. Really no approximation. This is just one way of modeling a distribution. So slightly more concisely, you can write it as a product of P's of the next word, given everything which happened in the past, so of the context.  So this is what we call autoregressive language models. Again, this is really not the only way of modeling distribution. This is just one way. It has some benefits and some downsides. One downside of autoregressive language models is that when you actually sample from this autoregressive language model, you basically have a full loop, which generates the next word, then conditions on that next word, and then regenerate in other words. So basically, if you have a longer sentence that you want to generate, it takes more time to generate it. So there are some downsides of this current paradigm, but that's what we currently have. So I'm going to talk about this one. Great. So autoregressive language models. At a high level, what the task of autoregressive language model is is simply predicting the next word, as I just said. So if you have a sentence like she likely prefers one potential next word, it might be dogs. And the way we do it is that we first tokenize. So you take these words or sub words. You tokenize them. And then you give an ID.  for each token. So here I have one, two, three. Then you pass it through this black box, as I already said. We're not going to talk about the architecture. You just pass it through a model. And you then get a distribution, a probability distribution, over the next word, or over the next token. And then you sample from this distribution, you get a new token. And then you detokenize. So you get a new ID. You get detokenize. And that's how you basically sample from a language model. One thing which is important to note is that the last two steps are actually only needed during inference. When you do training, you just need to predict the most likely token. And you can just compare to the real token, which happened in practice. And then you basically change the weights of your model to increase the probability of generating that token. Great. So our progressive neural language models. So to be slightly more specific, still, without talking about the architecture, the first thing we do is that we have all of these. Yes.  So here, predicting the probability of the next token. So this may be that your final output vector has to be the same dimensionality as the number of tokens that you have. Yes. How do you deal with like, if you have more to increase adding more tokens to your tokens? Is it a private sample? Yeah. So we're going to talk about tokenization actually later. So you will get some sense of this. You basically can deal with adding new tokens. I'm kind of exaggerating. There are methods for doing it, but essentially people don't do it. So it's really important to think about how you tokenize your text, and that's why we'll talk about that later. But it's a very good point to notice that you basically the vocabulary size to the number of tokens that you have is essentially the output of your language model. So it's actually pretty large. OK. So autoregressive new language models. First thing you do is that you take every word or every token. You embed them. So you get some vector representation for each of these tokens. You pass them through some neural network.  we said it's the transformer, then you get a representation for all the words in the context. So it's basically representation of the entire sentence. You pass it through a linear layer, as you just said, to basically map it to the number so that the output, the number of outputs is the number of tokens. You then pass it through some softmax and you basically get probability distribution over the next words, given every word in the context. And the last that you use is basically, it's essentially a task of classifying the next token. So it's a very simple kind of machine learning task. So you use the cross-central P loss where you basically look at the actual target that happened, which is a target distribution, which is a one-hot encoding, which here in this case says, I saw the real one that happened is cat. So one-hot distribution over cat. And here this is the actual, do you see my mouse? Oh yeah, this is the distribution that you generate.  generated and we see you do cross entropy which really just increases the probability of generating cat and decreases all the The probability of generating all the other tokens one thing to notice is that as you all know again This is just equivalent to maximizing the text log like the text log likelihood because you can just rewrite the Max over the probability of This autogressive language modeling task as just being this minimum over I just added the log here and Minus which is just the minimum of the loss which is the cross entropy loss so basically minimizing the loss is the same thing as Maximizing the likelihood of your text any question questions Okay tokenizer So this is one thing that people usually don't talk that much about tokenizers are extremely important So it's really important that you kind of understand at least what they do at a high level so why do we need tokenizers in the first place  First, it's more general than words. So one simple thing that you might think is, oh, we're just going to take every word that we will have, you just say every word is a token in its own. But then what happens is if there's a typo in your word, then you might not have any token associated with this word with a typo, and then you don't know how to actually pass this word with a typo into a large language model. So what do you do next? And also, even if you think about words, words is a very, like words are fine with Latin-based languages. But if you think about a language like Thai, you won't have a simple way of tokenizing by spaces because there are no spaces between words. So really tokens are much more general than words. First thing, the second thing that you might think is that you might tokenize every sentence character by character. You might say, A is one token, B is another token. That would actually work and probably very well. The issue is that then your sequence becomes super long. And as you probably remember from...  the lecture on transformers, the complexity grows quadratically with the length of sequences. So you really don't want to have a super long sequence. So tokenizers basically try to deal with those two problems and give common sub sequences a certain token. And usually how you should be thinking about is around an average of every token is around three, four letters. And there are many algorithms for tokenization. I'll just talk about one of them to give you a high level, which is what we call byte-paying coding, which is actually pretty common, one of the two most common tokenizers. And the way that you train a tokenizer is that first you start with a very large corpus of text. And here I'm really not talking about training a large language model yet. This is purely for the tokenization step. So this is my large corpus of text with these five words. And then you associate every character in this corpus of text, different token. So here I just split it up.  character with a different token and I just call it all of those tokens. And then what you do is that you go through your text and every time you see pairs of tokens that are very common, the most common pair of token, you just merge them. So here you see three times the tokens T and O next to each other. So you're just gonna say this is a new token and then you continue, you repeat that. So now you have T okay, talk, which happens three times, talk with an E that happens, sorry, two times, and token, which happens twice and an EX, which also happened twice. So this is that if you were to train a tokenizer on this corpus of text, which is very small, that's how you would finish with a token with a treat like a trained tokenizer. In reality, you do it on on much larger corpus of text. And this is the real tokenizer of actually I think this is GPT3 or CHGPD. And here you see how it would actually separate these  words. So basically you see the same thing as what we gave in the previous example. Token becomes its own token. So tokenizer is actually split up into two tokens. Token andizer. So yeah, that's all about tokenizers. Any question on that? Yeah. Yeah. Yeah. So actually there's a step before tokenizers, which is what we call pre tokenizers, which is exactly what you just said. So this is mostly in theory, there's no reason to deal with spaces and punctuation separately. You could just say every space gets its own token, every punctuation gets its own token, and you could just do all the merging. The problem is that so there's an efficiency question. Actually training these tokenizers takes a long time. So you're better because you have to consider every pair of token. So what you end up doing is saying if there's a space, this is very like pre tokenizers are very English specific. You say if there's a space, we're not going to start looking at  the token that came before and the token that came afterwards. So you're not merging in between spaces. But this is just like a computation optimization. You could theoretically just deal with it the same way as you do with any other character. Yeah. When you merge tokens to the top, the tokens that you merged are very at the same height as the smaller token. You actually keep the smaller tokens. I mean, in reality, it doesn't matter much because usually on large corpus of text, you will have actually everything. But you usually keep the small ones. And the reason why you want to do that is because if, in case there's a, as we said before, you have some grammatical mistakes or some typos, you still want to be able to represent these words by character. So yeah. Yes. Yes. Are the tokens unique? So I mean, say in this case, T-O-K-E-N, is there only one occurrence so that you need to need multiple occurrence so they can have it?  Take on different meetings, you see? Oh, I see what you would say. No, it's every token has its own unique ID. So this is a great question. For example, if you think about bank, which could be bank for money or bank like water, it will have the same token. But the model will learn, the transformer will learn that based on the words that are around it, it will should associate that. I'm saying I'm being very hindrower of you here, but associate that with a representation that is either more like the bank money side or the bank water side. But that's the transformer that does that. It's not a tokenizer. Yes? Yes, we mentioned during tokenization, too, there's smaller tokens. It's not that we're trying to say. Like, we just have it at the T, we keep the T, and then you don't need to tokenize out to the external icon out and tokenize it. So let's say maybe you didn't even tokenize it like in your data, you are trying to encode token. So how does the tokenizer know to code it with token or to react? Yes.  The great question, you basically, when you tokenize, so that's after training of the tokenizer, when you actually apply to tokenizer, you basically always choose the largest token that you can apply. So if you can do token, you will never do T, you will always do token. But there's actually, so people don't really talk that much about tokenizers, but there's a lot of computational benefits or computational tricks that you can do for making these things faster. So I really don't think we, and honestly, I think a lot of people think that we should just get away from tokenizers and just kind of tokenize character by character or bytes by bytes. But as I said right now, it's this issue of length. But maybe one day, like in five or 10 years, we'll have different architectures that don't scale credetically with the length of the sequence and maybe we'll move away from tokenizers. So are you sure with us the drawback? Why do you give people one and move away from the tokenizer? Oh, yeah. So think.  One good example is math. If you think about math, actually numbers right now are not tokenized. So for example, 327 might have its own token, which means that models, when they see numbers, they don't see them the same way as we do. And this is very annoying because the reason why we can kind of generalize with math is because we can deal with every letter separately and we can then do composition, where you know that basically if you add stuff, it's just the same thing as adding every one separately plus whatever the unit that you add. So they can do that. So then you have to do like special tokenization. And like one of the big changes that GPT forwarded is changed the way that they tokenize code. So for example, if you have code, you know you have often in Python these four spaces at the beginning, those were dealt with kind of strangely before. And as a result, the model couldn't really understand how to deal with code. So tokenization actually matters a lot.  Okay, so I'll move on right now, but we can come back later on tokenizers. Great. So we talked about the task, the last tokenizer. Let's talk a little bit about evaluation. So the way that LLMs are usually evaluated is what we call, is using what we call Poplexity. At a high level, it's basically just your validation loss. The slight difference with Poplexity is that we use something that is slightly more vulnerable, which is that we use the average per token loss, and then you exponentiate it. And the reason why you exponentiate it is because you want, I mean, the loss has a log inside, and you, like, one human's are actually pretty bad at thinking in log space, but two logs depend on the base of the log. While when you exponentiate, you basically have everything in the kind of the vocabulary size unit. And the average for token is just so that your Poplexity is independent of the length of your sequence. So Poplexity is just too to the power average of the loss of the sequence.  So, perplexity is between one and the length of the vocabulary of your tokenizer. One, it's simply, well, if you predict perfectly the thing which every word, then every word will have basically product of ones. So, the best perplexity you can have is one. If you really have no idea, you basically predict with one divided by size of vocabulary, and then you do simple math and you basically get perplexity of size of vocabulary. So, then tuition of perplexity is that it's basically the number of tokens that you're model is kind of hesitating between. So, if you're model is perfect, it doesn't hesitate, it no exactly the word. If it really has no idea, then it hesitates between all of the vocabulary. So, perplexity really improved. That's perplexity on a standard data set between 2017 and 2023. It went from a kind of 70 tokens to less than 10 tokens over these five six years. So, that means that the models were previously as dated between 70.  words every time it was generating a word and now it's as dating between like less than 10 words. So that's much better. But complexity is actually not used anymore in academic benchmarking. More sick is it depends on the tokenizer that you use. It depends on the actual data that people are evaluating on. But it's still very important for development of LLMs. So when you actually train your own LLM, people will still really look at the complexity. One common other way and now more common in academia of evaluating these LLMs is just by taking all the classical NLP benchmarks. And I'll give you a few examples later and just kind of aggregating everything. So collect as many automatically evaluable benchmarks and just evaluate across all of them. So one such or actually two such benchmarks of what we call Helm which is from Stanford. Another one is the hugging face open LLM lead award which are probably two most common ones right now.  So just to give you an idea in how they are all of these type of tasks, which are mostly things that can be easily evaluated like question answering. So think about many different question answering tasks. The benefit with question answering is that you usually know what is the real answer. So you can the way that you evaluate these models, I'll give you a concrete example in one second, is that you can just look at how likely the language model is to generate the real answer compared to some other answers. And that's essentially at a high level how you evaluate these models. So to give you a specific example, MMLU is probably the most common academic benchmark for LMS. And this is just a collection of many question and answers in all of those domains. For example, college, medicine, college physics, astronomy, and these type of topics. And the questions are things like, so this is an astronomy. What is true for type 1a supernova, then you give 4.  different potential answers and you just ask the model which one is more likely. So there are many different ways of doing it. Either you can look at the likelihood of generating all these answers or you can ask the model which one is the most likely. So there are different ways that you can prompt the model but at a high level you know which one is correct and there are three other mistakes. Yes. Creating is like unconstrained text that's not funny. Yeah. How do you do a down-to-the-model? It gives something that's you know semantically completely identical but is not the exact totalist that you expect. Yeah so that's a great question. I'll talk more about that later. Here in this case we don't do unconstrained. So the way you would evaluate MMLU is basically either you look you as the first question and then you look at the likelihood of the model generating A, the likelihood of the model generating B, C and D and you look at which one is the most likely. Oh you can ask the model out of ABCD which one is the most likely and you look at the model.  look at what the most like in extokin is a b c o d. So you can stream the model to say it can only answer these four things. Can you say you can stream the model? Yeah. You can stream it with the prompt or do you mean of its whole probability distribution there outfits? You're only comparing the outfits up like you're only comparing the A-tunkin. Yeah. So in the second case I gave you, you would do exactly the, I will actually you would do both. In the first model saying a b c o d plus you would consume to only look at these four tokens. In the first case you don't even need to generate anything. So in the first case you literally just look given it's a language model. It can give a distribution over sentences. You just look at what is the likelihood of generating all of these words. What is the likelihood of generating the second choice? And you just look at whether the most likely sentence is actually the real answer. So if you're actually sample from it you really just use p of x1 to xl. Does that make sense?  sense? That being said, evaluation of open-ended questions is something we're going to talk about later and it's actually really important and really challenging. Yes? Earlier I mentioned that metrics like complexity are not usually used because it depends on how you do it. Some design choices, I also want to speak more to that. Oh, yeah. So, think about complexity. I told you, complexity is between one and vocabulary size. So now I imagine that ChatGPT uses a tokenizer that has like 10,000 tokens, but Gemini from Google uses a tokenizer that had 100,000 potential tokens. Then actually the Gemini one will have like the upper bound of the the complexity that you can get is actually worse for Gemini than for ChatGPT. Does that make sense? So that's just an idea. It's actually a little bit more complicated now, but there's just like one first or the bit of where you can see that the tokenizer.  actually matters. Great. OK, so evaluation challenges. There are many. I'll just talk about two really briefly. One, as I told you, there are two ways of doing evaluation for these MML views. Actually, there are many more than two, but I give you two examples. And it happens that for a long time, even though that was a very classical benchmark, that everyone used actually different companies and different organization were actually using different ways of evaluating MML view. And as a result, you get completely different results. For example, LAMAS 65B, which was the first model of meta in the LAMAS series, had on helm 63.7 accuracy, but on this other benchmark had like 48.8. So really, the way that you evaluate, and this is not even talking about prompting, this is really just kind of the way that you evaluate.  the models. Promoting is another issue. So really there are a lot of inconsistencies. It's not as easy as it looks. First thing, yeah, sorry. How do we make sure that all these models aren't trained on the bench model? Okay, second thing. This is a great question. Train test contamination. This is something which I would say is really important in academia. In, given that the talk is mostly about training large language models, for companies it's maybe not that important because they know what they trained on. For us, we have no idea. So far, it's a real problem. So there are many different ways of trying to test set, sorry, whether the test set was actually in the training set. One kind of cut trick that people in the lab, in Tetsu's lab have found is that what you can do is that given that most of the data set online are not randomized, you can just look at  And in that language models what they do is just predict the next word. You can just look at the entire test set. What if you generate all the examples in order versus all the examples in a different order? And if it's more likely to generate the thing in order given that there's no real order there, then it means that probably was in the training set. Does that make sense? So there are many, that's like one of them. There are many other ways of doing it. Train test contamination, again, not that important for development, really important for academic benchmarking. Great. So there are many other challenges, but I'll move on for now. Great. Data. So data is another really big topic. At a high level people just say, oh, you basically train large language models on all of internet. What does that even mean? So people sometimes say all of clean internet, which is even less fun. So internet is very dirty and really not representative of what we were.  one in practice. If I download a random website right now, you would be shocked at what is in there. It's definitely not your Wikipedia. So I'll go really briefly on what people do. I can answer some questions, but data is on its own. It's a huge topic. Basically, first, what you do is download all of internet. What that means is that you use web crawlers that will go on every web page on internet, or every web page that is on Google. And that is around 250 billion pages right now. And that's around one petabyte of data. So this is actually a common crawl is one web crawler. So people will usually write their own web crawlers. What they do is that they use standard web crawlers. And a common crawl is one of them that basically every month adds all the new websites that were added on internet are found by Google. And they put it in a big, basically a big data set.  So that's on Common Quall you have around 250 billion pages right now. So 1 e6 gigabytes of data. Once you have this, so this is a random web page, like literally random from this Common Quall. What you see is I'm one and really doesn't look at the type of things that you would usually see. But actually, so this is an HTML page. It's hard to see, but if you look through, you will see some content. For example, here, test King World is your ultimate source for the system X-high performance server, and then you have three dots. So you don't even, the sentence is not even finished. That's how a random internet looks like. So of course, it's not that useful if you just train a large language model to generate things like this. So what are some of the steps that I needed? First one, you extract the text from the HTML. So that's what I just tried to do by looking at basically the correct text. There are a lot of challenges by this. For example, extracting math is actually very common.  complicated, but pretty important for training large language models. Or for example boilerplates, a lot of your forums will have the same type of headers, the same type of footers. You don't want to repeat all of this in your data. Then you will filter undesirable content. So not safe for work, harmful content, PII. So usually every company has basically as a blacklist of websites that they don't want to train their models on. That blacklist is very long. And you basically say, if it comes from there, we don't train on this. There are other ways of doing these things is that you can train a small model for classifying what is PII, removing these things. It's hard. Every point here that I'm going to show you is like a hard amount of work. But I'm going to go quickly through it. So filter undesirable content. Second or fourth is the duplication. As I said, you might have things like headers and footers in forums that are always the same.  want to remove that. Another thing that you might have is a lot of URLs that are different, but actually show the same website. And you might also have a lot of paragraphs that come from common books that are basically de-doubligated a thousand times or 10,000 times on internet. So you need to have to de-doubligate also very challenging because you have to do that at scale. Once you do de-doubligation, you will do some heuristic filtering. You will try to remove low-quality documents. The way you do that are things like rules-based filtering. For example, if you see that there are some outlier tokens. If the distribution of tokens in the website is very different than the usual distribution of tokens, then it's probably some outlier. If you see that the length of the words in this website is super long, there's something strange going on on that website. If you see that the website has only three words, maybe is it worth training on it? Maybe not. If it has 10 million words, maybe there's something also wrong going on that page.  So a lot of rules like this, yes? What are our undesirable content from our data set instead of kind of... ...it's like a supervised mass. Can we not just say like, here's this hate speech website that's actively trying to... ...but to actively penalize them up for data. We'll do exactly that, but not at this step. That's where the post training will come from. Pre-training, the idea is just to say, I want to model kind of how humans speak, essentially. And I want to remove all these like, headers, photos and menus and things like this. But it's a very good, like, idea that you just had in it. That's exactly what we'll do later. Next step, model base field training. So once you've filtered a lot of data, what you will do... ...and that's actually a very cute trick. You will take all of Wikipedia and you will look at all the links... ...that are linked through Wikipedia pages. Because probably if something is...  by Wikipedia, it's probably some high-quality website. And you will train a classifier to predict whether something comes from, whether a document comes from one of these references from Wikipedia, or whether it's from the random web. And you will try to basically say, I want more of the things that come from Wikipedia references. Does that make sense? So yeah, so you will train a machine learning model. Usually also very simple models, because you need to do that really at scale. I mean, just think about the 250 billion pages. Next one, you will try to classify your data into different domains. You will say, OK, this is entertainment, this is books, this is code, this is like these type of domains. And then you will try to either up or downweight some of the domains. For example, you might say, you might see that actually, if you train more on code, then actually your model becomes better on reasoning. So that's something that people...  people usually say in a very hand-waver way, if you train your model on code, actually it helps reasoning. So you want to up-weight the coding distribution because that helps for general language modeling skills. Books is usually also another one that people usually up-weight. Entertainment, they usually down-weight. So things like this. Of course you want to do it, so people used to do it maybe kind of heuristically. Now there's entire pipelines that we'll talk about of how to do these things slightly more automatically. And then at the end of training, usually training on all of this data that we saw, usually train on very high-quality data at the end of training your large language model, where you decrease your learning rate. And that basically means that you're kind of overfitting your model on a very high-quality data. So usually what you do there is like Wikipedia. You basically overfit on Wikipedia. And you overfit on like...  human data that was collected. The other thing is like, continue pre-training, forgetting longer context. I'm going to skip over all of these things. But I just to give you a sense of how hard it is when people just say, oh, I'm going to train on internet, that's a lot of work. Really, we haven't figured it out yet. So collecting well data is a huge part of practical large language model. Some might say it's actually the key. Yes. No more data. So there's a question. So usually you would install the term, where I write on data. After I go to your master's suppose it's a typical amount of you that you have been in. And then how large it seems that it's a big deal to go through all the data steps you took out. So is a question, how large is the data after you filter? Yes, so you feel that it's good to go through. How large it seems you need to go through the field, the order of future systems. How slow is it? How many people would you need? Oh.  What are you going to do this video? OK, that's a great question. I'm going to somewhat answer about the data, how large is the dataset at the end of this slide, for number of people that work on it. That's a great question. I'm actually not quite sure, but I would say, yeah, I actually don't quite know, but I would say it's probably even bigger than number of people that work on kind of the tuning of the pre-training of the model. So the data is bigger than kind of the modeling aspect. Yeah, I don't think I have a good sense. I would say probably in Lama's team, which have like 70 HP, people I would say maybe 15 work on data. Yeah. All these things, you don't need that many people. You need a lot of computer also, because for data, you need a lot of CPUs. So yeah, and I'll answer the second question at the end of this slide. So as I just kind of alluded to, really, we  have installed data at all for pre-training. So there's a lot of research that has to be done. First, how do you process these things super efficiently? Second, how do you balance all of these different domains? Can you do synthetic data generation? That's actually a big one right now. Because we don't have, we'll talk about that later, we don't have enough data on the internet. Can you use multimodal data instead of just text data? And how does that improve even your text performance? There's a lot of secrecy. Because really, this is the key of most of the pre-trained large language models. So for competitive dynamics, usually these companies don't talk about how they do the data collection. And also, there's a copyright liability issue. They definitely don't want to tell you that they've trained on books even though they did, because if not, you can sue them. Common academic benchmarks. So that will kind of answer what you asked. So those are the smaller ones. The names are not that important, but it you decide from a head-  around 150 billion tokens, which are around 800 gigabytes of data. And now it's around 15 trillion tokens, which is also the size of the models that are, right now the best models are probably trained on that amount of data. So 15 trillion tokens, which is probably, I guess, two more to my bigger than that. So 80 E3 gigabyte. So that would be around 100 to 1000 times the filtering of the common crawl, if I'm not mistaken. So yeah, one very famous one is the pile. So this is an academic benchmark of the pile. And we can just look at what distribution of the data they have. It sings like archive, PubMed Central, which is all the biology stuff. Here it's Wikipedia. You see stack exchange, some GitHub, and some books, and things like this. Again, this is on the smaller side.  So this is, if we look at here, this is on 280B. So in reality, it's like 100 times bigger. So you cannot have that much of GitHub and on Wikipedia. In terms of closed source models, just to give you an idea, Lamat 2, it was trained on two trillion tokens. Lamat 3, 15 trillion tokens, which is currently the best model that we know on how much it was trained on, which is the same thing as the best academic, or the biggest academic benchmark, which is 15 trillion tokens. In the GPD 4, we don't really know, but it's probably in the same order of magnitude. Or it's probably around that, actually, it's probably around 13 from leaks, if the leaks are true. Great. So scaling loss, any other questions on data before you go to scaling loss? Sorry, I know I'm giving you a lot of information, but there's a lot into training and large language models. Great. Scaling loss. So the idea is that what people saw,  around 2020 or at least from a long time, but they've been able to kind of theoretically show it or impurity show it since 2020 is that the more data you train your models on and the larger the models, the better the performance. This is actually pretty different than what you've seen in this class. In this class, we teach you about overfitting. Overfitting doesn't happen with large language models. Larger models, better performance. It's something that really took a long time for the community who took this type of class to realize. But for the exam, overfitting exists. So, okay, the idea of scaling loss is that if given that you know that more data and larger models will always give you better performance, can we predict how much better your performance will be if you increase the amount of data and the size of your model? And surprisingly, it works. So here you see three plus from a very famous paper called scaling loss from OpenAI. Here you see on the x-axis compute.  So how much did you train, like, how much compute that you spent for training? And here you see test loss. So this is essentially, I mean, some perplexity, but it's your validation loss. So it's a log of the perplexity. And if you put these two on log scale, then you see that the performance, like the, sorry, the scaling law is linear. That means that if you increase your compute by a certain amount, you can say by how much your test loss will actually decrease. Same thing with data and same thing for parameters. If you increase the data set size, your loss will decrease by an amount that is somewhat predictable. If you increase the number of parameters, it will decrease, the loss will decrease by a amount which is somewhat predictable. This is really amazing, very surprising. I mean, it looks innocuous when you look at these type of plots, but that's crazy because it means that you can predict how well we're going to perform in two, three years, depending on how much compute we will add.  assuming that these things will hold. There's nothing theoretical about it. Yes? What is the loss of the user here as a proplexity? So I said proplexity was like 2 to the power of the loss. So this is the power of the proplexity. And the second thing is, when you don't increase the number of parameters, so you increase the total data set size and the number of the application. Time doesn't that just increase your compute? So all of this work is not just how many. You do data? Oh, yes. No, this is a great question. So the compute here is actually a factor of two things. The data and the parameter. What I'm showing here is that you can, well, actually, we're going to talk about that in details. But basically, if you increase the number of parameters, you should increase the number of data that you have. So you actually don't go multiple times through the same data set. No one does epochs at least not yet, because we haven't still kind of enough data.  So yeah, this is all the same trend which is increased compute decreased loss. Yes. Have we seen the numbers for the last two years? Or is it still holding? It is still holding. I don't have like good numbers to show you, but it is still holding, surprisingly. Yes. Is there a draw evidence like a procoevent that you've never thought of? But you can't draw it with expected value, right? No empirical evidence of plateauing any time soon. Why? We don't know. Well, it happened. Probably. I mean, it doesn't need to because it's actually in log scale. So it's not like as if it had to go, it had to plateau like mathematically. It could continue decreasing like this. I mean, most people think that it will probably plateau at some point. We don't know when. Okay, so that's, I will talk more about scaling loss now. So why are scaling loss really cool?  Imagine that I give you, you're very fortunate, I give you 10,000 GPUs for this month. What model will you train? How do you even go about answering that question? I mean, this is a hypothetical, but that's exactly what these companies are faced with. The old pipeline, which was basically two high parameters on the big models. So let's say I have 30 days, I will train 30 models for one day, each I will pick the best one, and that will be the final model that I will use in production. That means that the model that I actually used was only trained for one day. The new pipeline is that you first find a scaling recipe. So you find something that tells you, for example, one common thing is that if you increase the size of your model, you should decrease your learning rate. So you find a scaling recipe such that you know, if I increase the size of my model, here's what I should do with some high parameters, then you tune your high parameters on smaller models of different sizes.  Let's say I will say for three days of my 30 days I will train many different models and I will do high-preparameter tuning on these small models each of different sizes Then I will fit a scaling law and try to extrapolate from these smaller models Which one will be the best if I if I train it for much longer? Oh, sorry if I train it for a larger model and Then I will train the final huge model for 27 days instead of just one day So the new pipeline is not train things or do high-preparameter tuning on the real scale of the model that you're going to use in practice But do things on smaller ones At different scales try to predict how well they will perform once you make them bigger I will give that I will give you a very concrete example right now Let's say transformers versus LSTMs and let's say you're you have you's 10,000 GPUs You're not sure which one you should be using should I be using transformable base model and an SCM base model What I will do is I will train transformers at different scales  So here you see different parameters on the x-axis, y-axis is my test source. I will then show you different LSTMs at different scales. Once I have these points, I will see, oh, it kind of fits a scaling law. I will fit my scaling law, and then I will be able to predict, oh, if I had 10 times more compute, here's how well I would perform for the LSTM. It's actually slightly less linear for the LSTM, but like you could probably try to predict where you would end up. And clearly from this plot, you would see that transformers are better. One thing to notice when you read these types of scaling laws is that there are two things that are important. One is really your scaling rate, which is kind of the slope of the scaling law. The other thing is your intercept. Like you could start worse, but actually become better over time. It just happens that LSTMs are worse for both. But I could show you another one where things you can predict that actually...  like after certain scale you're better off using that type of model than others. So that's why scaling laws are actually really useful. Any questions on that? Yeah. So these are all kind of very, how sensitive art is to like small difference in architecture like one light transfer of architecture versus another transfer of architecture? You basically have to like pick your own curve and basically say like, oh, scaling does tell you that should be some like logarithmic function. Yeah. Yeah. So usually for example, if you're an academic and you want to now at least that's like pretty recent and you want to propose a new like activation, that's exactly what you will do. You will fit a scaling law, show another scaling law with the standard like I don't know Gailu and you will say that it's better. In reality, once you start thinking about it in scaling laws terms, you really realize that actually all the architecture differences that we can make like the small minor ones, all they do is maybe...  We changed a little bit the intercept, but really that doesn't matter. Just train it for 10 hours longer or wait for the next GPUs and these things are really secondary. Exactly why I was telling you originally people spend too much time on the architecture and losses in reality these things don't matter as much. Data though, if you use good data, you will have much better scaling loss than if you use bad data. That really matters. Another really cool thing you can do with scaling loss is that you can ask yourself how to optimally allocate training resources. Should I train larger models? Because we thought it's better when you train larger models, but we thought it's also better when you use more data. Which one should I do? Should I just train on more data, a smaller model or should I train a larger model on less data? So Chintilla is a very famous paper that first showed this. The way they did it, I want to give you a little bit of a sense of what these plots are. Here you see training loss again.  On the x-axis, you see parameter differences, as sorry, number of parameters, so the size of the model. And here, all these curves are what we call isoflops, which is that all the models on this curve have been trained with the same amount of compute. The way that you do that is that you change, so you vary the number of tokens that we're trained on, and the size of the models. But you vary in such a way that a total compute is constant. So all these curves that you see with different colors have different amount of compute that we're trained on. Then you take the best one for each of those curves. Once you have the best one for each of those curves, you can plot how much flops it was, and on which curve were you on, and how much parameters did you actually use for training that specific point? You put that on the log log scale again, and now you fit a scaling log again. So now I have something which tells me if-  If I want to train a model of 10 to the power 23 flops, here's exactly the number of parameters that I should be using, 100 B. And you can do the same thing with flops and tokens. So now you can predict if I tell you exactly, I have one month of compute. What size of model should I be training? Figure scaling law, and I tell you. Of course, that all looks beautiful. In reality, there's a lot of small things of, should you be counting embedding parameters. There's a lot of complexities. But if you do things well, these things actually do hold. So the optimal number of parameters that Shinchilla people have found is to use 20 tokens for every parameter that you train. So if you add one more parameter, you should train your thing on your model on 20 more tokens. So one caveat here is that this is optimal training resources. So that is telling me, if you have 10 to the power 23 flops, or if you have like 100, I don't know how much that is. 100 million.  $5 million or $10, no, that would smudge less actually. I'd say I have $5 million to train my best model that gets the lowest loss. What would I train on? In reality, these companies need to think about inference also. If you have a smaller model, they will spend less over time. So actually, if you consider the inference cost, you have other papers that try to show that. It's around 150 parameters, sorry, tokens per parameters. Because you prefer having a smaller model, because over time, you're going to actually spend less money on inference of these models. So 150 to one, that's around what the best models are trained on right now. At least the ones that are used in practice in production. Great. Any question on Chichol? Great. I'm sorry. How expensive is it?  or it's really small and it's really good to train. Actually, very expensive. I will not talk about it first, because that would be another entire lecture. But just think about Chat GPT. When they have, I don't know how much it is now, like 600 million people that use it. Like, that's a lot. So it's actually very expensive. There's a lot of optimization you can do for inference, though. And that's an entire other lecture. So I'm going to skip that this time. But it's very interesting. OK, two things. As I said, there are many things that you can answer with scaling loss. I just try to give you two examples, but really there are many things. What data do you use? What mixer? What data mixing? Waiting? You use the data mixers. That's what we talked about before. What architecture you use? Whether you should make your models wider or deeper. Should you be paying for more GPUs? Or actually collecting more data? All these things are things.  you can try to answer with scaling loss. One thing I want to say is the bitter lesson. If you ever heard of Richard Sutton, a very famous blog post in 2019, what he realized, which I think not enough people realized, I didn't definitely did not realize at that time, is that once you see these type of scaling loss, you know that the more compute you have, the better models you will get. So with scale, you will get better model. And you also know by Mozilla or these type of variants of Mozilla, that you will always have better compute. Then the only thing that matters is just to have architectures that can leverage computation. So what matters is basically systems, data, and less so the architecture, like the small architecture differences like your activation and things like this. So I think that's one of the reasons why most of research focuses on some things that for industry matters less. And I was one of those researchers for a large part of me.  My career. So don't spend time over-complicating. Do you do the simple things? Do it well, seal them. That's really what OpenAI taught us with ChatGPT and with all the GPs before. OK, I want to give you some back-of-the-envelope computations. So I might be off by a few factors here, but I just want to give you a sense of how costly it is to train some of these models. I'll give as an example, a Lamat 300B, which is currently the best open source model that you can get. It was trained on 15.6 tokens. It has 405 billion parameters. So just now that you know what is like this optimal tokens parameter, that's around 40. So that's a little bit more than Chinchilla, but less than this inference optimal model. So they went for training optimality. Flops for this model. So one simple way to compute flops is six times the number.  of parameters times the number of data that you train on. So if you do the simple calculation here, it's 3.8E25 flops. The reason why this is important is that if you follow the little bit of the news, there's an executive order from Biden that basically says I want you have 1E26 parameters, sorry, flops, then you have special scrutiny on your models. So they went 2x less than that. So they really went right below this to not have special scrutiny. So 3, 8, I might be off by a little bit, but it's definitely under the 1E26. So P is parameters, N is data, number of tokens. This is just an approximation. Yeah. Okay, compute, we know that they train it on 16,000 H100s, and we know the throughput they set it to. So if you do the computation.  It takes around 70 days, or 26 million GPU hours. At least that's with my back-of-the-envelope computation. They actually said that they used 30 million instead of 26 million GPU hours. So maybe they had like some challenges. I don't really know. But if you follow the simple computation, it's around 70 days. Cost, I mean, this is hard to approximate, but I'm just going to say it's kind of the rent. Like, what if I were to rent H100s? That many, H100s for that many days. How much will I pay? H100, a lower bound on the renting cost of H100 is around two hours, a $2 per hour. So if you multiply this by 26 million hours, you get $52 million. So they probably pay less than that, but not actually much less, because all these services that actually rent GPUs, they don't make that much.  money. So it's probably slightly less but not that much less. Now salary, I said 50 employees, 500k per year. Yeah, it's probably the right bullpock, 25 million. So if you put all together, around 75 million dollars for training this slammer model. I'm probably out by like 10 million, but that's kind of right bullpock. Carbon emitted, a lot of people might ask, like also the cost is not the only thing that is important. So I did the computation. It's around 4,000 tons of CO2 equivalent. That is actually only 2000 return tickets from JFK to London. So right now carbon emitted is actually not, I mean it's huge, but it's not like meaningful yet. I think in maybe GPT 6 GPT  Once you multiply this by 100, that might become a real issue. Right now, it's still not, I think, an issue in the grand scheme of things. Next model, the way you should be thinking about these models, is that every new generation, the number of flops essentially multiplies 10x. Well, at least that's what they try, if they have enough energy and if they can buy enough GPUs. Great. Any question on these backup DNA envelope math? Okay. So, now we talked about pre-training. I wanted to also chat about systems, because now we know compute is really important. So there's a question of how do you optimize your compute? I will leave that for the end, because I'm not sure how much time we will have. I think it's important, but hopefully I'll be able to talk about it later. It's slightly different than what we've been talking about right now. So I'll move on to post-training for now. So the task of post-training, the reason why we need to...  to do post-training is as I told you before, it's to make AI assistance. So language modeling is not really the thing that you want when you have an AI assistant. For example, if you ask to GPT-3, which is a purely language model, a pure language model, not an aligned one, if you ask a question, I explain the moon landing to a six-year-old, the conclusion that you would get is something like explain the theory of gravity to a six-year-old. Because what it learned is that on internet, if you have one question, you usually have maybe another bullet point of other similar questions. You don't usually have question in an answer later. This is not what you want from an AI assistant. So how do we do this alignment, which is this post-training and making these models assistance? So the goal of this alignment is to basically get LMS, follow the instructions that are given by users. Sign and maybe some designers.  kind of desires. So think about moderation. You don't want the model like, open-air definitely doesn't want the model to say stuff that is very toxic. So here you see on the left hand side that when you ask a question it actually provides a real answer so it's not like before the LLM and on the right hand side you see that it would if you ask to write a tweet describing how as certain part of the population or evil it will say that it cannot do that. So that's kind of this alignment. The background here is that basically the data that you want for training some of these models is like we know what we want which is just asking humans this is a question this is the answer that you want but the thing is that it's very expensive to collect that data and it's hard to find it online. In contrast pre-training data is not what you want but there's a lot of it. So what we will do or the main idea is simply take a  pre-trained large language model, pre-trained all of internet, and then you just fine tune. So you just change a little bit of weights on the type of data that you actually want. And hopefully given it, you're already pre-trained on all of internet. It basically learns or knows how to speak in English and knows standard language syntax. Then you can really fine tune it with very little data. OK, SFT. So supervised fine tuning is really exactly what I just said, which is the idea of fine tuning the large language model on basically the desired answers that are collected from humans. So why is it called supervised fine tuning? Because you basically want to do language modeling on the real answers. So language modeling is this like next word prediction. And that's the fine tuning part. And then you want to do it on desired answers given by humans. So that's why we call it supervised. So how do we collect this data? Well, I just said it. You can just ask humans to tell you, this is the question. This is the answer that you would want from something.  of these models. So this is an example. I can't read very well on my computer, but my kid needs to do a science, no, let's read this one. Can you write a short introduction about the relevance of the term monopsony? And then it says monopsony refers to a market structure blah, blah, blah. And that's a human number with that. So actually this is open assistant, which was a way to collect data online by humans. So this type of supervised fine tuning while I'm in is really the key of chat GPT. This is what made the big jump from GPT3, which was mostly something that was known by AI researchers to chat GPT, which became known by basically everyone. So the problem with human data is that it's very slow to collect and very expensive. So one percent possible simple idea.  is to use LMS to scale data collection. So that's exactly what we did with Alpaca one year ago. What we did is we asked humans, or we use a data set of human question answers. So there were 175 question answers here. And we asked the best more at the time. So Texas Vincis user three to basically generate many more of these question and answers. So all we did is like, this is what humans would write, now write similar answers and similar questions. And we collected 52,000 LLM generated question answers. And then what we did is simply we took LAMAS 7B, which was the best pre-trained model at the time. And we just fine tuned this with supervised fine tuning as I told you. And that's how we got the Alpaca 7B model. And this is the type of data that we collected. So things like what does algorithm mean? And algorithm is a step by step set of instruction. You used to solve a problem or achieve a goal, blah, blah, blah. So the data is not actually, it's actually pretty good, given it was LM gen.  generated by LLMs from essentially two generations ago. So that really started at least for us kind of as an academic replication of ChatGPT. Now it really is a big field of synthetic data generation of how to use LLMs to basically make development of LLMs faster and basically by decreasing the amount of human hours that you need. Quantity of data. So we talked about what type of data and how we collected. One thing which is surprising with SFT is that you don't need that much data. So what this paper showed, this is called Lima, is that if you have, if you scale the amount of data that you use from supervised fine training from 2000 to 32,000, it really doesn't help much. So here scaling loss definitely don't help. So the intuition here is that all you learn is you learn how to format your desired answers. Another way of seeing it.  is that your pre-trained models, they essentially model the distribution of every user on internet. One that might write bullet points, another one that might answer question with an answer. So all you tell your model is like, wait, you should actually be optimizing more for this type of user than another one. So you're not actually teaching anything through this SFT, so supervised fine tuning. All you do is you tell the model to kind of optimize for one type of user that it's already in a pre-trained dataset. So the knowledge is already in a pre-trained LLM, and you basically just specialize to one type of user. Great, any question on SFT? Yes. So, I know it's a big issue with synthetic data where if you keep generating data from the same distribution, eventually you're not learning a new distribution, you're essentially playing with it. It just puts track of that. Surely you can't scale that for a way you can keep going on in generating from the same data.  and hope to learn something new. So it's an active area of research. And you've thought that you have around how people are maybe thinking around this and better ways to bootstrap or to give up on this idea and realize that the chart shows you don't need that many, so just get humans to generate 2,000 radiability. Yeah. So that's a very good question. So for the data stuff, so I'm saying it's not that important for SETT, but there will be another thing we'll talk about right after, where actually data does matter. My intuition based on not that much empirical results is that you can still get even though you use your LMS, if you use purely LM generated text, and you do that for like three, four generations of LMS, I agree with you that probably you won't improve much. But for me, what is important is how do you use human in the loop with LMS? Not purely LMS, not purely humans, but maybe what you can do is just have the model generate some new text and just humans write a few edits. And it's not much f-.  faster than writing the entire text. And I think that if you have that type of collaboration, then from an information theoretical point of view, you still get additional information, but you're so much faster than if you use humans. And I think that as a field, we'll probably move towards these type of things, which is really just finding the examples that are important and asking humans, it's kind of active learning, just asking humans exactly when you need to get their inputs. Yes? So, you're just trying to make the same loss function, the same general training after the supervised learning that we do for the pre-training, right? Because the examples you showed, I think the important thing for good examples is that they're super action-oriented. There's these more complex things. Still just like changing. Same loss. So that's why here, I didn't maybe didn't emphasize enough. This is just language modeling. Fine-tune the language model on the desired answers. So this is literally the same loss. It will be different.  in two seconds. But the first step of SFT is literally the same loss where you just say, okay, I want to actually specialize on that type of data. So there's even a question of like, what is pre-training, what is post-training? Because in reality, it's just like a different data that you use. The reason why we can usually call it post-training is that the way we collect that data is very different. Great, great questions. Yes. Maybe it's the same question, but why would these 2000 examples have such a over-weighted influence of the internet? So that's why we, also that's another reason why we call it post-training is that we use different type of hyper parameters. So you know, I told you basically at the end of pre-training, you essentially end up with a learning rate of zero. And here you're going to increase your learning rate to like 1 e minus 5, 1 e minus, yeah. And so the way that you give to them is actually different. OK, second step or second part of this post-training is what we call reinforcement learning.  from human feedback or all HF, some of you might have heard of that. The idea is that SFT has a problem, namely that you do behavioral cloning, which means that you just try to clone what the humans would say. And that has many issues. One of them is that you're bound by human abilities. So if humans actually, humans won't generate the things that they think is actually the best thing to generate. So if you ask me to write a book, I mean, I can definitely enjoy a book. I can probably say one book is better than another, but I'm definitely not going to be as good as writing the book that I want to read. So you're going to be bound by the human ability to generate things, even though the humans might be better at distinguishing between things. That's one issue. Issue number two, I find that actually pretty interesting, is that if you ever heard of the word house Cination, so this is LLM's generating false information, house Cination might or these people have hypothesized that that can  come from the supervised fine tuning, even if you do supervised fine tuning on data that is correct. And the reason why that is is that if, given I told you that basically SFT is with very little data and it's with data that doesn't, the model doesn't learn anything new. So what if the human gives an answer that the model didn't know was true? From the model perspective, the human basically is telling the model, generate this thing that seems plausible, but actually I have no idea if it's true or not. So just to give you a very concrete example, if we go back to this monopsony example, can you write blah blah blah about monopsony, imagine that there were human rotor reference on this type of book. And that book might exist, that might be a correct reference. But what if the LLM never saw this reference during pre-training? Then it doesn't know that it's a correct reference. To really what you tell the model is to generate a make up, some plausibly sounding reference.  rather than actually tell the real reference that it's arguing pre-training. So hallucination might be, like, might be caused by this SFT. That's problem number two. Does that all make sense? Great. Problem number three, price. Generating the ideal answers is very pricing. And that comes back to your question of, like, humans writing an entire answer is actually pretty expensive. So that's where all HF comes in. The idea is that instead of cloning the behaviors of humans, we're going to maximize human preference. And the way we're going to do that, so the pipeline, is that for a certain, for every instruction, you're going to ask a model to generate two answers. And usually you use a pretty good model. So you usually don't use an LLM here. You use a SFT fine tune, you use a fine tune LLM already to give, like, pretty good answers. And then you ask labelers, which of these two...  answers was better. So select the preferred one. And then with different type of algorithms, we're going to talk about the algorithms. You just fine tune the model to generate more of the green thing than the red thing. So more of the good stuff. So now the question is how. And we're going to talk about that right now. So there are two ways that we're going to talk about and two that are mainly using the community. The first one is simply the idea of using reinforcement learning. So hopefully you all know what reinforcement learning is now. So when you think about using reinforcement learning, one important question is like what is the reward that we are optimizing? So in this case, there are really two options that I can think about. The first one you could just say, I'm going to compare the output generated by some baseline, the output generated by my model. And I'm just going to ask the human to say which one is better. And I'm going to use this as a reward. So if I'm better than the baseline, this is a plus one. If not, that's a minus one. So now it's binary reward. The problem of binary reward is that it's very sparse.  you don't get much information out of it. Like maybe you answered was slightly better, maybe it was way better, and you don't really know from this how much better it was. So option two is that you can train what we call a reward model, which is simply a classifier. So you use machine learning to classify how much better two outputs are from the perspective of the human. So there's a little bit of better, but what you basically do is that you train, you take a real model R, which is just a large, also a large classifier, and you basically ask this reward model, you give it the input and the actual output that you have, one of the two outputs, and you just exponentially that's the softmax class that you all know about, and now you divide by the, the exponentialed reward on the first example, sorry, on the first output.  and it's on the second output. And you basically train, so the reason why you do that is that you train your model, you train this reward model to be able to classify how much better one output is to another one. So another slightly less-converted way of seeing it is that your reward model will output some reward that will be used as the logits of your softmax. So now if you have high logits in your softmax, it means that highly likely this output is better. So that's what we call Bradley Terry model. Yes. Is this your reward model going to be the entire output? Or is it going to be like that? So this takes the entire output at one. So it takes all the input and all the output, and it gives one number. Yes? So I'm going to be talking about the value of an a human being. So with the reward model, where would that human be? Oh, why so? And...  Sorry, maybe I wasn't clear. You train this reward model to fit this green and red preference from humans. So basically, you train a classifier to say whether the humans prefer red or green. But instead of using the binary reward, which is what the human will tell you, you basically use the large bits of the softmax. And the thing with the large bits is that large bits are continuous. So now you know that if your reward model said it has high logents, then in some ways the human highly preferred this answer to some other answer. Great. So as I just said, continuous information says better. So that's what people use in practice. Or at least, use to use in practice. I'll tell you about the other algorithm later. So what you do at the end is that you basically try to just use reinforcement learning that you know about. Now we know we have our reward. What you sample through is the generation from your large language model.  Then you just use some regularization terms. The reason why we do this regularization term is for avoiding what we call over-optimization. This reward model might not be really represent, like might not perfectly model human preferences. So you don't want to maximize this thing to essentially infinity. You do it using PPO, which is a common reinforcement learning algorithm. One thing to note here because it will be important for later, is that when we use maximum likelihood, I'm sorry, now the large language models are actually a policy for your reinforcement learning. It's not maximizing maximum likelihood anymore, which means that you're not modeling any distribution anymore. And the reason why this is important is that models that went through this type of PPO actually don't give you likelihoods of text that are meaningful. Because what you optimize them to do is basically just optimize for generating the most likely thing. Not optimized for modeling.  like all the answers that humans might say. Another way of saying that is that there's nothing that incentivizes here the model to not give like a single possible generation. Nothing here says it's good if you have some distribution with some entropy. Okay, if you haven't followed, it's not that important, but just good to know. Great. So PPO is exactly what Chad G.P.T. did originally. So here's the on their blog posts or what they have, is step one, do supervised fine training, which now you all know about. Step two, train a reward model on human preferences. Step three, do PPO multiple steps, which is where you see this blue arrow. So you train the model once with the PPO, you collect new data, you continue. And that's exactly what Chad G.P.T. did. And that was a big breakthrough between GP3 and Chad G.P.T. One thing to note is that PPO has many challenges. Reinforce learning.  something as super nice theoretically. In practice, anyone who ever worked with reinforcement learning knows it's such a mess. There's a lot of things like roll outs, out-of-loop slipping, so many complications. So it's messy. This is the idealized PPO-use4LM setting. So that's already much more complicated than this expectation we saw before. And in practice, it's actually much more complicated. So we have one implementation of it that we had to do, and I'm not going to go through it. But basically, you have like so much stuff that you have to think about when you implement that type of PPO algorithm. So you have clipping everywhere. You have a lot of complexities and things are not well documented. All this to say that there was a new method that was proposed also from Sanford one year ago called DPO, which is essentially a simplification of PPO. And the way what they did or the idea that they have is that instead of using reinforcement learning, you can just maximize the probability of generating the stuff that you like and minimum.  the probability of the stuff that you don't like. So if you think about the human preference, the red and green maximize green minimize red. So the loss is actually this one. What you see, this is simply some log of the model. So this is the likelihood of the model generating the things that the human preferred given the inputs. And what you try to do is basically maximize the likelihood of generating the things that you like, minimize the likelihood of the things that you don't like. All the rest of the terms here, it's not too important. It's actually really not that complicated to understand. But at the high level, it's really just maximizing the things you like minimizing the rest. And one thing to note, which I was going to say just here, is that actually all the rest is chosen such that the global minima of PPO and the global minima of this DPO under some assumptions.  essentially equivalent. So this is the right thing to do mathematically. I'm not going to go through the derivations, but that's the right thing to do. It's pretty different with PPO in the sense that now, with PPO what you had to do is collect their human preferences, then train your reward model with maximum likelihood, then use reinforcement learning. Now all you do is basically maximum likelihood. Much simpler, yes. I mean, yeah, it's a simple thing. This is a much simpler thing, like what you just do to do with your business. Why did they start with this reward model? What about them doing that? I think it's a great question. I don't really know. What I can tell you is that I don't put in the people who did basically this, sorry, who did Chagy PT initially, other ones who actually wrote PPO. And I think there were just, like, there are a lot of reinforcement learning people. And I think that for them, it was very intuitive. So there's also some additional potential benefits. For example, they don't...  Yeah, for example, if you use the reward model, the cool thing here we have reinforced learning is that you can use unlabeled data with the reward model. So here you can only use the label data for doing DPO. For PPO, you first train your reward model and then you can use unlabeled data where the reward model will basically label this unlabeled data. So there's additional kind of potential, there could be potential improvements. In practice, it happens that they are known and I think just that a lot of people in this team were reinforcement learning experts, including the main author of PPO, which I'm told me. So much simpler in PPO and it basically performs as well. So now this is the standard thing that people use. At least in the open source community, I believe it's actually the standard also in industry. That's called DPO. Gains, so those are older papers on the left. Here this is on a summarization task. You see.  All I want to show you is that basically the pre-trained models were okay and they approve of scale. If you do supervised fine tuning, you improve them a little bit more. If you do PPO or something with all HF with human feedback, you get performance that are as oftentimes depending on a benchmark, even better than humans. So this is the human reference summaries. Same thing is done on a paper that we have alpaca farm where we see the evaluation here is not too important, but basically you see pre-trained model. You jump to SFT and then you jump to PPO, DPO and PPO have the exact same performance. So basically all HF helps. That's kind of the conclusion and DPO is simple. Data, the way that you collect that type of data, first idea is just use humans as we already talked about. Guidelines are very complicated for what humans should be labeling and it's really not that easy. See if you ever do some of the labeling, you will see that it's...  Extremely complicated. Like if I zoom into this, here I have a question, tell me about self-driving cars. And you read both self-driving cars of vehicles that are capable of detecting the surroundings blah, blah, blah, blah. Self-driving cars are cars that are equipped with sensors, blah, blah, blah, to navigate without the need for a driver. And we both seem OK. Like which one is better? It's actually hard to say at the glance. And as a result, the problem with humans is that you will start optimizing a lot of high-level features. For example, the second one is longer. I can guarantee you that most humans will choose the second one. Even though I may do first one is better, I don't know. I haven't read it carefully. So challenges of humans, first, slow and expensive. Second, as I just mentioned, it's hard to focus on things that matter, like correctness. And people usually look at things that don't matter as much, like to form, like length. And as a result, so what I show here is that when you do RHF, the more you do have RHF, the longer the output of the...  models become. So if you've ever been annoyed at chat GPT answering you super long sentences, this is because of all HF. Annotated distribution shift. Like the distribution of annotators that use matters a lot. And you have to think like what is what is even the humans that we want to represent in these models. Another question is like crowdsourcing ethics. Like usually these basically a lot of the labeling that is done. Like the people who do them are not paid well and they have to go through a lot of toxic data because you're basically one the model to avoid saying the toxic data. So crowdsourcing ethics too. So many challenges with human data. So what we did also last year is again the same thing as alpaca just the idea of like oh well now challenges with humans maybe we can just replace them with lm's. So what we did is simply replace oh I see that I'm just realizing that the slides are not centered. Anyways you  replace human preference with LM preferences. So here on this figure, you see on the X-axis the price that we paid for collecting human data. It's around $300 for 1,000 examples. And this is on mechanical turquoise, which are usually like cheaper than maybe some of the other companies that you could go through. And on the Y-axis, it's basically the agreement with other humans, with the mode of other humans. And what you see is that actually, as I told you before, labeling is really complicated. Humans agree with themselves only around 66% of the time. I'm a binary task. And it's not that the humans are not good here, because we were five main authors on this paper. We tried to label this data ourselves, and we only had like, say, 67 or 68% accuracy, even though we talked for like three hours of how we should be doing labeling. But really, it's complicated. It's not an easy task. And here I just showed many different models. And basically, you see that models are much cheaper, and they can actually...  get higher agreement of the mode of humans than humans themselves. The reason why is because humans have a lot of variants, models have no variants. They might be a little bit more biased, but have less variants. It works surprisingly well. Now it's kind of the standard and open source community. I think even in an industry, a lot of people use both humans and LLMs for improving the collection of all HF data. This is the paper from last year, but honestly, now it's more like that LLMs would be around this agreement and this cost. So around, I would say 50X cheaper than humans and better agreement with humans than humans themselves. Okay, so that gets us to evaluation of post-training. And that goes back to your initial question at the beginning of the lecture. How do you evaluate something like charge-up? The answers that charge-up could give are basically unbounded. And it's not that there's one right answer. There are many answers that are just as good. So the main topic.  One, you can't use validation loss because one method might use PPO, the other one might use DPO, validation loss is not comparable. Second, you can't use, sorry, perplexity. That's the thing I told you before. These models are not calibrated. They don't give distributions. They just optimize for one thing. So you can't use perplexity for actually evaluating these type of models. Once they're aligned. Sorry, once they're aligned. Third, there's a lot of diversity of questions that human might ask to these models. Generation, open QA, like some question answering, some summarization, and all of these things. So there's so many things you have to cover. Then the tests are really open-ended. So it's very hard to automate. So that's what you were alluding to before. So the idea is that instead of trying to come up with really easily automated benchmarks, it's just we're going to ask questions that users actually asked to these models in practice. And we're just going to ask annotators to say between these...  two models, which one is better? Like what's the, what's the better output? So basically you do the exact same thing as basically the data from all HF, but you use it now for evaluation. Yes? I'm not sure I understand that. I mean, can't use procllexity not calibrated, really. Hello, I'm still doing like an exit token prediction. So, IPI procllexity, please. So think about the optimal solution after doing PPO is basically one model that gives you essentially a delta like basically says that there's only one sentence that is, that could be generated for that question. So now if you use it on something that is slightly semantically differently, different, it would actually give a likelihood of zero for that answer. So in reality, it's not that extreme, because as you say, it's still a distribution, but it just shows you that there's a fundamental issue with procllexity once these models are not LLMs anymore, they were not trained, at least with PPO, they were not trained to do maximum likelihood anymore. They were trained to be PPO.  policies. Okay, so probably the most common, or the most, yeah, the most common benchmark or the most trusted one is what we call chatbot arena, which is basically go on internet, have random users on the internet blindly talk with two chatbots, just ask many questions, see the two answers, and rate which one is better, and you do that over 100,000 of users, and then you get the actual preferences and you get rankings of models. So you can go right now on chatbot arena and actually interact with these models. One potential issue just to highlight is that while people who want to do these type of things are usually more like tech driven, or like tech savvy, so a lot of the questions that you will ask are more like tech stuff, discussing software errors, inquiries about AI tools, and all these things. So another issue is cost and speed. If you really want to use something like this for development process, it will be too costly.  you will need to basically pay a lot of humans to do that. So one simple idea is, again, as we said many times, just use LM instead of humans. You probably know the drill at this point. Steps for every instruction generate outputs by some baseline and a model that you want to evaluate. So he imagined that I am comparing an answer from Chad G.P.T. and from Mistro. I'm just asking another model, which one is better? And I just basically averaged that out. Yeah, I asked you, G.P.T. for which one is better. I averaged that out of my entire distribution over my entire benchmark or data set. And that gives me a win rate, so win probability for one model compared to another one. And now you can rank models. And this is the Alpeque-Eval leaderboard. So the benefits of this is that actually we show we get 98% correlation with Chad Baragwina, so very high correlation with humans. So this is...  comparison with correlation with other benchmarks and it takes less than three minutes and less than $10 to run. So it's pretty cheap. There are downsides though. One of them is purist correlation. So as we already saw before, LMS prefer, this is one spurious correlation. Not many. I'll just talk about one. LMS prefer longer outputs. Actually humans also prefer longer outputs but the problem or the issue once you use LMS is that once there is bias you will continue optimizing that. Humans at some point I can guarantee you if I ask a simple question and you give me five pages of answers. I'll be like no I don't like that answer. But LMS if they have this bias and they were trained for that, they will continue preferring longer outputs. So here we see the preference just showing that humans and models prefer longer outputs and here is another view of the initial Apache VAL data set benchmark when when we asked when we rank GPT4 when we look at the run rate of GPT4 versus actually GPT4 itself if we  If we use the standard GPD4, it gets 50% by definition if we're comparing GPD4 versus GPD4. But if we ask a GPD4 to be slightly more verbose, so we just say in the prompt, be verbose in your answers, then it gets a reinway of 64.4%. So really, there's a huge variance. And if you ask it to be concise, it gets 20%. So there's a huge variance depending on whether you ask it to be concise of verbose. That's very annoying. So one possible solution, which is what we did, is just use some regression analysis. I'm not going to go into details, but basically use causal inference tools to control for length. And right now, actually, length matters much less. So if you ask it to be verbose, you still get some gains, but much less. Great. So that's all about post-training. And now for the next eight minutes, might talk about systems or just answer questions. Yes. OK. Go back to your post-training. In terms of post-training, how did we tune those parameters using?  a small body of fine-tuning data and have such big effect on the model. You mentioned earlier that there's a different set of hypergrammers. Are we changing just some of the weights, the later weights or all the weights? What's actually happening? Yeah, I kind of skimmed through all of this. You change all the weights. Actually, industry would change all the weights. In open source land, you might have heard of Laura, which is going to change it basically only some of the weights. Or it actually, to be more specific, it's going to add some differences to the output of every layer. But in industry, you're going to just fine-tune all the weights. Also to say something else about the data, actually this last step, RLHF, you're usually going to collect a lot more data than with SFT. So if SFF 50 is like 5,000, 10,000, maybe 50,000 with RLHF, I think you're going to be more unlike the 1 million, or the magnitude. It's still much less than pre-training though. 15 trillion tokens.  I mean, this is like, that's not even a drop. And then you influence the weight of the wall. So you do it. I mean, you have to think that how you do it is you use, I mean, as I said, the learning way that you're going to use is going to be different. But also, you only do that. So just imagine if I trained, even if I trained on one sentence, but over and over again, at some point in my model will only generate that sentence, even if it was just one sentence instead of the 15 trillion tokens. So if you use a large enough learning rate and for enough time, you will basically overfit that sentence. So the key thing to remember is that the data is not I'd, it's not as if you mix some post-training data and some pre-training data. You do pre-training. And then you just start fine-tuning only on a post-training. So another way, maybe another perspective, is that the pre-training is just an initialization of your model. And once you view it that way, that this is just initialization of weights, then there's nothing special.  You don't need to remember that you trained a lot of data before. The only thing that matters is that you had initialization, and now I actually trained a model. So maybe think about it that way. Like there's a mark of property in some ways. It's just like, you had your weights. This is my initialization. Now I'm training that one. Does that kind of answer your question? Kind of, but you said something just now about it's almost a equivalent of just re-running the fine tuning data many times. Is it actually, is that what actually happens in order to give so much more preference? You might have. I actually don't know right now how they do it in industry. When we did our packet, we had to do three blocks. So you did run it three times to it. But I mean, even the number of times that you run it through, it's actually not important. The only thing is the effective learning rate. That what matters. So yeah. Great. So I think.  five minutes, right? Okay, I might try to give a high level overview, at least from one of the systems trick. Systems, as we said, for everyone, bottleneck is a, sorry, compute is the huge bottleneck. One question you might ask is why not buy more GPUs? GPUs are expensive but also as case, even if you have $10 million right now, you cannot buy the best GPUs. There's also some physical limitations. When you have multiple GPUs, you have to communicate between them. That takes time. So just buying more GPUs is not that easy. So it's really important to think about how do you allocate resources and how do you optimize your pipeline? So system. 101 on GPUs, I'm sorry, I'm going slightly faster. I hope that some of you at least can follow. GPUs are basically optimized for throughput. CPUs are optimized.  for latency. So GPUs, the way you have to think about it is that there's one command that is run on many, many cores at the same time on different type of data. So this is how you see GPU. You see there are many different cores. We call them streaming multi-processes, which is very different than the usual CPU architecture. So just think high throughput, powerization for GPUs. GPUs are optimized for fast matrix multiplication. So every time you will do something on GPU, if you can do it with a matrix multiplication, it's going to be 10 times faster than with anything else. That is a little bit annoying, because it means that we are kind of bottlenecked to doing anything with matrix multiplications. Another thing to note with GPUs is that compute has been improving faster than memory and communication. So right now GPUs usually are hard to keep, like the data that you send at CPUs is actually hard to keep up with.  the process. So most of your GPUs are actually going to be idle if you just run normal code. If you don't optimize your code. So communication and this will continue over time. Another thing to know about GPUs is that there's a memory hierarchy. This is the same thing I actually with CPUs. But basically, the closer you are to your cores, the less memory there is, but the faster things run. If you are further, more memory slower. OK, I'm going to skip that. OK, actually, I'm going to say it. I told you about this defective communication. The metric that people usually look at is model flop utilization. So what is the theoretical maximum that GPU could run at? No more flops that it could use per second. Divide the number of observes through per divided by this theoretical maximum. And in general, if you reach 50%, you're very happy. Like Facebook, I looked at Lama was at 45% for something like this. So that means that data doesn't come fast enough, even for these big companies. So one simple thing.  trick and that might be the only one I'm going to tell you about is low precision. One simple idea is that, well, if I'm going to put my floats in low precision, then there's going to be fewer bits that I have to send to my GPUs. If there's fewer bits, it's faster communication, lower memory consumption, things are going to go faster. And for deep planning, it just happens that decimal is not that important. So when you do matrix multiplication, when you do, like, for example, SGD, it is already so much noise that if you update something by 0.01 or 0.015, who cares? So basically, instead of using 32 bits per float, which is what people use to use, or 64, for example, which is what we would use in other domains, you use 16 bits for matrix multiplication. So for every float, you use 16 bits. And for training, you have this type of, like, what we call automatic mix precision, which is that some of the things are in 32 bits, others are in 16 bits.  Generally, the way you should be thinking about it is that your weights are stored of your model are stored in 32 bits But just before the computation you put everything in 16 16 bits like this you do computation super fast and at the end You update your weights in 32 bits and the reason why you do all the updates in 32 bits It's just think that if you're learning weight for example is very small You still want to be able to like make a difference in your weights So all the computation is done in 16 bits, but the weights are actually stored in 32 bits So that's like the standard way that people are doing it Okay, I'll actually talk just about this and then I'll skip all the rest operate a fusion because I think it's actually pretty cool As I just said communication is very slow and actually every time you use a pie torch line It basically moves variable to global memory of your GPU So when you have something like this X dot cosine Equal X1 and then you do X1 dot cosine what is happening behind the scenes is that you take the X which is data  you ship it to your actual processes of your GPUs. You apply the cosine, you ship it back to the main memory of your GPU, and then you see the next line, you ship it back to the GPU processor, you apply another cosine, and you ship it back again. Another way to see that is that you go from your DRAM which is your global memory in your GPU, and you ship it to compute, you ship it back for every line. This is a naive way of doing it. This seems very wasteful. So the idea, simple idea of operating a fusion is just communicate, do all the computation, ship it backwards. And this is exactly what a few kernels are. So if you ever want to make your computations in PyTorch much faster, just apply torch.com.com on your model. This is going to make your model around two times faster. And what it does is simply that it rewrites your code, your PyTorch code, basically NC++.  in CUDA to do the communication only once, then do all the operations, then ship it back. Okay, I'm not going to have time to talk about tiling. Tiling is important, powerization, powerization is important, and mixture of experts, mixture of experts is important. Outlook, there are many things we haven't talked about. We haven't talked about architectures, we definitely haven't talked about inference. There are many other things that are important with LLMs. What is the UI that you use? I mean, arguably, ChatGPT, the big novelty was just have a simple UI to use it. Multi-modality, what are all the misuses you could have, the fact that they might not be enough data on the internet to train all these models, the quality of data collection, so many other things. If you are interested in all these topics, I would suggest three classes. CS224N is probably the one that touches the least on LLMs, they give some background in historical context of all the LLMs that give kind of some  some at Jason Matillo. CS324, I think it's called, I think it's called large language models. More in-depth reading and lectures on everything I talked about. CS336, which is large language model from scratch, you actually build your own LLM. It's an amazing class, also given by my two supervisors, very heavy workloads, so be careful. Great. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Text Preprocessing**"
      ],
      "metadata": {
        "id": "qRQiP4I0g15p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "cleaned_text = clean_text(transcription)\n"
      ],
      "metadata": {
        "id": "MN7m6n8IeITt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "words = word_tokenize(cleaned_text)\n",
        "sentences = sent_tokenize(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TNnJGwFhejwC",
        "outputId": "a5ecbc1e-53f9-4a07-b4ad-6cba19e0dc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stop_words = {\"great question\",\"uh\", \"um\", \"you know\", \"like\", \"er\", \"basically\", \"actually\", \"okay\",\"ive\",\"one thing\"}\n",
        "stop_words.update(custom_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7JWrwPPveqn4",
        "outputId": "6287c88f-c3c7-4937-9aa8-ccf114fe88a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out stop words from the tokenized words\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]"
      ],
      "metadata": {
        "id": "NbhfgMQHexjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequency Analysis of Bigrams and Trigrams\n",
        "I performed frequency analysis on the generated bigrams and trigrams to identify the most common word pairs and triples in the transcription text. This helps highlight recurring phrases that are most used to the lecture content."
      ],
      "metadata": {
        "id": "RVVbH89bhmBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = list(ngrams(filtered_words, 2))\n",
        "bigram_phrases = [' '.join(gram) for gram in bigrams]\n",
        "print(\"Bigram Phrases:\", bigram_phrases)\n",
        "\n",
        "trigrams = list(ngrams(filtered_words, 3))\n",
        "trigram_phrases = [' '.join(gram) for gram in trigrams]\n",
        "print(\"Trigram Phrases:\", trigram_phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS4RPb0Ke4CN",
        "outputId": "f42f392c-f783-4b0e-e874-10d87561af13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Phrases: ['lets get', 'get started', 'started ill', 'ill talking', 'talking building', 'building llms', 'llms today', 'today think', 'think lot', 'lot heard', 'heard llms', 'llms quick', 'quick recap', 'recap llms', 'llms standing', 'standing large', 'large language', 'language models', 'models chat', 'chat bots', 'bots youve', 'youve hearing', 'hearing recently', 'recently chad', 'chad gpt', 'gpt openai', 'openai cloud', 'cloud untropic', 'untropic gemini', 'gemini lama', 'lama type', 'type models', 'models today', 'today well', 'well talking', 'talking work', 'work going', 'going overview', 'overview one', 'one lecture', 'lecture hard', 'hard compress', 'compress everything', 'everything hopefully', 'hopefully ill', 'ill touch', 'touch little', 'little bit', 'bit components', 'components needed', 'needed train', 'train llms', 'llms also', 'also questions', 'questions please', 'please interrupt', 'interrupt ask', 'ask question', 'question likely', 'likely people', 'people room', 'room zoom', 'zoom question', 'question please', 'please ask', 'ask great', 'great matters', 'matters training', 'training llms', 'llms key', 'key components', 'components matter', 'matter one', 'one architecture', 'architecture probably', 'probably know', 'know lms', 'lms neural', 'neural networks', 'networks think', 'think neural', 'neural networks', 'networks think', 'think architecture', 'architecture youre', 'youre using', 'using another', 'another component', 'component really', 'really important', 'important training', 'training loss', 'loss training', 'training algorithm', 'algorithm train', 'train models', 'models data', 'data train', 'train models', 'models evaluation', 'evaluation know', 'know whether', 'whether youre', 'youre making', 'making progress', 'progress towards', 'towards goal', 'goal llms', 'llms system', 'system component', 'component make', 'make models', 'models run', 'run modern', 'modern hardware', 'hardware really', 'really important', 'important models', 'models really', 'really large', 'large ever', 'ever systems', 'systems really', 'really important', 'important topic', 'topic llms', 'llms five', 'five components', 'components probably', 'probably know', 'know llms', 'llms dont', 'dont know', 'know lms', 'lms based', 'based transformers', 'transformers least', 'least version', 'version transformers', 'transformers im', 'im going', 'going talk', 'talk architecture', 'architecture today', 'today one', 'one gave', 'gave us', 'us lecture', 'lecture transformers', 'transformers weeks', 'weeks ago', 'ago two', 'two find', 'find much', 'much information', 'information online', 'online transformers', 'transformers think', 'think theres', 'theres much', 'much less', 'less information', 'information four', 'four topics', 'topics really', 'really want', 'want talk', 'talk another', 'another thing', 'thing say', 'say academia', 'academia focuses', 'focuses architecture', 'architecture training', 'training algorithm', 'algorithm losses', 'losses academics', 'academics done', 'done lot', 'lot big', 'big part', 'part career', 'career simply', 'simply thinking', 'thinking make', 'make new', 'new architectures', 'architectures new', 'new models', 'models seems', 'seems important', 'important reality', 'reality honestly', 'honestly matters', 'matters practice', 'practice mostly', 'mostly three', 'three topics', 'topics data', 'data evaluation', 'evaluation systems', 'systems one', 'one industry', 'industry focuses', 'focuses thats', 'thats also', 'also one', 'one reasons', 'reasons dont', 'dont want', 'want talk', 'talk much', 'much architecture', 'architecture really', 'really rest', 'rest super', 'super important', 'important great', 'great overview', 'overview lecture', 'lecture ill', 'ill talking', 'talking pretraining', 'pretraining pretraining', 'pretraining probably', 'probably heard', 'heard word', 'word general', 'general word', 'word kind', 'kind classical', 'classical language', 'language modeling', 'modeling paradigm', 'paradigm train', 'train language', 'language model', 'model essentially', 'essentially model', 'model internet', 'internet theres', 'theres post', 'post training', 'training recent', 'recent paradigm', 'paradigm taking', 'taking large', 'large language', 'language models', 'models making', 'making essentially', 'essentially ai', 'ai assistants', 'assistants recent', 'recent trend', 'trend since', 'since chatgpt', 'chatgpt ever', 'ever heard', 'heard gpt3', 'gpt3 gpt2', 'gpt2 thats', 'thats really', 'really pretraining', 'pretraining land', 'land heard', 'heard chatgpt', 'chatgpt probably', 'probably really', 'really post', 'post training', 'training land', 'land talk', 'talk ill', 'ill start', 'start pretraining', 'pretraining specifically', 'specifically ill', 'ill talk', 'talk task', 'task pretraining', 'pretraining lms', 'lms laws', 'laws people', 'people use', 'use language', 'language modeling', 'modeling quick', 'quick recap', 'recap language', 'language models', 'models high', 'high level', 'level simply', 'simply models', 'models probability', 'probability distribution', 'distribution sequences', 'sequences tokens', 'tokens words', 'words model', 'model p', 'p x1', 'x1 excel', 'excel x1', 'x1 word', 'word wanted', 'wanted excel', 'excel last', 'last word', 'word sequence', 'sequence sentence', 'sentence concretely', 'concretely sentence', 'sentence mouse', 'mouse eight', 'eight cheese', 'cheese language', 'language model', 'model gives', 'gives simply', 'simply probability', 'probability sentence', 'sentence uttered', 'uttered human', 'human found', 'found online', 'online another', 'another sentence', 'sentence mouse', 'mouse eight', 'eight cheese', 'cheese theres', 'theres grammatical', 'grammatical mistakes', 'mistakes model', 'model syntactic', 'syntactic knowledge', 'knowledge know', 'know less', 'less likelihood', 'likelihood appearing', 'appearing online', 'online another', 'another sentence', 'sentence cheese', 'cheese eight', 'eight mouse', 'mouse model', 'model hopefully', 'hopefully know', 'know fact', 'fact usually', 'usually cheese', 'cheese dont', 'dont eat', 'eat mouse', 'mouse theres', 'theres semantic', 'semantic knowledge', 'knowledge less', 'less likely', 'likely first', 'first sentence', 'sentence high', 'high level', 'level language', 'language models', 'models one', 'one word', 'word youve', 'youve probably', 'probably hearing', 'hearing lot', 'lot news', 'news generative', 'generative models', 'models something', 'something generate', 'generate models', 'models generate', 'generate sentences', 'sentences generate', 'generate data', 'data reason', 'reason know', 'know say', 'say language', 'language models', 'models genitive', 'genitive models', 'models model', 'model distribution', 'distribution simply', 'simply sample', 'sample model', 'model generate', 'generate data', 'data generate', 'generate sentences', 'sentences using', 'using language', 'language model', 'model type', 'type models', 'models people', 'people currently', 'currently using', 'using call', 'call autoregressive', 'autoregressive language', 'language models', 'models key', 'key idea', 'idea autoregressive', 'autoregressive language', 'language models', 'models take', 'take distribution', 'distribution words', 'words decompose', 'decompose distribution', 'distribution first', 'first word', 'word multiply', 'multiply distribution', 'distribution likelihood', 'likelihood second', 'second word', 'word given', 'given first', 'first word', 'word multiply', 'multiply p', 'p third', 'third word', 'word given', 'given first', 'first two', 'two words', 'words theres', 'theres approximation', 'approximation chain', 'chain rule', 'rule probability', 'probability hopefully', 'hopefully know', 'know really', 'really approximation', 'approximation one', 'one way', 'way modeling', 'modeling distribution', 'distribution slightly', 'slightly concisely', 'concisely write', 'write product', 'product ps', 'ps next', 'next word', 'word given', 'given everything', 'everything happened', 'happened past', 'past context', 'context call', 'call autoregressive', 'autoregressive language', 'language models', 'models really', 'really way', 'way modeling', 'modeling distribution', 'distribution one', 'one way', 'way benefits', 'benefits downsides', 'downsides one', 'one downside', 'downside autoregressive', 'autoregressive language', 'language models', 'models sample', 'sample autoregressive', 'autoregressive language', 'language model', 'model full', 'full loop', 'loop generates', 'generates next', 'next word', 'word conditions', 'conditions next', 'next word', 'word regenerate', 'regenerate words', 'words longer', 'longer sentence', 'sentence want', 'want generate', 'generate takes', 'takes time', 'time generate', 'generate downsides', 'downsides current', 'current paradigm', 'paradigm thats', 'thats currently', 'currently im', 'im going', 'going talk', 'talk one', 'one great', 'great autoregressive', 'autoregressive language', 'language models', 'models high', 'high level', 'level task', 'task autoregressive', 'autoregressive language', 'language model', 'model simply', 'simply predicting', 'predicting next', 'next word', 'word said', 'said sentence', 'sentence likely', 'likely prefers', 'prefers one', 'one potential', 'potential next', 'next word', 'word might', 'might dogs', 'dogs way', 'way first', 'first tokenize', 'tokenize take', 'take words', 'words sub', 'sub words', 'words tokenize', 'tokenize give', 'give id', 'id token', 'token one', 'one two', 'two three', 'three pass', 'pass black', 'black box', 'box already', 'already said', 'said going', 'going talk', 'talk architecture', 'architecture pass', 'pass model', 'model get', 'get distribution', 'distribution probability', 'probability distribution', 'distribution next', 'next word', 'word next', 'next token', 'token sample', 'sample distribution', 'distribution get', 'get new', 'new token', 'token detokenize', 'detokenize get', 'get new', 'new id', 'id get', 'get detokenize', 'detokenize thats', 'thats sample', 'sample language', 'language model', 'model one', 'one thing', 'thing important', 'important note', 'note last', 'last two', 'two steps', 'steps needed', 'needed inference', 'inference training', 'training need', 'need predict', 'predict likely', 'likely token', 'token compare', 'compare real', 'real token', 'token happened', 'happened practice', 'practice change', 'change weights', 'weights model', 'model increase', 'increase probability', 'probability generating', 'generating token', 'token great', 'great progressive', 'progressive neural', 'neural language', 'language models', 'models slightly', 'slightly specific', 'specific still', 'still without', 'without talking', 'talking architecture', 'architecture first', 'first thing', 'thing yes', 'yes predicting', 'predicting probability', 'probability next', 'next token', 'token may', 'may final', 'final output', 'output vector', 'vector dimensionality', 'dimensionality number', 'number tokens', 'tokens yes', 'yes deal', 'deal increase', 'increase adding', 'adding tokens', 'tokens tokens', 'tokens private', 'private sample', 'sample yeah', 'yeah going', 'going talk', 'talk tokenization', 'tokenization later', 'later get', 'get sense', 'sense deal', 'deal adding', 'adding new', 'new tokens', 'tokens im', 'im kind', 'kind exaggerating', 'exaggerating methods', 'methods essentially', 'essentially people', 'people dont', 'dont really', 'really important', 'important think', 'think tokenize', 'tokenize text', 'text thats', 'thats well', 'well talk', 'talk later', 'later good', 'good point', 'point notice', 'notice vocabulary', 'vocabulary size', 'size number', 'number tokens', 'tokens essentially', 'essentially output', 'output language', 'language model', 'model pretty', 'pretty large', 'large ok', 'ok autoregressive', 'autoregressive new', 'new language', 'language models', 'models first', 'first thing', 'thing take', 'take every', 'every word', 'word every', 'every token', 'token embed', 'embed get', 'get vector', 'vector representation', 'representation tokens', 'tokens pass', 'pass neural', 'neural network', 'network said', 'said transformer', 'transformer get', 'get representation', 'representation words', 'words context', 'context representation', 'representation entire', 'entire sentence', 'sentence pass', 'pass linear', 'linear layer', 'layer said', 'said map', 'map number', 'number output', 'output number', 'number outputs', 'outputs number', 'number tokens', 'tokens pass', 'pass softmax', 'softmax get', 'get probability', 'probability distribution', 'distribution next', 'next words', 'words given', 'given every', 'every word', 'word context', 'context last', 'last use', 'use essentially', 'essentially task', 'task classifying', 'classifying next', 'next token', 'token simple', 'simple kind', 'kind machine', 'machine learning', 'learning task', 'task use', 'use crosscentral', 'crosscentral p', 'p loss', 'loss look', 'look actual', 'actual target', 'target happened', 'happened target', 'target distribution', 'distribution onehot', 'onehot encoding', 'encoding case', 'case says', 'says saw', 'saw real', 'real one', 'one happened', 'happened cat', 'cat onehot', 'onehot distribution', 'distribution cat', 'cat actual', 'actual see', 'see mouse', 'mouse oh', 'oh yeah', 'yeah distribution', 'distribution generate', 'generate generated', 'generated see', 'see cross', 'cross entropy', 'entropy really', 'really increases', 'increases probability', 'probability generating', 'generating cat', 'cat decreases', 'decreases probability', 'probability generating', 'generating tokens', 'tokens one', 'one thing', 'thing notice', 'notice know', 'know equivalent', 'equivalent maximizing', 'maximizing text', 'text log', 'log text', 'text log', 'log likelihood', 'likelihood rewrite', 'rewrite max', 'max probability', 'probability autogressive', 'autogressive language', 'language modeling', 'modeling task', 'task minimum', 'minimum added', 'added log', 'log minus', 'minus minimum', 'minimum loss', 'loss cross', 'cross entropy', 'entropy loss', 'loss minimizing', 'minimizing loss', 'loss thing', 'thing maximizing', 'maximizing likelihood', 'likelihood text', 'text question', 'question questions', 'questions tokenizer', 'tokenizer one', 'one thing', 'thing people', 'people usually', 'usually dont', 'dont talk', 'talk much', 'much tokenizers', 'tokenizers extremely', 'extremely important', 'important really', 'really important', 'important kind', 'kind understand', 'understand least', 'least high', 'high level', 'level need', 'need tokenizers', 'tokenizers first', 'first place', 'place first', 'first general', 'general words', 'words one', 'one simple', 'simple thing', 'thing might', 'might think', 'think oh', 'oh going', 'going take', 'take every', 'every word', 'word say', 'say every', 'every word', 'word token', 'token happens', 'happens theres', 'theres typo', 'typo word', 'word might', 'might token', 'token associated', 'associated word', 'word typo', 'typo dont', 'dont know', 'know pass', 'pass word', 'word typo', 'typo large', 'large language', 'language model', 'model next', 'next also', 'also even', 'even think', 'think words', 'words words', 'words words', 'words fine', 'fine latinbased', 'latinbased languages', 'languages think', 'think language', 'language thai', 'thai wont', 'wont simple', 'simple way', 'way tokenizing', 'tokenizing spaces', 'spaces spaces', 'spaces words', 'words really', 'really tokens', 'tokens much', 'much general', 'general words', 'words first', 'first thing', 'thing second', 'second thing', 'thing might', 'might think', 'think might', 'might tokenize', 'tokenize every', 'every sentence', 'sentence character', 'character character', 'character might', 'might say', 'say one', 'one token', 'token b', 'b another', 'another token', 'token would', 'would work', 'work probably', 'probably well', 'well issue', 'issue sequence', 'sequence becomes', 'becomes super', 'super long', 'long probably', 'probably remember', 'remember lecture', 'lecture transformers', 'transformers complexity', 'complexity grows', 'grows quadratically', 'quadratically length', 'length sequences', 'sequences really', 'really dont', 'dont want', 'want super', 'super long', 'long sequence', 'sequence tokenizers', 'tokenizers try', 'try deal', 'deal two', 'two problems', 'problems give', 'give common', 'common sub', 'sub sequences', 'sequences certain', 'certain token', 'token usually', 'usually thinking', 'thinking around', 'around average', 'average every', 'every token', 'token around', 'around three', 'three four', 'four letters', 'letters many', 'many algorithms', 'algorithms tokenization', 'tokenization ill', 'ill talk', 'talk one', 'one give', 'give high', 'high level', 'level call', 'call bytepaying', 'bytepaying coding', 'coding pretty', 'pretty common', 'common one', 'one two', 'two common', 'common tokenizers', 'tokenizers way', 'way train', 'train tokenizer', 'tokenizer first', 'first start', 'start large', 'large corpus', 'corpus text', 'text im', 'im really', 'really talking', 'talking training', 'training large', 'large language', 'language model', 'model yet', 'yet purely', 'purely tokenization', 'tokenization step', 'step large', 'large corpus', 'corpus text', 'text five', 'five words', 'words associate', 'associate every', 'every character', 'character corpus', 'corpus text', 'text different', 'different token', 'token split', 'split character', 'character different', 'different token', 'token call', 'call tokens', 'tokens go', 'go text', 'text every', 'every time', 'time see', 'see pairs', 'pairs tokens', 'tokens common', 'common common', 'common pair', 'pair token', 'token merge', 'merge see', 'see three', 'three times', 'times tokens', 'tokens next', 'next youre', 'youre gon', 'gon na', 'na say', 'say new', 'new token', 'token continue', 'continue repeat', 'repeat talk', 'talk happens', 'happens three', 'three times', 'times talk', 'talk e', 'e happens', 'happens sorry', 'sorry two', 'two times', 'times token', 'token happens', 'happens twice', 'twice ex', 'ex also', 'also happened', 'happened twice', 'twice train', 'train tokenizer', 'tokenizer corpus', 'corpus text', 'text small', 'small thats', 'thats would', 'would finish', 'finish token', 'token treat', 'treat trained', 'trained tokenizer', 'tokenizer reality', 'reality much', 'much larger', 'larger corpus', 'corpus text', 'text real', 'real tokenizer', 'tokenizer think', 'think gpt3', 'gpt3 chgpd', 'chgpd see', 'see would', 'would separate', 'separate words', 'words see', 'see thing', 'thing gave', 'gave previous', 'previous example', 'example token', 'token becomes', 'becomes token', 'token tokenizer', 'tokenizer split', 'split two', 'two tokens', 'tokens token', 'token andizer', 'andizer yeah', 'yeah thats', 'thats tokenizers', 'tokenizers question', 'question yeah', 'yeah yeah', 'yeah yeah', 'yeah theres', 'theres step', 'step tokenizers', 'tokenizers call', 'call pre', 'pre tokenizers', 'tokenizers exactly', 'exactly said', 'said mostly', 'mostly theory', 'theory theres', 'theres reason', 'reason deal', 'deal spaces', 'spaces punctuation', 'punctuation separately', 'separately could', 'could say', 'say every', 'every space', 'space gets', 'gets token', 'token every', 'every punctuation', 'punctuation gets', 'gets token', 'token could', 'could merging', 'merging problem', 'problem theres', 'theres efficiency', 'efficiency question', 'question training', 'training tokenizers', 'tokenizers takes', 'takes long', 'long time', 'time youre', 'youre better', 'better consider', 'consider every', 'every pair', 'pair token', 'token end', 'end saying', 'saying theres', 'theres space', 'space pre', 'pre tokenizers', 'tokenizers english', 'english specific', 'specific say', 'say theres', 'theres space', 'space going', 'going start', 'start looking', 'looking token', 'token came', 'came token', 'token came', 'came afterwards', 'afterwards youre', 'youre merging', 'merging spaces', 'spaces computation', 'computation optimization', 'optimization could', 'could theoretically', 'theoretically deal', 'deal way', 'way character', 'character yeah', 'yeah merge', 'merge tokens', 'tokens top', 'top tokens', 'tokens merged', 'merged height', 'height smaller', 'smaller token', 'token keep', 'keep smaller', 'smaller tokens', 'tokens mean', 'mean reality', 'reality doesnt', 'doesnt matter', 'matter much', 'much usually', 'usually large', 'large corpus', 'corpus text', 'text everything', 'everything usually', 'usually keep', 'keep small', 'small ones', 'ones reason', 'reason want', 'want case', 'case theres', 'theres said', 'said grammatical', 'grammatical mistakes', 'mistakes typos', 'typos still', 'still want', 'want able', 'able represent', 'represent words', 'words character', 'character yeah', 'yeah yes', 'yes yes', 'yes tokens', 'tokens unique', 'unique mean', 'mean say', 'say case', 'case token', 'token one', 'one occurrence', 'occurrence need', 'need need', 'need multiple', 'multiple occurrence', 'occurrence take', 'take different', 'different meetings', 'meetings see', 'see oh', 'oh see', 'see would', 'would say', 'say every', 'every token', 'token unique', 'unique id', 'id great', 'great question', 'question example', 'example think', 'think bank', 'bank could', 'could bank', 'bank money', 'money bank', 'bank water', 'water token', 'token model', 'model learn', 'learn transformer', 'transformer learn', 'learn based', 'based words', 'words around', 'around associate', 'associate im', 'im saying', 'saying im', 'im hindrower', 'hindrower associate', 'associate representation', 'representation either', 'either bank', 'bank money', 'money side', 'side bank', 'bank water', 'water side', 'side thats', 'thats transformer', 'transformer tokenizer', 'tokenizer yes', 'yes yes', 'yes mentioned', 'mentioned tokenization', 'tokenization theres', 'theres smaller', 'smaller tokens', 'tokens trying', 'trying say', 'say keep', 'keep dont', 'dont need', 'need tokenize', 'tokenize external', 'external icon', 'icon tokenize', 'tokenize lets', 'lets say', 'say maybe', 'maybe didnt', 'didnt even', 'even tokenize', 'tokenize data', 'data trying', 'trying encode', 'encode token', 'token tokenizer', 'tokenizer know', 'know code', 'code token', 'token react', 'react yes', 'yes great', 'great question', 'question tokenize', 'tokenize thats', 'thats training', 'training tokenizer', 'tokenizer apply', 'apply tokenizer', 'tokenizer always', 'always choose', 'choose largest', 'largest token', 'token apply', 'apply token', 'token never', 'never always', 'always token', 'token theres', 'theres people', 'people dont', 'dont really', 'really talk', 'talk much', 'much tokenizers', 'tokenizers theres', 'theres lot', 'lot computational', 'computational benefits', 'benefits computational', 'computational tricks', 'tricks making', 'making things', 'things faster', 'faster really', 'really dont', 'dont think', 'think honestly', 'honestly think', 'think lot', 'lot people', 'people think', 'think get', 'get away', 'away tokenizers', 'tokenizers kind', 'kind tokenize', 'tokenize character', 'character character', 'character bytes', 'bytes bytes', 'bytes said', 'said right', 'right issue', 'issue length', 'length maybe', 'maybe one', 'one day', 'day five', 'five 10', '10 years', 'years well', 'well different', 'different architectures', 'architectures dont', 'dont scale', 'scale credetically', 'credetically length', 'length sequence', 'sequence maybe', 'maybe well', 'well move', 'move away', 'away tokenizers', 'tokenizers sure', 'sure us', 'us drawback', 'drawback give', 'give people', 'people one', 'one move', 'move away', 'away tokenizer', 'tokenizer oh', 'oh yeah', 'yeah think', 'think one', 'one good', 'good example', 'example math', 'math think', 'think math', 'math numbers', 'numbers right', 'right tokenized', 'tokenized example', 'example 327', '327 might', 'might token', 'token means', 'means models', 'models see', 'see numbers', 'numbers dont', 'dont see', 'see way', 'way annoying', 'annoying reason', 'reason kind', 'kind generalize', 'generalize math', 'math deal', 'deal every', 'every letter', 'letter separately', 'separately composition', 'composition know', 'know add', 'add stuff', 'stuff thing', 'thing adding', 'adding every', 'every one', 'one separately', 'separately plus', 'plus whatever', 'whatever unit', 'unit add', 'add special', 'special tokenization', 'tokenization one', 'one big', 'big changes', 'changes gpt', 'gpt forwarded', 'forwarded changed', 'changed way', 'way tokenize', 'tokenize code', 'code example', 'example code', 'code know', 'know often', 'often python', 'python four', 'four spaces', 'spaces beginning', 'beginning dealt', 'dealt kind', 'kind strangely', 'strangely result', 'result model', 'model couldnt', 'couldnt really', 'really understand', 'understand deal', 'deal code', 'code tokenization', 'tokenization matters', 'matters lot', 'lot ill', 'ill move', 'move right', 'right come', 'come back', 'back later', 'later tokenizers', 'tokenizers great', 'great talked', 'talked task', 'task last', 'last tokenizer', 'tokenizer lets', 'lets talk', 'talk little', 'little bit', 'bit evaluation', 'evaluation way', 'way llms', 'llms usually', 'usually evaluated', 'evaluated call', 'call using', 'using call', 'call poplexity', 'poplexity high', 'high level', 'level validation', 'validation loss', 'loss slight', 'slight difference', 'difference poplexity', 'poplexity use', 'use something', 'something slightly', 'slightly vulnerable', 'vulnerable use', 'use average', 'average per', 'per token', 'token loss', 'loss exponentiate', 'exponentiate reason', 'reason exponentiate', 'exponentiate want', 'want mean', 'mean loss', 'loss log', 'log inside', 'inside one', 'one humans', 'humans pretty', 'pretty bad', 'bad thinking', 'thinking log', 'log space', 'space two', 'two logs', 'logs depend', 'depend base', 'base log', 'log exponentiate', 'exponentiate everything', 'everything kind', 'kind vocabulary', 'vocabulary size', 'size unit', 'unit average', 'average token', 'token poplexity', 'poplexity independent', 'independent length', 'length sequence', 'sequence poplexity', 'poplexity power', 'power average', 'average loss', 'loss sequence', 'sequence perplexity', 'perplexity one', 'one length', 'length vocabulary', 'vocabulary tokenizer', 'tokenizer one', 'one simply', 'simply well', 'well predict', 'predict perfectly', 'perfectly thing', 'thing every', 'every word', 'word every', 'every word', 'word product', 'product ones', 'ones best', 'best perplexity', 'perplexity one', 'one really', 'really idea', 'idea predict', 'predict one', 'one divided', 'divided size', 'size vocabulary', 'vocabulary simple', 'simple math', 'math get', 'get perplexity', 'perplexity size', 'size vocabulary', 'vocabulary tuition', 'tuition perplexity', 'perplexity number', 'number tokens', 'tokens youre', 'youre model', 'model kind', 'kind hesitating', 'hesitating youre', 'youre model', 'model perfect', 'perfect doesnt', 'doesnt hesitate', 'hesitate exactly', 'exactly word', 'word really', 'really idea', 'idea hesitates', 'hesitates vocabulary', 'vocabulary perplexity', 'perplexity really', 'really improved', 'improved thats', 'thats perplexity', 'perplexity standard', 'standard data', 'data set', 'set 2017', '2017 2023', '2023 went', 'went kind', 'kind 70', '70 tokens', 'tokens less', 'less 10', '10 tokens', 'tokens five', 'five six', 'six years', 'years means', 'means models', 'models previously', 'previously dated', 'dated 70', '70 words', 'words every', 'every time', 'time generating', 'generating word', 'word dating', 'dating less', 'less 10', '10 words', 'words thats', 'thats much', 'much better', 'better complexity', 'complexity used', 'used anymore', 'anymore academic', 'academic benchmarking', 'benchmarking sick', 'sick depends', 'depends tokenizer', 'tokenizer use', 'use depends', 'depends actual', 'actual data', 'data people', 'people evaluating', 'evaluating still', 'still important', 'important development', 'development llms', 'llms train', 'train llm', 'llm people', 'people still', 'still really', 'really look', 'look complexity', 'complexity one', 'one common', 'common way', 'way common', 'common academia', 'academia evaluating', 'evaluating llms', 'llms taking', 'taking classical', 'classical nlp', 'nlp benchmarks', 'benchmarks ill', 'ill give', 'give examples', 'examples later', 'later kind', 'kind aggregating', 'aggregating everything', 'everything collect', 'collect many', 'many automatically', 'automatically evaluable', 'evaluable benchmarks', 'benchmarks evaluate', 'evaluate across', 'across one', 'one two', 'two benchmarks', 'benchmarks call', 'call helm', 'helm stanford', 'stanford another', 'another one', 'one hugging', 'hugging face', 'face open', 'open llm', 'llm lead', 'lead award', 'award probably', 'probably two', 'two common', 'common ones', 'ones right', 'right give', 'give idea', 'idea type', 'type tasks', 'tasks mostly', 'mostly things', 'things easily', 'easily evaluated', 'evaluated question', 'question answering', 'answering think', 'think many', 'many different', 'different question', 'question answering', 'answering tasks', 'tasks benefit', 'benefit question', 'question answering', 'answering usually', 'usually know', 'know real', 'real answer', 'answer way', 'way evaluate', 'evaluate models', 'models ill', 'ill give', 'give concrete', 'concrete example', 'example one', 'one second', 'second look', 'look likely', 'likely language', 'language model', 'model generate', 'generate real', 'real answer', 'answer compared', 'compared answers', 'answers thats', 'thats essentially', 'essentially high', 'high level', 'level evaluate', 'evaluate models', 'models give', 'give specific', 'specific example', 'example mmlu', 'mmlu probably', 'probably common', 'common academic', 'academic benchmark', 'benchmark lms', 'lms collection', 'collection many', 'many question', 'question answers', 'answers domains', 'domains example', 'example college', 'college medicine', 'medicine college', 'college physics', 'physics astronomy', 'astronomy type', 'type topics', 'topics questions', 'questions things', 'things astronomy', 'astronomy true', 'true type', 'type 1a', '1a supernova', 'supernova give', 'give 4', '4 different', 'different potential', 'potential answers', 'answers ask', 'ask model', 'model one', 'one likely', 'likely many', 'many different', 'different ways', 'ways either', 'either look', 'look likelihood', 'likelihood generating', 'generating answers', 'answers ask', 'ask model', 'model one', 'one likely', 'likely different', 'different ways', 'ways prompt', 'prompt model', 'model high', 'high level', 'level know', 'know one', 'one correct', 'correct three', 'three mistakes', 'mistakes yes', 'yes creating', 'creating unconstrained', 'unconstrained text', 'text thats', 'thats funny', 'funny yeah', 'yeah downtothemodel', 'downtothemodel gives', 'gives something', 'something thats', 'thats know', 'know semantically', 'semantically completely', 'completely identical', 'identical exact', 'exact totalist', 'totalist expect', 'expect yeah', 'yeah thats', 'thats great', 'great question', 'question ill', 'ill talk', 'talk later', 'later case', 'case dont', 'dont unconstrained', 'unconstrained way', 'way would', 'would evaluate', 'evaluate mmlu', 'mmlu either', 'either look', 'look first', 'first question', 'question look', 'look likelihood', 'likelihood model', 'model generating', 'generating likelihood', 'likelihood model', 'model generating', 'generating b', 'b c', 'c look', 'look one', 'one likely', 'likely oh', 'oh ask', 'ask model', 'model abcd', 'abcd one', 'one likely', 'likely look', 'look model', 'model look', 'look extokin', 'extokin b', 'b c', 'c stream', 'stream model', 'model say', 'say answer', 'answer four', 'four things', 'things say', 'say stream', 'stream model', 'model yeah', 'yeah stream', 'stream prompt', 'prompt mean', 'mean whole', 'whole probability', 'probability distribution', 'distribution outfits', 'outfits youre', 'youre comparing', 'comparing outfits', 'outfits youre', 'youre comparing', 'comparing atunkin', 'atunkin yeah', 'yeah second', 'second case', 'case gave', 'gave would', 'would exactly', 'exactly would', 'would first', 'first model', 'model saying', 'saying b', 'b c', 'c plus', 'plus would', 'would consume', 'consume look', 'look four', 'four tokens', 'tokens first', 'first case', 'case dont', 'dont even', 'even need', 'need generate', 'generate anything', 'anything first', 'first case', 'case literally', 'literally look', 'look given', 'given language', 'language model', 'model give', 'give distribution', 'distribution sentences', 'sentences look', 'look likelihood', 'likelihood generating', 'generating words', 'words likelihood', 'likelihood generating', 'generating second', 'second choice', 'choice look', 'look whether', 'whether likely', 'likely sentence', 'sentence real', 'real answer', 'answer youre', 'youre sample', 'sample really', 'really use', 'use p', 'p x1', 'x1 xl', 'xl make', 'make sense', 'sense sense', 'sense said', 'said evaluation', 'evaluation openended', 'openended questions', 'questions something', 'something going', 'going talk', 'talk later', 'later really', 'really important', 'important really', 'really challenging', 'challenging yes', 'yes earlier', 'earlier mentioned', 'mentioned metrics', 'metrics complexity', 'complexity usually', 'usually used', 'used depends', 'depends design', 'design choices', 'choices also', 'also want', 'want speak', 'speak oh', 'oh yeah', 'yeah think', 'think complexity', 'complexity told', 'told complexity', 'complexity one', 'one vocabulary', 'vocabulary size', 'size imagine', 'imagine chatgpt', 'chatgpt uses', 'uses tokenizer', 'tokenizer 10000', '10000 tokens', 'tokens gemini', 'gemini google', 'google uses', 'uses tokenizer', 'tokenizer 100000', '100000 potential', 'potential tokens', 'tokens gemini', 'gemini one', 'one upper', 'upper bound', 'bound complexity', 'complexity get', 'get worse', 'worse gemini', 'gemini chatgpt', 'chatgpt make', 'make sense', 'sense thats', 'thats idea', 'idea little', 'little bit', 'bit complicated', 'complicated theres', 'theres one', 'one first', 'first bit', 'bit see', 'see tokenizer', 'tokenizer matters', 'matters great', 'great ok', 'ok evaluation', 'evaluation challenges', 'challenges many', 'many ill', 'ill talk', 'talk two', 'two really', 'really briefly', 'briefly one', 'one told', 'told two', 'two ways', 'ways evaluation', 'evaluation mml', 'mml views', 'views many', 'many two', 'two give', 'give two', 'two examples', 'examples happens', 'happens long', 'long time', 'time even', 'even though', 'though classical', 'classical benchmark', 'benchmark everyone', 'everyone used', 'used different', 'different companies', 'companies different', 'different organization', 'organization using', 'using different', 'different ways', 'ways evaluating', 'evaluating mml', 'mml view', 'view result', 'result get', 'get completely', 'completely different', 'different results', 'results example', 'example lamas', 'lamas 65b', '65b first', 'first model', 'model meta', 'meta lamas', 'lamas series', 'series helm', 'helm 637', '637 accuracy', 'accuracy benchmark', 'benchmark 488', '488 really', 'really way', 'way evaluate', 'evaluate even', 'even talking', 'talking prompting', 'prompting really', 'really kind', 'kind way', 'way evaluate', 'evaluate models', 'models promoting', 'promoting another', 'another issue', 'issue really', 'really lot', 'lot inconsistencies', 'inconsistencies easy', 'easy looks', 'looks first', 'first thing', 'thing yeah', 'yeah sorry', 'sorry make', 'make sure', 'sure models', 'models arent', 'arent trained', 'trained bench', 'bench model', 'model second', 'second thing', 'thing great', 'great question', 'question train', 'train test', 'test contamination', 'contamination something', 'something would', 'would say', 'say really', 'really important', 'important academia', 'academia given', 'given talk', 'talk mostly', 'mostly training', 'training large', 'large language', 'language models', 'models companies', 'companies maybe', 'maybe important', 'important know', 'know trained', 'trained us', 'us idea', 'idea far', 'far real', 'real problem', 'problem many', 'many different', 'different ways', 'ways trying', 'trying test', 'test set', 'set sorry', 'sorry whether', 'whether test', 'test set', 'set training', 'training set', 'set one', 'one kind', 'kind cut', 'cut trick', 'trick people', 'people lab', 'lab tetsus', 'tetsus lab', 'lab found', 'found given', 'given data', 'data set', 'set online', 'online randomized', 'randomized look', 'look language', 'language models', 'models predict', 'predict next', 'next word', 'word look', 'look entire', 'entire test', 'test set', 'set generate', 'generate examples', 'examples order', 'order versus', 'versus examples', 'examples different', 'different order', 'order likely', 'likely generate', 'generate thing', 'thing order', 'order given', 'given theres', 'theres real', 'real order', 'order means', 'means probably', 'probably training', 'training set', 'set make', 'make sense', 'sense many', 'many thats', 'thats one', 'one many', 'many ways', 'ways train', 'train test', 'test contamination', 'contamination important', 'important development', 'development really', 'really important', 'important academic', 'academic benchmarking', 'benchmarking great', 'great many', 'many challenges', 'challenges ill', 'ill move', 'move great', 'great data', 'data data', 'data another', 'another really', 'really big', 'big topic', 'topic high', 'high level', 'level people', 'people say', 'say oh', 'oh train', 'train large', 'large language', 'language models', 'models internet', 'internet even', 'even mean', 'mean people', 'people sometimes', 'sometimes say', 'say clean', 'clean internet', 'internet even', 'even less', 'less fun', 'fun internet', 'internet dirty', 'dirty really', 'really representative', 'representative one', 'one practice', 'practice download', 'download random', 'random website', 'website right', 'right would', 'would shocked', 'shocked definitely', 'definitely wikipedia', 'wikipedia ill', 'ill go', 'go really', 'really briefly', 'briefly people', 'people answer', 'answer questions', 'questions data', 'data huge', 'huge topic', 'topic first', 'first download', 'download internet', 'internet means', 'means use', 'use web', 'web crawlers', 'crawlers go', 'go every', 'every web', 'web page', 'page internet', 'internet every', 'every web', 'web page', 'page google', 'google around', 'around 250', '250 billion', 'billion pages', 'pages right', 'right thats', 'thats around', 'around one', 'one petabyte', 'petabyte data', 'data common', 'common crawl', 'crawl one', 'one web', 'web crawler', 'crawler people', 'people usually', 'usually write', 'write web', 'web crawlers', 'crawlers use', 'use standard', 'standard web', 'web crawlers', 'crawlers common', 'common crawl', 'crawl one', 'one every', 'every month', 'month adds', 'adds new', 'new websites', 'websites added', 'added internet', 'internet found', 'found google', 'google put', 'put big', 'big big', 'big data', 'data set', 'set thats', 'thats common', 'common quall', 'quall around', 'around 250', '250 billion', 'billion pages', 'pages right', 'right 1', '1 e6', 'e6 gigabytes', 'gigabytes data', 'data random', 'random web', 'web page', 'page literally', 'literally random', 'random common', 'common quall', 'quall see', 'see im', 'im one', 'one really', 'really doesnt', 'doesnt look', 'look type', 'type things', 'things would', 'would usually', 'usually see', 'see html', 'html page', 'page hard', 'hard see', 'see look', 'look see', 'see content', 'content example', 'example test', 'test king', 'king world', 'world ultimate', 'ultimate source', 'source system', 'system xhigh', 'xhigh performance', 'performance server', 'server three', 'three dots', 'dots dont', 'dont even', 'even sentence', 'sentence even', 'even finished', 'finished thats', 'thats random', 'random internet', 'internet looks', 'looks course', 'course useful', 'useful train', 'train large', 'large language', 'language model', 'model generate', 'generate things', 'things steps', 'steps needed', 'needed first', 'first one', 'one extract', 'extract text', 'text html', 'html thats', 'thats tried', 'tried looking', 'looking correct', 'correct text', 'text lot', 'lot challenges', 'challenges example', 'example extracting', 'extracting math', 'math common', 'common complicated', 'complicated pretty', 'pretty important', 'important training', 'training large', 'large language', 'language models', 'models example', 'example boilerplates', 'boilerplates lot', 'lot forums', 'forums type', 'type headers', 'headers type', 'type footers', 'footers dont', 'dont want', 'want repeat', 'repeat data', 'data filter', 'filter undesirable', 'undesirable content', 'content safe', 'safe work', 'work harmful', 'harmful content', 'content pii', 'pii usually', 'usually every', 'every company', 'company blacklist', 'blacklist websites', 'websites dont', 'dont want', 'want train', 'train models', 'models blacklist', 'blacklist long', 'long say', 'say comes', 'comes dont', 'dont train', 'train ways', 'ways things', 'things train', 'train small', 'small model', 'model classifying', 'classifying pii', 'pii removing', 'removing things', 'things hard', 'hard every', 'every point', 'point im', 'im going', 'going show', 'show hard', 'hard amount', 'amount work', 'work im', 'im going', 'going go', 'go quickly', 'quickly filter', 'filter undesirable', 'undesirable content', 'content second', 'second fourth', 'fourth duplication', 'duplication said', 'said might', 'might things', 'things headers', 'headers footers', 'footers forums', 'forums always', 'always want', 'want remove', 'remove another', 'another thing', 'thing might', 'might lot', 'lot urls', 'urls different', 'different show', 'show website', 'website might', 'might also', 'also lot', 'lot paragraphs', 'paragraphs come', 'come common', 'common books', 'books dedoubligated', 'dedoubligated thousand', 'thousand times', 'times 10000', '10000 times', 'times internet', 'internet need', 'need dedoubligate', 'dedoubligate also', 'also challenging', 'challenging scale', 'scale dedoubligation', 'dedoubligation heuristic', 'heuristic filtering', 'filtering try', 'try remove', 'remove lowquality', 'lowquality documents', 'documents way', 'way things', 'things rulesbased', 'rulesbased filtering', 'filtering example', 'example see', 'see outlier', 'outlier tokens', 'tokens distribution', 'distribution tokens', 'tokens website', 'website different', 'different usual', 'usual distribution', 'distribution tokens', 'tokens probably', 'probably outlier', 'outlier see', 'see length', 'length words', 'words website', 'website super', 'super long', 'long theres', 'theres something', 'something strange', 'strange going', 'going website', 'website see', 'see website', 'website three', 'three words', 'words maybe', 'maybe worth', 'worth training', 'training maybe', 'maybe 10', '10 million', 'million words', 'words maybe', 'maybe theres', 'theres something', 'something also', 'also wrong', 'wrong going', 'going page', 'page lot', 'lot rules', 'rules yes', 'yes undesirable', 'undesirable content', 'content data', 'data set', 'set instead', 'instead kind', 'kind supervised', 'supervised mass', 'mass say', 'say heres', 'heres hate', 'hate speech', 'speech website', 'website thats', 'thats actively', 'actively trying', 'trying actively', 'actively penalize', 'penalize data', 'data well', 'well exactly', 'exactly step', 'step thats', 'thats post', 'post training', 'training come', 'come pretraining', 'pretraining idea', 'idea say', 'say want', 'want model', 'model kind', 'kind humans', 'humans speak', 'speak essentially', 'essentially want', 'want remove', 'remove headers', 'headers photos', 'photos menus', 'menus things', 'things good', 'good idea', 'idea thats', 'thats exactly', 'exactly well', 'well later', 'later next', 'next step', 'step model', 'model base', 'base field', 'field training', 'training youve', 'youve filtered', 'filtered lot', 'lot data', 'data thats', 'thats cute', 'cute trick', 'trick take', 'take wikipedia', 'wikipedia look', 'look links', 'links linked', 'linked wikipedia', 'wikipedia pages', 'pages probably', 'probably something', 'something wikipedia', 'wikipedia probably', 'probably highquality', 'highquality website', 'website train', 'train classifier', 'classifier predict', 'predict whether', 'whether something', 'something comes', 'comes whether', 'whether document', 'document comes', 'comes one', 'one references', 'references wikipedia', 'wikipedia whether', 'whether random', 'random web', 'web try', 'try say', 'say want', 'want things', 'things come', 'come wikipedia', 'wikipedia references', 'references make', 'make sense', 'sense yeah', 'yeah train', 'train machine', 'machine learning', 'learning model', 'model usually', 'usually also', 'also simple', 'simple models', 'models need', 'need really', 'really scale', 'scale mean', 'mean think', 'think 250', '250 billion', 'billion pages', 'pages next', 'next one', 'one try', 'try classify', 'classify data', 'data different', 'different domains', 'domains say', 'say ok', 'ok entertainment', 'entertainment books', 'books code', 'code type', 'type domains', 'domains try', 'try either', 'either downweight', 'downweight domains', 'domains example', 'example might', 'might say', 'say might', 'might see', 'see train', 'train code', 'code model', 'model becomes', 'becomes better', 'better reasoning', 'reasoning thats', 'thats something', 'something people', 'people people', 'people usually', 'usually say', 'say handwaver', 'handwaver way', 'way train', 'train model', 'model code', 'code helps', 'helps reasoning', 'reasoning want', 'want upweight', 'upweight coding', 'coding distribution', 'distribution helps', 'helps general', 'general language', 'language modeling', 'modeling skills', 'skills books', 'books usually', 'usually also', 'also another', 'another one', 'one people', 'people usually', 'usually upweight', 'upweight entertainment', 'entertainment usually', 'usually downweight', 'downweight things', 'things course', 'course want', 'want people', 'people used', 'used maybe', 'maybe kind', 'kind heuristically', 'heuristically theres', 'theres entire', 'entire pipelines', 'pipelines well', 'well talk', 'talk things', 'things slightly', 'slightly automatically', 'automatically end', 'end training', 'training usually', 'usually training', 'training data', 'data saw', 'saw usually', 'usually train', 'train highquality', 'highquality data', 'data end', 'end training', 'training large', 'large language', 'language model', 'model decrease', 'decrease learning', 'learning rate', 'rate means', 'means youre', 'youre kind', 'kind overfitting', 'overfitting model', 'model highquality', 'highquality data', 'data usually', 'usually wikipedia', 'wikipedia overfit', 'overfit wikipedia', 'wikipedia overfit', 'overfit human', 'human data', 'data collected', 'collected thing', 'thing continue', 'continue pretraining', 'pretraining forgetting', 'forgetting longer', 'longer context', 'context im', 'im going', 'going skip', 'skip things', 'things give', 'give sense', 'sense hard', 'hard people', 'people say', 'say oh', 'oh im', 'im going', 'going train', 'train internet', 'internet thats', 'thats lot', 'lot work', 'work really', 'really havent', 'havent figured', 'figured yet', 'yet collecting', 'collecting well', 'well data', 'data huge', 'huge part', 'part practical', 'practical large', 'large language', 'language model', 'model might', 'might say', 'say key', 'key yes', 'yes data', 'data theres', 'theres question', 'question usually', 'usually would', 'would install', 'install term', 'term write', 'write data', 'data go', 'go masters', 'masters suppose', 'suppose typical', 'typical amount', 'amount large', 'large seems', 'seems big', 'big deal', 'deal go', 'go data', 'data steps', 'steps took', 'took question', 'question large', 'large data', 'data filter', 'filter yes', 'yes feel', 'feel good', 'good go', 'go large', 'large seems', 'seems need', 'need go', 'go field', 'field order', 'order future', 'future systems', 'systems slow', 'slow many', 'many people', 'people would', 'would need', 'need oh', 'oh going', 'going video', 'video ok', 'ok thats', 'thats great', 'great question', 'question im', 'im going', 'going somewhat', 'somewhat answer', 'answer data', 'data large', 'large dataset', 'dataset end', 'end slide', 'slide number', 'number people', 'people work', 'work thats', 'thats great', 'great question', 'question im', 'im quite', 'quite sure', 'sure would', 'would say', 'say yeah', 'yeah dont', 'dont quite', 'quite know', 'know would', 'would say', 'say probably', 'probably even', 'even bigger', 'bigger number', 'number people', 'people work', 'work kind', 'kind tuning', 'tuning pretraining', 'pretraining model', 'model data', 'data bigger', 'bigger kind', 'kind modeling', 'modeling aspect', 'aspect yeah', 'yeah dont', 'dont think', 'think good', 'good sense', 'sense would', 'would say', 'say probably', 'probably lamas', 'lamas team', 'team 70', '70 hp', 'hp people', 'people would', 'would say', 'say maybe', 'maybe 15', '15 work', 'work data', 'data yeah', 'yeah things', 'things dont', 'dont need', 'need many', 'many people', 'people need', 'need lot', 'lot computer', 'computer also', 'also data', 'data need', 'need lot', 'lot cpus', 'cpus yeah', 'yeah ill', 'ill answer', 'answer second', 'second question', 'question end', 'end slide', 'slide kind', 'kind alluded', 'alluded really', 'really installed', 'installed data', 'data pretraining', 'pretraining theres', 'theres lot', 'lot research', 'research done', 'done first', 'first process', 'process things', 'things super', 'super efficiently', 'efficiently second', 'second balance', 'balance different', 'different domains', 'domains synthetic', 'synthetic data', 'data generation', 'generation thats', 'thats big', 'big one', 'one right', 'right dont', 'dont well', 'well talk', 'talk later', 'later dont', 'dont enough', 'enough data', 'data internet', 'internet use', 'use multimodal', 'multimodal data', 'data instead', 'instead text', 'text data', 'data improve', 'improve even', 'even text', 'text performance', 'performance theres', 'theres lot', 'lot secrecy', 'secrecy really', 'really key', 'key pretrained', 'pretrained large', 'large language', 'language models', 'models competitive', 'competitive dynamics', 'dynamics usually', 'usually companies', 'companies dont', 'dont talk', 'talk data', 'data collection', 'collection also', 'also theres', 'theres copyright', 'copyright liability', 'liability issue', 'issue definitely', 'definitely dont', 'dont want', 'want tell', 'tell theyve', 'theyve trained', 'trained books', 'books even', 'even though', 'though sue', 'sue common', 'common academic', 'academic benchmarks', 'benchmarks kind', 'kind answer', 'answer asked', 'asked smaller', 'smaller ones', 'ones names', 'names important', 'important decide', 'decide head', 'head around', 'around 150', '150 billion', 'billion tokens', 'tokens around', 'around 800', '800 gigabytes', 'gigabytes data', 'data around', 'around 15', '15 trillion', 'trillion tokens', 'tokens also', 'also size', 'size models', 'models right', 'right best', 'best models', 'models probably', 'probably trained', 'trained amount', 'amount data', 'data 15', '15 trillion', 'trillion tokens', 'tokens probably', 'probably guess', 'guess two', 'two bigger', 'bigger 80', '80 e3', 'e3 gigabyte', 'gigabyte would', 'would around', 'around 100', '100 1000', '1000 times', 'times filtering', 'filtering common', 'common crawl', 'crawl im', 'im mistaken', 'mistaken yeah', 'yeah one', 'one famous', 'famous one', 'one pile', 'pile academic', 'academic benchmark', 'benchmark pile', 'pile look', 'look distribution', 'distribution data', 'data sings', 'sings archive', 'archive pubmed', 'pubmed central', 'central biology', 'biology stuff', 'stuff wikipedia', 'wikipedia see', 'see stack', 'stack exchange', 'exchange github', 'github books', 'books things', 'things smaller', 'smaller side', 'side look', 'look 280b', '280b reality', 'reality 100', '100 times', 'times bigger', 'bigger much', 'much github', 'github wikipedia', 'wikipedia terms', 'terms closed', 'closed source', 'source models', 'models give', 'give idea', 'idea lamat', 'lamat 2', '2 trained', 'trained two', 'two trillion', 'trillion tokens', 'tokens lamat', 'lamat 3', '3 15', '15 trillion', 'trillion tokens', 'tokens currently', 'currently best', 'best model', 'model know', 'know much', 'much trained', 'trained thing', 'thing best', 'best academic', 'academic biggest', 'biggest academic', 'academic benchmark', 'benchmark 15', '15 trillion', 'trillion tokens', 'tokens gpd', 'gpd 4', '4 dont', 'dont really', 'really know', 'know probably', 'probably order', 'order magnitude', 'magnitude probably', 'probably around', 'around probably', 'probably around', 'around 13', '13 leaks', 'leaks leaks', 'leaks true', 'true great', 'great scaling', 'scaling loss', 'loss questions', 'questions data', 'data go', 'go scaling', 'scaling loss', 'loss sorry', 'sorry know', 'know im', 'im giving', 'giving lot', 'lot information', 'information theres', 'theres lot', 'lot training', 'training large', 'large language', 'language models', 'models great', 'great scaling', 'scaling loss', 'loss idea', 'idea people', 'people saw', 'saw around', 'around 2020', '2020 least', 'least long', 'long time', 'time theyve', 'theyve able', 'able kind', 'kind theoretically', 'theoretically show', 'show impurity', 'impurity show', 'show since', 'since 2020', '2020 data', 'data train', 'train models', 'models larger', 'larger models', 'models better', 'better performance', 'performance pretty', 'pretty different', 'different youve', 'youve seen', 'seen class', 'class class', 'class teach', 'teach overfitting', 'overfitting overfitting', 'overfitting doesnt', 'doesnt happen', 'happen large', 'large language', 'language models', 'models larger', 'larger models', 'models better', 'better performance', 'performance something', 'something really', 'really took', 'took long', 'long time', 'time community', 'community took', 'took type', 'type class', 'class realize', 'realize exam', 'exam overfitting', 'overfitting exists', 'exists idea', 'idea scaling', 'scaling loss', 'loss given', 'given know', 'know data', 'data larger', 'larger models', 'models always', 'always give', 'give better', 'better performance', 'performance predict', 'predict much', 'much better', 'better performance', 'performance increase', 'increase amount', 'amount data', 'data size', 'size model', 'model surprisingly', 'surprisingly works', 'works see', 'see three', 'three plus', 'plus famous', 'famous paper', 'paper called', 'called scaling', 'scaling loss', 'loss openai', 'openai see', 'see xaxis', 'xaxis compute', 'compute much', 'much train', 'train much', 'much compute', 'compute spent', 'spent training', 'training see', 'see test', 'test loss', 'loss essentially', 'essentially mean', 'mean perplexity', 'perplexity validation', 'validation loss', 'loss log', 'log perplexity', 'perplexity put', 'put two', 'two log', 'log scale', 'scale see', 'see performance', 'performance sorry', 'sorry scaling', 'scaling law', 'law linear', 'linear means', 'means increase', 'increase compute', 'compute certain', 'certain amount', 'amount say', 'say much', 'much test', 'test loss', 'loss decrease', 'decrease thing', 'thing data', 'data thing', 'thing parameters', 'parameters increase', 'increase data', 'data set', 'set size', 'size loss', 'loss decrease', 'decrease amount', 'amount somewhat', 'somewhat predictable', 'predictable increase', 'increase number', 'number parameters', 'parameters decrease', 'decrease loss', 'loss decrease', 'decrease amount', 'amount somewhat', 'somewhat predictable', 'predictable really', 'really amazing', 'amazing surprising', 'surprising mean', 'mean looks', 'looks innocuous', 'innocuous look', 'look type', 'type plots', 'plots thats', 'thats crazy', 'crazy means', 'means predict', 'predict well', 'well going', 'going perform', 'perform two', 'two three', 'three years', 'years depending', 'depending much', 'much compute', 'compute add', 'add assuming', 'assuming things', 'things hold', 'hold theres', 'theres nothing', 'nothing theoretical', 'theoretical yes', 'yes loss', 'loss user', 'user proplexity', 'proplexity said', 'said proplexity', 'proplexity 2', '2 power', 'power loss', 'loss power', 'power proplexity', 'proplexity second', 'second thing', 'thing dont', 'dont increase', 'increase number', 'number parameters', 'parameters increase', 'increase total', 'total data', 'data set', 'set size', 'size number', 'number application', 'application time', 'time doesnt', 'doesnt increase', 'increase compute', 'compute work', 'work many', 'many data', 'data oh', 'oh yes', 'yes great', 'great question', 'question compute', 'compute factor', 'factor two', 'two things', 'things data', 'data parameter', 'parameter im', 'im showing', 'showing well', 'well going', 'going talk', 'talk details', 'details increase', 'increase number', 'number parameters', 'parameters increase', 'increase number', 'number data', 'data dont', 'dont go', 'go multiple', 'multiple times', 'times data', 'data set', 'set one', 'one epochs', 'epochs least', 'least yet', 'yet havent', 'havent still', 'still kind', 'kind enough', 'enough data', 'data yeah', 'yeah trend', 'trend increased', 'increased compute', 'compute decreased', 'decreased loss', 'loss yes', 'yes seen', 'seen numbers', 'numbers last', 'last two', 'two years', 'years still', 'still holding', 'holding still', 'still holding', 'holding dont', 'dont good', 'good numbers', 'numbers show', 'show still', 'still holding', 'holding surprisingly', 'surprisingly yes', 'yes draw', 'draw evidence', 'evidence procoevent', 'procoevent youve', 'youve never', 'never thought', 'thought cant', 'cant draw', 'draw expected', 'expected value', 'value right', 'right empirical', 'empirical evidence', 'evidence plateauing', 'plateauing time', 'time soon', 'soon dont', 'dont know', 'know well', 'well happened', 'happened probably', 'probably mean', 'mean doesnt', 'doesnt need', 'need log', 'log scale', 'scale go', 'go plateau', 'plateau mathematically', 'mathematically could', 'could continue', 'continue decreasing', 'decreasing mean', 'mean people', 'people think', 'think probably', 'probably plateau', 'plateau point', 'point dont', 'dont know', 'know thats', 'thats talk', 'talk scaling', 'scaling loss', 'loss scaling', 'scaling loss', 'loss really', 'really cool', 'cool imagine', 'imagine give', 'give youre', 'youre fortunate', 'fortunate give', 'give 10000', '10000 gpus', 'gpus month', 'month model', 'model train', 'train even', 'even go', 'go answering', 'answering question', 'question mean', 'mean hypothetical', 'hypothetical thats', 'thats exactly', 'exactly companies', 'companies faced', 'faced old', 'old pipeline', 'pipeline two', 'two high', 'high parameters', 'parameters big', 'big models', 'models lets', 'lets say', 'say 30', '30 days', 'days train', 'train 30', '30 models', 'models one', 'one day', 'day pick', 'pick best', 'best one', 'one final', 'final model', 'model use', 'use production', 'production means', 'means model', 'model used', 'used trained', 'trained one', 'one day', 'day new', 'new pipeline', 'pipeline first', 'first find', 'find scaling', 'scaling recipe', 'recipe find', 'find something', 'something tells', 'tells example', 'example one', 'one common', 'common thing', 'thing increase', 'increase size', 'size model', 'model decrease', 'decrease learning', 'learning rate', 'rate find', 'find scaling', 'scaling recipe', 'recipe know', 'know increase', 'increase size', 'size model', 'model heres', 'heres high', 'high parameters', 'parameters tune', 'tune high', 'high parameters', 'parameters smaller', 'smaller models', 'models different', 'different sizes', 'sizes lets', 'lets say', 'say say', 'say three', 'three days', 'days 30', '30 days', 'days train', 'train many', 'many different', 'different models', 'models highpreparameter', 'highpreparameter tuning', 'tuning small', 'small models', 'models different', 'different sizes', 'sizes fit', 'fit scaling', 'scaling law', 'law try', 'try extrapolate', 'extrapolate smaller', 'smaller models', 'models one', 'one best', 'best train', 'train much', 'much longer', 'longer oh', 'oh sorry', 'sorry train', 'train larger', 'larger model', 'model train', 'train final', 'final huge', 'huge model', 'model 27', '27 days', 'days instead', 'instead one', 'one day', 'day new', 'new pipeline', 'pipeline train', 'train things', 'things highpreparameter', 'highpreparameter tuning', 'tuning real', 'real scale', 'scale model', 'model youre', 'youre going', 'going use', 'use practice', 'practice things', 'things smaller', 'smaller ones', 'ones different', 'different scales', 'scales try', 'try predict', 'predict well', 'well perform', 'perform make', 'make bigger', 'bigger give', 'give give', 'give concrete', 'concrete example', 'example right', 'right lets', 'lets say', 'say transformers', 'transformers versus', 'versus lstms', 'lstms lets', 'lets say', 'say youre', 'youre yous', 'yous 10000', '10000 gpus', 'gpus youre', 'youre sure', 'sure one', 'one using', 'using using', 'using transformable', 'transformable base', 'base model', 'model scm', 'scm base', 'base model', 'model train', 'train transformers', 'transformers different', 'different scales', 'scales see', 'see different', 'different parameters', 'parameters xaxis', 'xaxis yaxis', 'yaxis test', 'test source', 'source show', 'show different', 'different lstms', 'lstms different', 'different scales', 'scales points', 'points see', 'see oh', 'oh kind', 'kind fits', 'fits scaling', 'scaling law', 'law fit', 'fit scaling', 'scaling law', 'law able', 'able predict', 'predict oh', 'oh 10', '10 times', 'times compute', 'compute heres', 'heres well', 'well would', 'would perform', 'perform lstm', 'lstm slightly', 'slightly less', 'less linear', 'linear lstm', 'lstm could', 'could probably', 'probably try', 'try predict', 'predict would', 'would end', 'end clearly', 'clearly plot', 'plot would', 'would see', 'see transformers', 'transformers better', 'better one', 'one thing', 'thing notice', 'notice read', 'read types', 'types scaling', 'scaling laws', 'laws two', 'two things', 'things important', 'important one', 'one really', 'really scaling', 'scaling rate', 'rate kind', 'kind slope', 'slope scaling', 'scaling law', 'law thing', 'thing intercept', 'intercept could', 'could start', 'start worse', 'worse become', 'become better', 'better time', 'time happens', 'happens lstms', 'lstms worse', 'worse could', 'could show', 'show another', 'another one', 'one things', 'things predict', 'predict certain', 'certain scale', 'scale youre', 'youre better', 'better using', 'using type', 'type model', 'model others', 'others thats', 'thats scaling', 'scaling laws', 'laws really', 'really useful', 'useful questions', 'questions yeah', 'yeah kind', 'kind sensitive', 'sensitive art', 'art small', 'small difference', 'difference architecture', 'architecture one', 'one light', 'light transfer', 'transfer architecture', 'architecture versus', 'versus another', 'another transfer', 'transfer architecture', 'architecture pick', 'pick curve', 'curve say', 'say oh', 'oh scaling', 'scaling tell', 'tell logarithmic', 'logarithmic function', 'function yeah', 'yeah yeah', 'yeah usually', 'usually example', 'example youre', 'youre academic', 'academic want', 'want least', 'least thats', 'thats pretty', 'pretty recent', 'recent want', 'want propose', 'propose new', 'new activation', 'activation thats', 'thats exactly', 'exactly fit', 'fit scaling', 'scaling law', 'law show', 'show another', 'another scaling', 'scaling law', 'law standard', 'standard dont', 'dont know', 'know gailu', 'gailu say', 'say better', 'better reality', 'reality start', 'start thinking', 'thinking scaling', 'scaling laws', 'laws terms', 'terms really', 'really realize', 'realize architecture', 'architecture differences', 'differences make', 'make small', 'small minor', 'minor ones', 'ones maybe', 'maybe changed', 'changed little', 'little bit', 'bit intercept', 'intercept really', 'really doesnt', 'doesnt matter', 'matter train', 'train 10', '10 hours', 'hours longer', 'longer wait', 'wait next', 'next gpus', 'gpus things', 'things really', 'really secondary', 'secondary exactly', 'exactly telling', 'telling originally', 'originally people', 'people spend', 'spend much', 'much time', 'time architecture', 'architecture losses', 'losses reality', 'reality things', 'things dont', 'dont matter', 'matter much', 'much data', 'data though', 'though use', 'use good', 'good data', 'data much', 'much better', 'better scaling', 'scaling loss', 'loss use', 'use bad', 'bad data', 'data really', 'really matters', 'matters another', 'another really', 'really cool', 'cool thing', 'thing scaling', 'scaling loss', 'loss ask', 'ask optimally', 'optimally allocate', 'allocate training', 'training resources', 'resources train', 'train larger', 'larger models', 'models thought', 'thought better', 'better train', 'train larger', 'larger models', 'models thought', 'thought also', 'also better', 'better use', 'use data', 'data one', 'one train', 'train data', 'data smaller', 'smaller model', 'model train', 'train larger', 'larger model', 'model less', 'less data', 'data chintilla', 'chintilla famous', 'famous paper', 'paper first', 'first showed', 'showed way', 'way want', 'want give', 'give little', 'little bit', 'bit sense', 'sense plots', 'plots see', 'see training', 'training loss', 'loss xaxis', 'xaxis see', 'see parameter', 'parameter differences', 'differences sorry', 'sorry number', 'number parameters', 'parameters size', 'size model', 'model curves', 'curves call', 'call isoflops', 'isoflops models', 'models curve', 'curve trained', 'trained amount', 'amount compute', 'compute way', 'way change', 'change vary', 'vary number', 'number tokens', 'tokens trained', 'trained size', 'size models', 'models vary', 'vary way', 'way total', 'total compute', 'compute constant', 'constant curves', 'curves see', 'see different', 'different colors', 'colors different', 'different amount', 'amount compute', 'compute trained', 'trained take', 'take best', 'best one', 'one curves', 'curves best', 'best one', 'one curves', 'curves plot', 'plot much', 'much flops', 'flops curve', 'curve much', 'much parameters', 'parameters use', 'use training', 'training specific', 'specific point', 'point put', 'put log', 'log log', 'log scale', 'scale fit', 'fit scaling', 'scaling log', 'log something', 'something tells', 'tells want', 'want train', 'train model', 'model 10', '10 power', 'power 23', '23 flops', 'flops heres', 'heres exactly', 'exactly number', 'number parameters', 'parameters using', 'using 100', '100 b', 'b thing', 'thing flops', 'flops tokens', 'tokens predict', 'predict tell', 'tell exactly', 'exactly one', 'one month', 'month compute', 'compute size', 'size model', 'model training', 'training figure', 'figure scaling', 'scaling law', 'law tell', 'tell course', 'course looks', 'looks beautiful', 'beautiful reality', 'reality theres', 'theres lot', 'lot small', 'small things', 'things counting', 'counting embedding', 'embedding parameters', 'parameters theres', 'theres lot', 'lot complexities', 'complexities things', 'things well', 'well things', 'things hold', 'hold optimal', 'optimal number', 'number parameters', 'parameters shinchilla', 'shinchilla people', 'people found', 'found use', 'use 20', '20 tokens', 'tokens every', 'every parameter', 'parameter train', 'train add', 'add one', 'one parameter', 'parameter train', 'train thing', 'thing model', 'model 20', '20 tokens', 'tokens one', 'one caveat', 'caveat optimal', 'optimal training', 'training resources', 'resources telling', 'telling 10', '10 power', 'power 23', '23 flops', 'flops 100', '100 dont', 'dont know', 'know much', 'much 100', '100 million', 'million 5', '5 million', 'million 10', '10 would', 'would smudge', 'smudge less', 'less id', 'id say', 'say 5', '5 million', 'million train', 'train best', 'best model', 'model gets', 'gets lowest', 'lowest loss', 'loss would', 'would train', 'train reality', 'reality companies', 'companies need', 'need think', 'think inference', 'inference also', 'also smaller', 'smaller model', 'model spend', 'spend less', 'less time', 'time consider', 'consider inference', 'inference cost', 'cost papers', 'papers try', 'try show', 'show around', 'around 150', '150 parameters', 'parameters sorry', 'sorry tokens', 'tokens per', 'per parameters', 'parameters prefer', 'prefer smaller', 'smaller model', 'model time', 'time youre', 'youre going', 'going spend', 'spend less', 'less money', 'money inference', 'inference models', 'models 150', '150 one', 'one thats', 'thats around', 'around best', 'best models', 'models trained', 'trained right', 'right least', 'least ones', 'ones used', 'used practice', 'practice production', 'production great', 'great question', 'question chichol', 'chichol great', 'great im', 'im sorry', 'sorry expensive', 'expensive really', 'really small', 'small really', 'really good', 'good train', 'train expensive', 'expensive talk', 'talk first', 'first would', 'would another', 'another entire', 'entire lecture', 'lecture think', 'think chat', 'chat gpt', 'gpt dont', 'dont know', 'know much', 'much 600', '600 million', 'million people', 'people use', 'use thats', 'thats lot', 'lot expensive', 'expensive theres', 'theres lot', 'lot optimization', 'optimization inference', 'inference though', 'though thats', 'thats entire', 'entire lecture', 'lecture im', 'im going', 'going skip', 'skip time', 'time interesting', 'interesting ok', 'ok two', 'two things', 'things said', 'said many', 'many things', 'things answer', 'answer scaling', 'scaling loss', 'loss try', 'try give', 'give two', 'two examples', 'examples really', 'really many', 'many things', 'things data', 'data use', 'use mixer', 'mixer data', 'data mixing', 'mixing waiting', 'waiting use', 'use data', 'data mixers', 'mixers thats', 'thats talked', 'talked architecture', 'architecture use', 'use whether', 'whether make', 'make models', 'models wider', 'wider deeper', 'deeper paying', 'paying gpus', 'gpus collecting', 'collecting data', 'data things', 'things things', 'things try', 'try answer', 'answer scaling', 'scaling loss', 'loss one', 'one thing', 'thing want', 'want say', 'say bitter', 'bitter lesson', 'lesson ever', 'ever heard', 'heard richard', 'richard sutton', 'sutton famous', 'famous blog', 'blog post', 'post 2019', '2019 realized', 'realized think', 'think enough', 'enough people', 'people realized', 'realized didnt', 'didnt definitely', 'definitely realize', 'realize time', 'time see', 'see type', 'type scaling', 'scaling loss', 'loss know', 'know compute', 'compute better', 'better models', 'models get', 'get scale', 'scale get', 'get better', 'better model', 'model also', 'also know', 'know mozilla', 'mozilla type', 'type variants', 'variants mozilla', 'mozilla always', 'always better', 'better compute', 'compute thing', 'thing matters', 'matters architectures', 'architectures leverage', 'leverage computation', 'computation matters', 'matters systems', 'systems data', 'data less', 'less architecture', 'architecture small', 'small architecture', 'architecture differences', 'differences activation', 'activation things', 'things think', 'think thats', 'thats one', 'one reasons', 'reasons research', 'research focuses', 'focuses things', 'things industry', 'industry matters', 'matters less', 'less one', 'one researchers', 'researchers large', 'large part', 'part career', 'career dont', 'dont spend', 'spend time', 'time overcomplicating', 'overcomplicating simple', 'simple things', 'things well', 'well seal', 'seal thats', 'thats really', 'really openai', 'openai taught', 'taught us', 'us chatgpt', 'chatgpt gps', 'gps ok', 'ok want', 'want give', 'give backoftheenvelope', 'backoftheenvelope computations', 'computations might', 'might factors', 'factors want', 'want give', 'give sense', 'sense costly', 'costly train', 'train models', 'models ill', 'ill give', 'give example', 'example lamat', 'lamat 300b', '300b currently', 'currently best', 'best open', 'open source', 'source model', 'model get', 'get trained', 'trained 156', '156 tokens', 'tokens 405', '405 billion', 'billion parameters', 'parameters know', 'know optimal', 'optimal tokens', 'tokens parameter', 'parameter thats', 'thats around', 'around 40', '40 thats', 'thats little', 'little bit', 'bit chinchilla', 'chinchilla less', 'less inference', 'inference optimal', 'optimal model', 'model went', 'went training', 'training optimality', 'optimality flops', 'flops model', 'model one', 'one simple', 'simple way', 'way compute', 'compute flops', 'flops six', 'six times', 'times number', 'number parameters', 'parameters times', 'times number', 'number data', 'data train', 'train simple', 'simple calculation', 'calculation 38e25', '38e25 flops', 'flops reason', 'reason important', 'important follow', 'follow little', 'little bit', 'bit news', 'news theres', 'theres executive', 'executive order', 'order biden', 'biden says', 'says want', 'want 1e26', '1e26 parameters', 'parameters sorry', 'sorry flops', 'flops special', 'special scrutiny', 'scrutiny models', 'models went', 'went 2x', '2x less', 'less really', 'really went', 'went right', 'right special', 'special scrutiny', 'scrutiny 3', '3 8', '8 might', 'might little', 'little bit', 'bit definitely', 'definitely 1e26', '1e26 p', 'p parameters', 'parameters n', 'n data', 'data number', 'number tokens', 'tokens approximation', 'approximation yeah', 'yeah compute', 'compute know', 'know train', 'train 16000', '16000 h100s', 'h100s know', 'know throughput', 'throughput set', 'set computation', 'computation takes', 'takes around', 'around 70', '70 days', 'days 26', '26 million', 'million gpu', 'gpu hours', 'hours least', 'least thats', 'thats backoftheenvelope', 'backoftheenvelope computation', 'computation said', 'said used', 'used 30', '30 million', 'million instead', 'instead 26', '26 million', 'million gpu', 'gpu hours', 'hours maybe', 'maybe challenges', 'challenges dont', 'dont really', 'really know', 'know follow', 'follow simple', 'simple computation', 'computation around', 'around 70', '70 days', 'days cost', 'cost mean', 'mean hard', 'hard approximate', 'approximate im', 'im going', 'going say', 'say kind', 'kind rent', 'rent rent', 'rent h100s', 'h100s many', 'many h100s', 'h100s many', 'many days', 'days much', 'much pay', 'pay h100', 'h100 lower', 'lower bound', 'bound renting', 'renting cost', 'cost h100', 'h100 around', 'around two', 'two hours', 'hours 2', '2 per', 'per hour', 'hour multiply', 'multiply 26', '26 million', 'million hours', 'hours get', 'get 52', '52 million', 'million probably', 'probably pay', 'pay less', 'less much', 'much less', 'less services', 'services rent', 'rent gpus', 'gpus dont', 'dont make', 'make much', 'much money', 'money probably', 'probably slightly', 'slightly less', 'less much', 'much less', 'less salary', 'salary said', 'said 50', '50 employees', 'employees 500k', '500k per', 'per year', 'year yeah', 'yeah probably', 'probably right', 'right bullpock', 'bullpock 25', '25 million', 'million put', 'put together', 'together around', 'around 75', '75 million', 'million dollars', 'dollars training', 'training slammer', 'slammer model', 'model im', 'im probably', 'probably 10', '10 million', 'million thats', 'thats kind', 'kind right', 'right bullpock', 'bullpock carbon', 'carbon emitted', 'emitted lot', 'lot people', 'people might', 'might ask', 'ask also', 'also cost', 'cost thing', 'thing important', 'important computation', 'computation around', 'around 4000', '4000 tons', 'tons co2', 'co2 equivalent', 'equivalent 2000', '2000 return', 'return tickets', 'tickets jfk', 'jfk london', 'london right', 'right carbon', 'carbon emitted', 'emitted mean', 'mean huge', 'huge meaningful', 'meaningful yet', 'yet think', 'think maybe', 'maybe gpt', 'gpt 6', '6 gpt', 'gpt multiply', 'multiply 100', '100 might', 'might become', 'become real', 'real issue', 'issue right', 'right still', 'still think', 'think issue', 'issue grand', 'grand scheme', 'scheme things', 'things next', 'next model', 'model way', 'way thinking', 'thinking models', 'models every', 'every new', 'new generation', 'generation number', 'number flops', 'flops essentially', 'essentially multiplies', 'multiplies 10x', '10x well', 'well least', 'least thats', 'thats try', 'try enough', 'enough energy', 'energy buy', 'buy enough', 'enough gpus', 'gpus great', 'great question', 'question backup', 'backup dna', 'dna envelope', 'envelope math', 'math talked', 'talked pretraining', 'pretraining wanted', 'wanted also', 'also chat', 'chat systems', 'systems know', 'know compute', 'compute really', 'really important', 'important theres', 'theres question', 'question optimize', 'optimize compute', 'compute leave', 'leave end', 'end im', 'im sure', 'sure much', 'much time', 'time think', 'think important', 'important hopefully', 'hopefully ill', 'ill able', 'able talk', 'talk later', 'later slightly', 'slightly different', 'different weve', 'weve talking', 'talking right', 'right ill', 'ill move', 'move posttraining', 'posttraining task', 'task posttraining', 'posttraining reason', 'reason need', 'need posttraining', 'posttraining told', 'told make', 'make ai', 'ai assistance', 'assistance language', 'language modeling', 'modeling really', 'really thing', 'thing want', 'want ai', 'ai assistant', 'assistant example', 'example ask', 'ask gpt3', 'gpt3 purely', 'purely language', 'language model', 'model pure', 'pure language', 'language model', 'model aligned', 'aligned one', 'one ask', 'ask question', 'question explain', 'explain moon', 'moon landing', 'landing sixyearold', 'sixyearold conclusion', 'conclusion would', 'would get', 'get something', 'something explain', 'explain theory', 'theory gravity', 'gravity sixyearold', 'sixyearold learned', 'learned internet', 'internet one', 'one question', 'question usually', 'usually maybe', 'maybe another', 'another bullet', 'bullet point', 'point similar', 'similar questions', 'questions dont', 'dont usually', 'usually question', 'question answer', 'answer later', 'later want', 'want ai', 'ai assistant', 'assistant alignment', 'alignment posttraining', 'posttraining making', 'making models', 'models assistance', 'assistance goal', 'goal alignment', 'alignment get', 'get lms', 'lms follow', 'follow instructions', 'instructions given', 'given users', 'users sign', 'sign maybe', 'maybe designers', 'designers kind', 'kind desires', 'desires think', 'think moderation', 'moderation dont', 'dont want', 'want model', 'model openair', 'openair definitely', 'definitely doesnt', 'doesnt want', 'want model', 'model say', 'say stuff', 'stuff toxic', 'toxic see', 'see left', 'left hand', 'hand side', 'side ask', 'ask question', 'question provides', 'provides real', 'real answer', 'answer llm', 'llm right', 'right hand', 'hand side', 'side see', 'see would', 'would ask', 'ask write', 'write tweet', 'tweet describing', 'describing certain', 'certain part', 'part population', 'population evil', 'evil say', 'say thats', 'thats kind', 'kind alignment', 'alignment background', 'background data', 'data want', 'want training', 'training models', 'models know', 'know want', 'want asking', 'asking humans', 'humans question', 'question answer', 'answer want', 'want thing', 'thing expensive', 'expensive collect', 'collect data', 'data hard', 'hard find', 'find online', 'online contrast', 'contrast pretraining', 'pretraining data', 'data want', 'want theres', 'theres lot', 'lot main', 'main idea', 'idea simply', 'simply take', 'take pretrained', 'pretrained large', 'large language', 'language model', 'model pretrained', 'pretrained internet', 'internet fine', 'fine tune', 'tune change', 'change little', 'little bit', 'bit weights', 'weights type', 'type data', 'data want', 'want hopefully', 'hopefully given', 'given youre', 'youre already', 'already pretrained', 'pretrained internet', 'internet learns', 'learns knows', 'knows speak', 'speak english', 'english knows', 'knows standard', 'standard language', 'language syntax', 'syntax really', 'really fine', 'fine tune', 'tune little', 'little data', 'data ok', 'ok sft', 'sft supervised', 'supervised fine', 'fine tuning', 'tuning really', 'really exactly', 'exactly said', 'said idea', 'idea fine', 'fine tuning', 'tuning large', 'large language', 'language model', 'model desired', 'desired answers', 'answers collected', 'collected humans', 'humans called', 'called supervised', 'supervised fine', 'fine tuning', 'tuning want', 'want language', 'language modeling', 'modeling real', 'real answers', 'answers language', 'language modeling', 'modeling next', 'next word', 'word prediction', 'prediction thats', 'thats fine', 'fine tuning', 'tuning part', 'part want', 'want desired', 'desired answers', 'answers given', 'given humans', 'humans thats', 'thats call', 'call supervised', 'supervised collect', 'collect data', 'data well', 'well said', 'said ask', 'ask humans', 'humans tell', 'tell question', 'question answer', 'answer would', 'would want', 'want something', 'something models', 'models example', 'example cant', 'cant read', 'read well', 'well computer', 'computer kid', 'kid needs', 'needs science', 'science lets', 'lets read', 'read one', 'one write', 'write short', 'short introduction', 'introduction relevance', 'relevance term', 'term monopsony', 'monopsony says', 'says monopsony', 'monopsony refers', 'refers market', 'market structure', 'structure blah', 'blah blah', 'blah blah', 'blah thats', 'thats human', 'human number', 'number open', 'open assistant', 'assistant way', 'way collect', 'collect data', 'data online', 'online humans', 'humans type', 'type supervised', 'supervised fine', 'fine tuning', 'tuning im', 'im really', 'really key', 'key chat', 'chat gpt', 'gpt made', 'made big', 'big jump', 'jump gpt3', 'gpt3 mostly', 'mostly something', 'something known', 'known ai', 'ai researchers', 'researchers chat', 'chat gpt', 'gpt became', 'became known', 'known everyone', 'everyone problem', 'problem human', 'human data', 'data slow', 'slow collect', 'collect expensive', 'expensive one', 'one percent', 'percent possible', 'possible simple', 'simple idea', 'idea use', 'use lms', 'lms scale', 'scale data', 'data collection', 'collection thats', 'thats exactly', 'exactly alpaca', 'alpaca one', 'one year', 'year ago', 'ago asked', 'asked humans', 'humans use', 'use data', 'data set', 'set human', 'human question', 'question answers', 'answers 175', '175 question', 'question answers', 'answers asked', 'asked best', 'best time', 'time texas', 'texas vincis', 'vincis user', 'user three', 'three generate', 'generate many', 'many question', 'question answers', 'answers humans', 'humans would', 'would write', 'write write', 'write similar', 'similar answers', 'answers similar', 'similar questions', 'questions collected', 'collected 52000', '52000 llm', 'llm generated', 'generated question', 'question answers', 'answers simply', 'simply took', 'took lamas', 'lamas 7b', '7b best', 'best pretrained', 'pretrained model', 'model time', 'time fine', 'fine tuned', 'tuned supervised', 'supervised fine', 'fine tuning', 'tuning told', 'told thats', 'thats got', 'got alpaca', 'alpaca 7b', '7b model', 'model type', 'type data', 'data collected', 'collected things', 'things algorithm', 'algorithm mean', 'mean algorithm', 'algorithm step', 'step step', 'step set', 'set instruction', 'instruction used', 'used solve', 'solve problem', 'problem achieve', 'achieve goal', 'goal blah', 'blah blah', 'blah blah', 'blah data', 'data pretty', 'pretty good', 'good given', 'given lm', 'lm gen', 'gen generated', 'generated llms', 'llms essentially', 'essentially two', 'two generations', 'generations ago', 'ago really', 'really started', 'started least', 'least us', 'us kind', 'kind academic', 'academic replication', 'replication chatgpt', 'chatgpt really', 'really big', 'big field', 'field synthetic', 'synthetic data', 'data generation', 'generation use', 'use llms', 'llms make', 'make development', 'development llms', 'llms faster', 'faster decreasing', 'decreasing amount', 'amount human', 'human hours', 'hours need', 'need quantity', 'quantity data', 'data talked', 'talked type', 'type data', 'data collected', 'collected one', 'one thing', 'thing surprising', 'surprising sft', 'sft dont', 'dont need', 'need much', 'much data', 'data paper', 'paper showed', 'showed called', 'called lima', 'lima scale', 'scale amount', 'amount data', 'data use', 'use supervised', 'supervised fine', 'fine training', 'training 2000', '2000 32000', '32000 really', 'really doesnt', 'doesnt help', 'help much', 'much scaling', 'scaling loss', 'loss definitely', 'definitely dont', 'dont help', 'help intuition', 'intuition learn', 'learn learn', 'learn format', 'format desired', 'desired answers', 'answers another', 'another way', 'way seeing', 'seeing pretrained', 'pretrained models', 'models essentially', 'essentially model', 'model distribution', 'distribution every', 'every user', 'user internet', 'internet one', 'one might', 'might write', 'write bullet', 'bullet points', 'points another', 'another one', 'one might', 'might answer', 'answer question', 'question answer', 'answer tell', 'tell model', 'model wait', 'wait optimizing', 'optimizing type', 'type user', 'user another', 'another one', 'one youre', 'youre teaching', 'teaching anything', 'anything sft', 'sft supervised', 'supervised fine', 'fine tuning', 'tuning tell', 'tell model', 'model kind', 'kind optimize', 'optimize one', 'one type', 'type user', 'user already', 'already pretrained', 'pretrained dataset', 'dataset knowledge', 'knowledge already', 'already pretrained', 'pretrained llm', 'llm specialize', 'specialize one', 'one type', 'type user', 'user great', 'great question', 'question sft', 'sft yes', 'yes know', 'know big', 'big issue', 'issue synthetic', 'synthetic data', 'data keep', 'keep generating', 'generating data', 'data distribution', 'distribution eventually', 'eventually youre', 'youre learning', 'learning new', 'new distribution', 'distribution youre', 'youre essentially', 'essentially playing', 'playing puts', 'puts track', 'track surely', 'surely cant', 'cant scale', 'scale way', 'way keep', 'keep going', 'going generating', 'generating data', 'data hope', 'hope learn', 'learn something', 'something new', 'new active', 'active area', 'area research', 'research youve', 'youve thought', 'thought around', 'around people', 'people maybe', 'maybe thinking', 'thinking around', 'around better', 'better ways', 'ways bootstrap', 'bootstrap give', 'give idea', 'idea realize', 'realize chart', 'chart shows', 'shows dont', 'dont need', 'need many', 'many get', 'get humans', 'humans generate', 'generate 2000', '2000 radiability', 'radiability yeah', 'yeah thats', 'thats good', 'good question', 'question data', 'data stuff', 'stuff im', 'im saying', 'saying important', 'important sett', 'sett another', 'another thing', 'thing well', 'well talk', 'talk right', 'right data', 'data matter', 'matter intuition', 'intuition based', 'based much', 'much empirical', 'empirical results', 'results still', 'still get', 'get even', 'even though', 'though use', 'use lms', 'lms use', 'use purely', 'purely lm', 'lm generated', 'generated text', 'text three', 'three four', 'four generations', 'generations lms', 'lms agree', 'agree probably', 'probably wont', 'wont improve', 'improve much', 'much important', 'important use', 'use human', 'human loop', 'loop lms', 'lms purely', 'purely lms', 'lms purely', 'purely humans', 'humans maybe', 'maybe model', 'model generate', 'generate new', 'new text', 'text humans', 'humans write', 'write edits', 'edits much', 'much f', 'f faster', 'faster writing', 'writing entire', 'entire text', 'text think', 'think type', 'type collaboration', 'collaboration information', 'information theoretical', 'theoretical point', 'point view', 'view still', 'still get', 'get additional', 'additional information', 'information youre', 'youre much', 'much faster', 'faster use', 'use humans', 'humans think', 'think field', 'field well', 'well probably', 'probably move', 'move towards', 'towards type', 'type things', 'things really', 'really finding', 'finding examples', 'examples important', 'important asking', 'asking humans', 'humans kind', 'kind active', 'active learning', 'learning asking', 'asking humans', 'humans exactly', 'exactly need', 'need get', 'get inputs', 'inputs yes', 'yes youre', 'youre trying', 'trying make', 'make loss', 'loss function', 'function general', 'general training', 'training supervised', 'supervised learning', 'learning pretraining', 'pretraining right', 'right examples', 'examples showed', 'showed think', 'think important', 'important thing', 'thing good', 'good examples', 'examples theyre', 'theyre super', 'super actionoriented', 'actionoriented theres', 'theres complex', 'complex things', 'things still', 'still changing', 'changing loss', 'loss thats', 'thats didnt', 'didnt maybe', 'maybe didnt', 'didnt emphasize', 'emphasize enough', 'enough language', 'language modeling', 'modeling finetune', 'finetune language', 'language model', 'model desired', 'desired answers', 'answers literally', 'literally loss', 'loss different', 'different two', 'two seconds', 'seconds first', 'first step', 'step sft', 'sft literally', 'literally loss', 'loss say', 'say want', 'want specialize', 'specialize type', 'type data', 'data theres', 'theres even', 'even question', 'question pretraining', 'pretraining posttraining', 'posttraining reality', 'reality different', 'different data', 'data use', 'use reason', 'reason usually', 'usually call', 'call posttraining', 'posttraining way', 'way collect', 'collect data', 'data different', 'different great', 'great great', 'great questions', 'questions yes', 'yes maybe', 'maybe question', 'question would', 'would 2000', '2000 examples', 'examples overweighted', 'overweighted influence', 'influence internet', 'internet thats', 'thats also', 'also thats', 'thats another', 'another reason', 'reason call', 'call posttraining', 'posttraining use', 'use different', 'different type', 'type hyper', 'hyper parameters', 'parameters know', 'know told', 'told end', 'end pretraining', 'pretraining essentially', 'essentially end', 'end learning', 'learning rate', 'rate zero', 'zero youre', 'youre going', 'going increase', 'increase learning', 'learning rate', 'rate 1', '1 e', 'e minus', 'minus 5', '5 1', '1 e', 'e minus', 'minus yeah', 'yeah way', 'way give', 'give different', 'different ok', 'ok second', 'second step', 'step second', 'second part', 'part posttraining', 'posttraining call', 'call reinforcement', 'reinforcement learning', 'learning human', 'human feedback', 'feedback hf', 'hf might', 'might heard', 'heard idea', 'idea sft', 'sft problem', 'problem namely', 'namely behavioral', 'behavioral cloning', 'cloning means', 'means try', 'try clone', 'clone humans', 'humans would', 'would say', 'say many', 'many issues', 'issues one', 'one youre', 'youre bound', 'bound human', 'human abilities', 'abilities humans', 'humans humans', 'humans wont', 'wont generate', 'generate things', 'things think', 'think best', 'best thing', 'thing generate', 'generate ask', 'ask write', 'write book', 'book mean', 'mean definitely', 'definitely enjoy', 'enjoy book', 'book probably', 'probably say', 'say one', 'one book', 'book better', 'better another', 'another im', 'im definitely', 'definitely going', 'going good', 'good writing', 'writing book', 'book want', 'want read', 'read youre', 'youre going', 'going bound', 'bound human', 'human ability', 'ability generate', 'generate things', 'things even', 'even though', 'though humans', 'humans might', 'might better', 'better distinguishing', 'distinguishing things', 'things thats', 'thats one', 'one issue', 'issue issue', 'issue number', 'number two', 'two find', 'find pretty', 'pretty interesting', 'interesting ever', 'ever heard', 'heard word', 'word house', 'house cination', 'cination llms', 'llms generating', 'generating false', 'false information', 'information house', 'house cination', 'cination might', 'might people', 'people hypothesized', 'hypothesized come', 'come supervised', 'supervised fine', 'fine tuning', 'tuning even', 'even supervised', 'supervised fine', 'fine tuning', 'tuning data', 'data correct', 'correct reason', 'reason given', 'given told', 'told sft', 'sft little', 'little data', 'data data', 'data doesnt', 'doesnt model', 'model doesnt', 'doesnt learn', 'learn anything', 'anything new', 'new human', 'human gives', 'gives answer', 'answer model', 'model didnt', 'didnt know', 'know true', 'true model', 'model perspective', 'perspective human', 'human telling', 'telling model', 'model generate', 'generate thing', 'thing seems', 'seems plausible', 'plausible idea', 'idea true', 'true give', 'give concrete', 'concrete example', 'example go', 'go back', 'back monopsony', 'monopsony example', 'example write', 'write blah', 'blah blah', 'blah blah', 'blah monopsony', 'monopsony imagine', 'imagine human', 'human rotor', 'rotor reference', 'reference type', 'type book', 'book book', 'book might', 'might exist', 'exist might', 'might correct', 'correct reference', 'reference llm', 'llm never', 'never saw', 'saw reference', 'reference pretraining', 'pretraining doesnt', 'doesnt know', 'know correct', 'correct reference', 'reference really', 'really tell', 'tell model', 'model generate', 'generate make', 'make plausibly', 'plausibly sounding', 'sounding reference', 'reference rather', 'rather tell', 'tell real', 'real reference', 'reference arguing', 'arguing pretraining', 'pretraining hallucination', 'hallucination might', 'might might', 'might caused', 'caused sft', 'sft thats', 'thats problem', 'problem number', 'number two', 'two make', 'make sense', 'sense great', 'great problem', 'problem number', 'number three', 'three price', 'price generating', 'generating ideal', 'ideal answers', 'answers pricing', 'pricing comes', 'comes back', 'back question', 'question humans', 'humans writing', 'writing entire', 'entire answer', 'answer pretty', 'pretty expensive', 'expensive thats', 'thats hf', 'hf comes', 'comes idea', 'idea instead', 'instead cloning', 'cloning behaviors', 'behaviors humans', 'humans going', 'going maximize', 'maximize human', 'human preference', 'preference way', 'way going', 'going pipeline', 'pipeline certain', 'certain every', 'every instruction', 'instruction youre', 'youre going', 'going ask', 'ask model', 'model generate', 'generate two', 'two answers', 'answers usually', 'usually use', 'use pretty', 'pretty good', 'good model', 'model usually', 'usually dont', 'dont use', 'use llm', 'llm use', 'use sft', 'sft fine', 'fine tune', 'tune use', 'use fine', 'fine tune', 'tune llm', 'llm already', 'already give', 'give pretty', 'pretty good', 'good answers', 'answers ask', 'ask labelers', 'labelers two', 'two answers', 'answers better', 'better select', 'select preferred', 'preferred one', 'one different', 'different type', 'type algorithms', 'algorithms going', 'going talk', 'talk algorithms', 'algorithms fine', 'fine tune', 'tune model', 'model generate', 'generate green', 'green thing', 'thing red', 'red thing', 'thing good', 'good stuff', 'stuff question', 'question going', 'going talk', 'talk right', 'right two', 'two ways', 'ways going', 'going talk', 'talk two', 'two mainly', 'mainly using', 'using community', 'community first', 'first one', 'one simply', 'simply idea', 'idea using', 'using reinforcement', 'reinforcement learning', 'learning hopefully', 'hopefully know', 'know reinforcement', 'reinforcement learning', 'learning think', 'think using', 'using reinforcement', 'reinforcement learning', 'learning one', 'one important', 'important question', 'question reward', 'reward optimizing', 'optimizing case', 'case really', 'really two', 'two options', 'options think', 'think first', 'first one', 'one could', 'could say', 'say im', 'im going', 'going compare', 'compare output', 'output generated', 'generated baseline', 'baseline output', 'output generated', 'generated model', 'model im', 'im going', 'going ask', 'ask human', 'human say', 'say one', 'one better', 'better im', 'im going', 'going use', 'use reward', 'reward im', 'im better', 'better baseline', 'baseline plus', 'plus one', 'one thats', 'thats minus', 'minus one', 'one binary', 'binary reward', 'reward problem', 'problem binary', 'binary reward', 'reward sparse', 'sparse dont', 'dont get', 'get much', 'much information', 'information maybe', 'maybe answered', 'answered slightly', 'slightly better', 'better maybe', 'maybe way', 'way better', 'better dont', 'dont really', 'really know', 'know much', 'much better', 'better option', 'option two', 'two train', 'train call', 'call reward', 'reward model', 'model simply', 'simply classifier', 'classifier use', 'use machine', 'machine learning', 'learning classify', 'classify much', 'much better', 'better two', 'two outputs', 'outputs perspective', 'perspective human', 'human theres', 'theres little', 'little bit', 'bit better', 'better train', 'train take', 'take real', 'real model', 'model r', 'r large', 'large also', 'also large', 'large classifier', 'classifier ask', 'ask reward', 'reward model', 'model give', 'give input', 'input actual', 'actual output', 'output one', 'one two', 'two outputs', 'outputs exponentially', 'exponentially thats', 'thats softmax', 'softmax class', 'class know', 'know divide', 'divide exponentialed', 'exponentialed reward', 'reward first', 'first example', 'example sorry', 'sorry first', 'first output', 'output second', 'second output', 'output train', 'train reason', 'reason train', 'train model', 'model train', 'train reward', 'reward model', 'model able', 'able classify', 'classify much', 'much better', 'better one', 'one output', 'output another', 'another one', 'one another', 'another slightly', 'slightly lessconverted', 'lessconverted way', 'way seeing', 'seeing reward', 'reward model', 'model output', 'output reward', 'reward used', 'used logits', 'logits softmax', 'softmax high', 'high logits', 'logits softmax', 'softmax means', 'means highly', 'highly likely', 'likely output', 'output better', 'better thats', 'thats call', 'call bradley', 'bradley terry', 'terry model', 'model yes', 'yes reward', 'reward model', 'model going', 'going entire', 'entire output', 'output going', 'going takes', 'takes entire', 'entire output', 'output one', 'one takes', 'takes input', 'input output', 'output gives', 'gives one', 'one number', 'number yes', 'yes im', 'im going', 'going talking', 'talking value', 'value human', 'human reward', 'reward model', 'model would', 'would human', 'human oh', 'oh sorry', 'sorry maybe', 'maybe wasnt', 'wasnt clear', 'clear train', 'train reward', 'reward model', 'model fit', 'fit green', 'green red', 'red preference', 'preference humans', 'humans train', 'train classifier', 'classifier say', 'say whether', 'whether humans', 'humans prefer', 'prefer red', 'red green', 'green instead', 'instead using', 'using binary', 'binary reward', 'reward human', 'human tell', 'tell use', 'use large', 'large bits', 'bits softmax', 'softmax thing', 'thing large', 'large bits', 'bits large', 'large bits', 'bits continuous', 'continuous know', 'know reward', 'reward model', 'model said', 'said high', 'high logents', 'logents ways', 'ways human', 'human highly', 'highly preferred', 'preferred answer', 'answer answer', 'answer great', 'great said', 'said continuous', 'continuous information', 'information says', 'says better', 'better thats', 'thats people', 'people use', 'use practice', 'practice least', 'least use', 'use use', 'use practice', 'practice ill', 'ill tell', 'tell algorithm', 'algorithm later', 'later end', 'end try', 'try use', 'use reinforcement', 'reinforcement learning', 'learning know', 'know know', 'know reward', 'reward sample', 'sample generation', 'generation large', 'large language', 'language model', 'model use', 'use regularization', 'regularization terms', 'terms reason', 'reason regularization', 'regularization term', 'term avoiding', 'avoiding call', 'call overoptimization', 'overoptimization reward', 'reward model', 'model might', 'might really', 'really represent', 'represent might', 'might perfectly', 'perfectly model', 'model human', 'human preferences', 'preferences dont', 'dont want', 'want maximize', 'maximize thing', 'thing essentially', 'essentially infinity', 'infinity using', 'using ppo', 'ppo common', 'common reinforcement', 'reinforcement learning', 'learning algorithm', 'algorithm one', 'one thing', 'thing note', 'note important', 'important later', 'later use', 'use maximum', 'maximum likelihood', 'likelihood im', 'im sorry', 'sorry large', 'large language', 'language models', 'models policy', 'policy reinforcement', 'reinforcement learning', 'learning maximizing', 'maximizing maximum', 'maximum likelihood', 'likelihood anymore', 'anymore means', 'means youre', 'youre modeling', 'modeling distribution', 'distribution anymore', 'anymore reason', 'reason important', 'important models', 'models went', 'went type', 'type ppo', 'ppo dont', 'dont give', 'give likelihoods', 'likelihoods text', 'text meaningful', 'meaningful optimize', 'optimize optimize', 'optimize generating', 'generating likely', 'likely thing', 'thing optimized', 'optimized modeling', 'modeling answers', 'answers humans', 'humans might', 'might say', 'say another', 'another way', 'way saying', 'saying theres', 'theres nothing', 'nothing incentivizes', 'incentivizes model', 'model give', 'give single', 'single possible', 'possible generation', 'generation nothing', 'nothing says', 'says good', 'good distribution', 'distribution entropy', 'entropy havent', 'havent followed', 'followed important', 'important good', 'good know', 'know great', 'great ppo', 'ppo exactly', 'exactly chad', 'chad gpt', 'gpt originally', 'originally heres', 'heres blog', 'blog posts', 'posts step', 'step one', 'one supervised', 'supervised fine', 'fine training', 'training know', 'know step', 'step two', 'two train', 'train reward', 'reward model', 'model human', 'human preferences', 'preferences step', 'step three', 'three ppo', 'ppo multiple', 'multiple steps', 'steps see', 'see blue', 'blue arrow', 'arrow train', 'train model', 'model ppo', 'ppo collect', 'collect new', 'new data', 'data continue', 'continue thats', 'thats exactly', 'exactly chad', 'chad gpt', 'gpt big', 'big breakthrough', 'breakthrough gp3', 'gp3 chad', 'chad gpt', 'gpt one', 'one thing', 'thing note', 'note ppo', 'ppo many', 'many challenges', 'challenges reinforce', 'reinforce learning', 'learning something', 'something super', 'super nice', 'nice theoretically', 'theoretically practice', 'practice anyone', 'anyone ever', 'ever worked', 'worked reinforcement', 'reinforcement learning', 'learning knows', 'knows mess', 'mess theres', 'theres lot', 'lot things', 'things roll', 'roll outs', 'outs outofloop', 'outofloop slipping', 'slipping many', 'many complications', 'complications messy', 'messy idealized', 'idealized ppouse4lm', 'ppouse4lm setting', 'setting thats', 'thats already', 'already much', 'much complicated', 'complicated expectation', 'expectation saw', 'saw practice', 'practice much', 'much complicated', 'complicated one', 'one implementation', 'implementation im', 'im going', 'going go', 'go much', 'much stuff', 'stuff think', 'think implement', 'implement type', 'type ppo', 'ppo algorithm', 'algorithm clipping', 'clipping everywhere', 'everywhere lot', 'lot complexities', 'complexities things', 'things well', 'well documented', 'documented say', 'say new', 'new method', 'method proposed', 'proposed also', 'also sanford', 'sanford one', 'one year', 'year ago', 'ago called', 'called dpo', 'dpo essentially', 'essentially simplification', 'simplification ppo', 'ppo way', 'way idea', 'idea instead', 'instead using', 'using reinforcement', 'reinforcement learning', 'learning maximize', 'maximize probability', 'probability generating', 'generating stuff', 'stuff minimum', 'minimum probability', 'probability stuff', 'stuff dont', 'dont think', 'think human', 'human preference', 'preference red', 'red green', 'green maximize', 'maximize green', 'green minimize', 'minimize red', 'red loss', 'loss one', 'one see', 'see simply', 'simply log', 'log model', 'model likelihood', 'likelihood model', 'model generating', 'generating things', 'things human', 'human preferred', 'preferred given', 'given inputs', 'inputs try', 'try maximize', 'maximize likelihood', 'likelihood generating', 'generating things', 'things minimize', 'minimize likelihood', 'likelihood things', 'things dont', 'dont rest', 'rest terms', 'terms important', 'important really', 'really complicated', 'complicated understand', 'understand high', 'high level', 'level really', 'really maximizing', 'maximizing things', 'things minimizing', 'minimizing rest', 'rest one', 'one thing', 'thing note', 'note going', 'going say', 'say rest', 'rest chosen', 'chosen global', 'global minima', 'minima ppo', 'ppo global', 'global minima', 'minima dpo', 'dpo assumptions', 'assumptions essentially', 'essentially equivalent', 'equivalent right', 'right thing', 'thing mathematically', 'mathematically im', 'im going', 'going go', 'go derivations', 'derivations thats', 'thats right', 'right thing', 'thing pretty', 'pretty different', 'different ppo', 'ppo sense', 'sense ppo', 'ppo collect', 'collect human', 'human preferences', 'preferences train', 'train reward', 'reward model', 'model maximum', 'maximum likelihood', 'likelihood use', 'use reinforcement', 'reinforcement learning', 'learning maximum', 'maximum likelihood', 'likelihood much', 'much simpler', 'simpler yes', 'yes mean', 'mean yeah', 'yeah simple', 'simple thing', 'thing much', 'much simpler', 'simpler thing', 'thing business', 'business start', 'start reward', 'reward model', 'model think', 'think great', 'great question', 'question dont', 'dont really', 'really know', 'know tell', 'tell dont', 'dont put', 'put people', 'people sorry', 'sorry chagy', 'chagy pt', 'pt initially', 'initially ones', 'ones wrote', 'wrote ppo', 'ppo think', 'think lot', 'lot reinforcement', 'reinforcement learning', 'learning people', 'people think', 'think intuitive', 'intuitive theres', 'theres also', 'also additional', 'additional potential', 'potential benefits', 'benefits example', 'example dont', 'dont yeah', 'yeah example', 'example use', 'use reward', 'reward model', 'model cool', 'cool thing', 'thing reinforced', 'reinforced learning', 'learning use', 'use unlabeled', 'unlabeled data', 'data reward', 'reward model', 'model use', 'use label', 'label data', 'data dpo', 'dpo ppo', 'ppo first', 'first train', 'train reward', 'reward model', 'model use', 'use unlabeled', 'unlabeled data', 'data reward', 'reward model', 'model label', 'label unlabeled', 'unlabeled data', 'data theres', 'theres additional', 'additional kind', 'kind potential', 'potential could', 'could potential', 'potential improvements', 'improvements practice', 'practice happens', 'happens known', 'known think', 'think lot', 'lot people', 'people team', 'team reinforcement', 'reinforcement learning', 'learning experts', 'experts including', 'including main', 'main author', 'author ppo', 'ppo im', 'im told', 'told much', 'much simpler', 'simpler ppo', 'ppo performs', 'performs well', 'well standard', 'standard thing', 'thing people', 'people use', 'use least', 'least open', 'open source', 'source community', 'community believe', 'believe standard', 'standard also', 'also industry', 'industry thats', 'thats called', 'called dpo', 'dpo gains', 'gains older', 'older papers', 'papers left', 'left summarization', 'summarization task', 'task see', 'see want', 'want show', 'show pretrained', 'pretrained models', 'models approve', 'approve scale', 'scale supervised', 'supervised fine', 'fine tuning', 'tuning improve', 'improve little', 'little bit', 'bit ppo', 'ppo something', 'something hf', 'hf human', 'human feedback', 'feedback get', 'get performance', 'performance oftentimes', 'oftentimes depending', 'depending benchmark', 'benchmark even', 'even better', 'better humans', 'humans human', 'human reference', 'reference summaries', 'summaries thing', 'thing done', 'done paper', 'paper alpaca', 'alpaca farm', 'farm see', 'see evaluation', 'evaluation important', 'important see', 'see pretrained', 'pretrained model', 'model jump', 'jump sft', 'sft jump', 'jump ppo', 'ppo dpo', 'dpo ppo', 'ppo exact', 'exact performance', 'performance hf', 'hf helps', 'helps thats', 'thats kind', 'kind conclusion', 'conclusion dpo', 'dpo simple', 'simple data', 'data way', 'way collect', 'collect type', 'type data', 'data first', 'first idea', 'idea use', 'use humans', 'humans already', 'already talked', 'talked guidelines', 'guidelines complicated', 'complicated humans', 'humans labeling', 'labeling really', 'really easy', 'easy see', 'see ever', 'ever labeling', 'labeling see', 'see extremely', 'extremely complicated', 'complicated zoom', 'zoom question', 'question tell', 'tell selfdriving', 'selfdriving cars', 'cars read', 'read selfdriving', 'selfdriving cars', 'cars vehicles', 'vehicles capable', 'capable detecting', 'detecting surroundings', 'surroundings blah', 'blah blah', 'blah blah', 'blah blah', 'blah selfdriving', 'selfdriving cars', 'cars cars', 'cars equipped', 'equipped sensors', 'sensors blah', 'blah blah', 'blah blah', 'blah navigate', 'navigate without', 'without need', 'need driver', 'driver seem', 'seem ok', 'ok one', 'one better', 'better hard', 'hard say', 'say glance', 'glance result', 'result problem', 'problem humans', 'humans start', 'start optimizing', 'optimizing lot', 'lot highlevel', 'highlevel features', 'features example', 'example second', 'second one', 'one longer', 'longer guarantee', 'guarantee humans', 'humans choose', 'choose second', 'second one', 'one even', 'even though', 'though may', 'may first', 'first one', 'one better', 'better dont', 'dont know', 'know havent', 'havent read', 'read carefully', 'carefully challenges', 'challenges humans', 'humans first', 'first slow', 'slow expensive', 'expensive second', 'second mentioned', 'mentioned hard', 'hard focus', 'focus things', 'things matter', 'matter correctness', 'correctness people', 'people usually', 'usually look', 'look things', 'things dont', 'dont matter', 'matter much', 'much form', 'form length', 'length result', 'result show', 'show rhf', 'rhf rhf', 'rhf longer', 'longer output', 'output models', 'models become', 'become youve', 'youve ever', 'ever annoyed', 'annoyed chat', 'chat gpt', 'gpt answering', 'answering super', 'super long', 'long sentences', 'sentences hf', 'hf annotated', 'annotated distribution', 'distribution shift', 'shift distribution', 'distribution annotators', 'annotators use', 'use matters', 'matters lot', 'lot think', 'think even', 'even humans', 'humans want', 'want represent', 'represent models', 'models another', 'another question', 'question crowdsourcing', 'crowdsourcing ethics', 'ethics usually', 'usually lot', 'lot labeling', 'labeling done', 'done people', 'people paid', 'paid well', 'well go', 'go lot', 'lot toxic', 'toxic data', 'data youre', 'youre one', 'one model', 'model avoid', 'avoid saying', 'saying toxic', 'toxic data', 'data crowdsourcing', 'crowdsourcing ethics', 'ethics many', 'many challenges', 'challenges human', 'human data', 'data also', 'also last', 'last year', 'year thing', 'thing alpaca', 'alpaca idea', 'idea oh', 'oh well', 'well challenges', 'challenges humans', 'humans maybe', 'maybe replace', 'replace lms', 'lms simply', 'simply replace', 'replace oh', 'oh see', 'see im', 'im realizing', 'realizing slides', 'slides centered', 'centered anyways', 'anyways replace', 'replace human', 'human preference', 'preference lm', 'lm preferences', 'preferences figure', 'figure see', 'see xaxis', 'xaxis price', 'price paid', 'paid collecting', 'collecting human', 'human data', 'data around', 'around 300', '300 1000', '1000 examples', 'examples mechanical', 'mechanical turquoise', 'turquoise usually', 'usually cheaper', 'cheaper maybe', 'maybe companies', 'companies could', 'could go', 'go yaxis', 'yaxis agreement', 'agreement humans', 'humans mode', 'mode humans', 'humans see', 'see told', 'told labeling', 'labeling really', 'really complicated', 'complicated humans', 'humans agree', 'agree around', 'around 66', '66 time', 'time im', 'im binary', 'binary task', 'task humans', 'humans good', 'good five', 'five main', 'main authors', 'authors paper', 'paper tried', 'tried label', 'label data', 'data say', 'say 67', '67 68', '68 accuracy', 'accuracy even', 'even though', 'though talked', 'talked three', 'three hours', 'hours labeling', 'labeling really', 'really complicated', 'complicated easy', 'easy task', 'task showed', 'showed many', 'many different', 'different models', 'models see', 'see models', 'models much', 'much cheaper', 'cheaper get', 'get higher', 'higher agreement', 'agreement mode', 'mode humans', 'humans humans', 'humans reason', 'reason humans', 'humans lot', 'lot variants', 'variants models', 'models variants', 'variants might', 'might little', 'little bit', 'bit biased', 'biased less', 'less variants', 'variants works', 'works surprisingly', 'surprisingly well', 'well kind', 'kind standard', 'standard open', 'open source', 'source community', 'community think', 'think even', 'even industry', 'industry lot', 'lot people', 'people use', 'use humans', 'humans llms', 'llms improving', 'improving collection', 'collection hf', 'hf data', 'data paper', 'paper last', 'last year', 'year honestly', 'honestly llms', 'llms would', 'would around', 'around agreement', 'agreement cost', 'cost around', 'around would', 'would say', 'say 50x', '50x cheaper', 'cheaper humans', 'humans better', 'better agreement', 'agreement humans', 'humans humans', 'humans gets', 'gets us', 'us evaluation', 'evaluation posttraining', 'posttraining goes', 'goes back', 'back initial', 'initial question', 'question beginning', 'beginning lecture', 'lecture evaluate', 'evaluate something', 'something chargeup', 'chargeup answers', 'answers chargeup', 'chargeup could', 'could give', 'give unbounded', 'unbounded theres', 'theres one', 'one right', 'right answer', 'answer many', 'many answers', 'answers good', 'good main', 'main topic', 'topic one', 'one cant', 'cant use', 'use validation', 'validation loss', 'loss one', 'one method', 'method might', 'might use', 'use ppo', 'ppo one', 'one might', 'might use', 'use dpo', 'dpo validation', 'validation loss', 'loss comparable', 'comparable second', 'second cant', 'cant use', 'use sorry', 'sorry perplexity', 'perplexity thats', 'thats thing', 'thing told', 'told models', 'models calibrated', 'calibrated dont', 'dont give', 'give distributions', 'distributions optimize', 'optimize one', 'one thing', 'thing cant', 'cant use', 'use perplexity', 'perplexity evaluating', 'evaluating type', 'type models', 'models theyre', 'theyre aligned', 'aligned sorry', 'sorry theyre', 'theyre aligned', 'aligned third', 'third theres', 'theres lot', 'lot diversity', 'diversity questions', 'questions human', 'human might', 'might ask', 'ask models', 'models generation', 'generation open', 'open qa', 'qa question', 'question answering', 'answering summarization', 'summarization things', 'things theres', 'theres many', 'many things', 'things cover', 'cover tests', 'tests really', 'really openended', 'openended hard', 'hard automate', 'automate thats', 'thats alluding', 'alluding idea', 'idea instead', 'instead trying', 'trying come', 'come really', 'really easily', 'easily automated', 'automated benchmarks', 'benchmarks going', 'going ask', 'ask questions', 'questions users', 'users asked', 'asked models', 'models practice', 'practice going', 'going ask', 'ask annotators', 'annotators say', 'say two', 'two models', 'models one', 'one better', 'better whats', 'whats whats', 'whats better', 'better output', 'output exact', 'exact thing', 'thing data', 'data hf', 'hf use', 'use evaluation', 'evaluation yes', 'yes im', 'im sure', 'sure understand', 'understand mean', 'mean cant', 'cant use', 'use procllexity', 'procllexity calibrated', 'calibrated really', 'really hello', 'hello im', 'im still', 'still exit', 'exit token', 'token prediction', 'prediction ipi', 'ipi procllexity', 'procllexity please', 'please think', 'think optimal', 'optimal solution', 'solution ppo', 'ppo one', 'one model', 'model gives', 'gives essentially', 'essentially delta', 'delta says', 'says theres', 'theres one', 'one sentence', 'sentence could', 'could generated', 'generated question', 'question use', 'use something', 'something slightly', 'slightly semantically', 'semantically differently', 'differently different', 'different would', 'would give', 'give likelihood', 'likelihood zero', 'zero answer', 'answer reality', 'reality extreme', 'extreme say', 'say still', 'still distribution', 'distribution shows', 'shows theres', 'theres fundamental', 'fundamental issue', 'issue procllexity', 'procllexity models', 'models llms', 'llms anymore', 'anymore trained', 'trained least', 'least ppo', 'ppo trained', 'trained maximum', 'maximum likelihood', 'likelihood anymore', 'anymore trained', 'trained ppo', 'ppo policies', 'policies probably', 'probably common', 'common yeah', 'yeah common', 'common benchmark', 'benchmark trusted', 'trusted one', 'one call', 'call chatbot', 'chatbot arena', 'arena go', 'go internet', 'internet random', 'random users', 'users internet', 'internet blindly', 'blindly talk', 'talk two', 'two chatbots', 'chatbots ask', 'ask many', 'many questions', 'questions see', 'see two', 'two answers', 'answers rate', 'rate one', 'one better', 'better 100000', '100000 users', 'users get', 'get actual', 'actual preferences', 'preferences get', 'get rankings', 'rankings models', 'models go', 'go right', 'right chatbot', 'chatbot arena', 'arena interact', 'interact models', 'models one', 'one potential', 'potential issue', 'issue highlight', 'highlight people', 'people want', 'want type', 'type things', 'things usually', 'usually tech', 'tech driven', 'driven tech', 'tech savvy', 'savvy lot', 'lot questions', 'questions ask', 'ask tech', 'tech stuff', 'stuff discussing', 'discussing software', 'software errors', 'errors inquiries', 'inquiries ai', 'ai tools', 'tools things', 'things another', 'another issue', 'issue cost', 'cost speed', 'speed really', 'really want', 'want use', 'use something', 'something development', 'development process', 'process costly', 'costly need', 'need pay', 'pay lot', 'lot humans', 'humans one', 'one simple', 'simple idea', 'idea said', 'said many', 'many times', 'times use', 'use lm', 'lm instead', 'instead humans', 'humans probably', 'probably know', 'know drill', 'drill point', 'point steps', 'steps every', 'every instruction', 'instruction generate', 'generate outputs', 'outputs baseline', 'baseline model', 'model want', 'want evaluate', 'evaluate imagined', 'imagined comparing', 'comparing answer', 'answer chad', 'chad gpt', 'gpt mistro', 'mistro im', 'im asking', 'asking another', 'another model', 'model one', 'one better', 'better averaged', 'averaged yeah', 'yeah asked', 'asked gpt', 'gpt one', 'one better', 'better averaged', 'averaged entire', 'entire distribution', 'distribution entire', 'entire benchmark', 'benchmark data', 'data set', 'set gives', 'gives win', 'win rate', 'rate win', 'win probability', 'probability one', 'one model', 'model compared', 'compared another', 'another one', 'one rank', 'rank models', 'models alpequeeval', 'alpequeeval leaderboard', 'leaderboard benefits', 'benefits show', 'show get', 'get 98', '98 correlation', 'correlation chad', 'chad baragwina', 'baragwina high', 'high correlation', 'correlation humans', 'humans comparison', 'comparison correlation', 'correlation benchmarks', 'benchmarks takes', 'takes less', 'less three', 'three minutes', 'minutes less', 'less 10', '10 run', 'run pretty', 'pretty cheap', 'cheap downsides', 'downsides though', 'though one', 'one purist', 'purist correlation', 'correlation already', 'already saw', 'saw lms', 'lms prefer', 'prefer one', 'one spurious', 'spurious correlation', 'correlation many', 'many ill', 'ill talk', 'talk one', 'one lms', 'lms prefer', 'prefer longer', 'longer outputs', 'outputs humans', 'humans also', 'also prefer', 'prefer longer', 'longer outputs', 'outputs problem', 'problem issue', 'issue use', 'use lms', 'lms bias', 'bias continue', 'continue optimizing', 'optimizing humans', 'humans point', 'point guarantee', 'guarantee ask', 'ask simple', 'simple question', 'question give', 'give five', 'five pages', 'pages answers', 'answers ill', 'ill dont', 'dont answer', 'answer lms', 'lms bias', 'bias trained', 'trained continue', 'continue preferring', 'preferring longer', 'longer outputs', 'outputs see', 'see preference', 'preference showing', 'showing humans', 'humans models', 'models prefer', 'prefer longer', 'longer outputs', 'outputs another', 'another view', 'view initial', 'initial apache', 'apache val', 'val data', 'data set', 'set benchmark', 'benchmark asked', 'asked rank', 'rank gpt4', 'gpt4 look', 'look run', 'run rate', 'rate gpt4', 'gpt4 versus', 'versus gpt4', 'gpt4 use', 'use standard', 'standard gpd4', 'gpd4 gets', 'gets 50', '50 definition', 'definition comparing', 'comparing gpd4', 'gpd4 versus', 'versus gpd4', 'gpd4 ask', 'ask gpd4', 'gpd4 slightly', 'slightly verbose', 'verbose say', 'say prompt', 'prompt verbose', 'verbose answers', 'answers gets', 'gets reinway', 'reinway 644', '644 really', 'really theres', 'theres huge', 'huge variance', 'variance ask', 'ask concise', 'concise gets', 'gets 20', '20 theres', 'theres huge', 'huge variance', 'variance depending', 'depending whether', 'whether ask', 'ask concise', 'concise verbose', 'verbose thats', 'thats annoying', 'annoying one', 'one possible', 'possible solution', 'solution use', 'use regression', 'regression analysis', 'analysis im', 'im going', 'going go', 'go details', 'details use', 'use causal', 'causal inference', 'inference tools', 'tools control', 'control length', 'length right', 'right length', 'length matters', 'matters much', 'much less', 'less ask', 'ask verbose', 'verbose still', 'still get', 'get gains', 'gains much', 'much less', 'less great', 'great thats', 'thats posttraining', 'posttraining next', 'next eight', 'eight minutes', 'minutes might', 'might talk', 'talk systems', 'systems answer', 'answer questions', 'questions yes', 'yes ok', 'ok go', 'go back', 'back posttraining', 'posttraining terms', 'terms posttraining', 'posttraining tune', 'tune parameters', 'parameters using', 'using small', 'small body', 'body finetuning', 'finetuning data', 'data big', 'big effect', 'effect model', 'model mentioned', 'mentioned earlier', 'earlier theres', 'theres different', 'different set', 'set hypergrammers', 'hypergrammers changing', 'changing weights', 'weights later', 'later weights', 'weights weights', 'weights whats', 'whats happening', 'happening yeah', 'yeah kind', 'kind skimmed', 'skimmed change', 'change weights', 'weights industry', 'industry would', 'would change', 'change weights', 'weights open', 'open source', 'source land', 'land might', 'might heard', 'heard laura', 'laura going', 'going change', 'change weights', 'weights specific', 'specific going', 'going add', 'add differences', 'differences output', 'output every', 'every layer', 'layer industry', 'industry youre', 'youre going', 'going finetune', 'finetune weights', 'weights also', 'also say', 'say something', 'something else', 'else data', 'data last', 'last step', 'step rlhf', 'rlhf youre', 'youre usually', 'usually going', 'going collect', 'collect lot', 'lot data', 'data sft', 'sft sff', 'sff 50', '50 5000', '5000 10000', '10000 maybe', 'maybe 50000', '50000 rlhf', 'rlhf think', 'think youre', 'youre going', 'going unlike', 'unlike 1', '1 million', 'million magnitude', 'magnitude still', 'still much', 'much less', 'less pretraining', 'pretraining though', 'though 15', '15 trillion', 'trillion tokens', 'tokens mean', 'mean thats', 'thats even', 'even drop', 'drop influence', 'influence weight', 'weight wall', 'wall mean', 'mean think', 'think use', 'use mean', 'mean said', 'said learning', 'learning way', 'way youre', 'youre going', 'going use', 'use going', 'going different', 'different also', 'also imagine', 'imagine trained', 'trained even', 'even trained', 'trained one', 'one sentence', 'sentence point', 'point model', 'model generate', 'generate sentence', 'sentence even', 'even one', 'one sentence', 'sentence instead', 'instead 15', '15 trillion', 'trillion tokens', 'tokens use', 'use large', 'large enough', 'enough learning', 'learning rate', 'rate enough', 'enough time', 'time overfit', 'overfit sentence', 'sentence key', 'key thing', 'thing remember', 'remember data', 'data id', 'id mix', 'mix posttraining', 'posttraining data', 'data pretraining', 'pretraining data', 'data pretraining', 'pretraining start', 'start finetuning', 'finetuning posttraining', 'posttraining another', 'another way', 'way maybe', 'maybe another', 'another perspective', 'perspective pretraining', 'pretraining initialization', 'initialization model', 'model view', 'view way', 'way initialization', 'initialization weights', 'weights theres', 'theres nothing', 'nothing special', 'special dont', 'dont need', 'need remember', 'remember trained', 'trained lot', 'lot data', 'data thing', 'thing matters', 'matters initialization', 'initialization trained', 'trained model', 'model maybe', 'maybe think', 'think way', 'way theres', 'theres mark', 'mark property', 'property ways', 'ways weights', 'weights initialization', 'initialization im', 'im training', 'training one', 'one kind', 'kind answer', 'answer question', 'question kind', 'kind said', 'said something', 'something almost', 'almost equivalent', 'equivalent rerunning', 'rerunning fine', 'fine tuning', 'tuning data', 'data many', 'many times', 'times happens', 'happens order', 'order give', 'give much', 'much preference', 'preference might', 'might dont', 'dont know', 'know right', 'right industry', 'industry packet', 'packet three', 'three blocks', 'blocks run', 'run three', 'three times', 'times mean', 'mean even', 'even number', 'number times', 'times run', 'run important', 'important thing', 'thing effective', 'effective learning', 'learning rate', 'rate matters', 'matters yeah', 'yeah great', 'great think', 'think five', 'five minutes', 'minutes right', 'right might', 'might try', 'try give', 'give high', 'high level', 'level overview', 'overview least', 'least one', 'one systems', 'systems trick', 'trick systems', 'systems said', 'said everyone', 'everyone bottleneck', 'bottleneck sorry', 'sorry compute', 'compute huge', 'huge bottleneck', 'bottleneck one', 'one question', 'question might', 'might ask', 'ask buy', 'buy gpus', 'gpus gpus', 'gpus expensive', 'expensive also', 'also case', 'case even', 'even 10', '10 million', 'million right', 'right buy', 'buy best', 'best gpus', 'gpus theres', 'theres also', 'also physical', 'physical limitations', 'limitations multiple', 'multiple gpus', 'gpus communicate', 'communicate takes', 'takes time', 'time buying', 'buying gpus', 'gpus easy', 'easy really', 'really important', 'important think', 'think allocate', 'allocate resources', 'resources optimize', 'optimize pipeline', 'pipeline system', 'system 101', '101 gpus', 'gpus im', 'im sorry', 'sorry im', 'im going', 'going slightly', 'slightly faster', 'faster hope', 'hope least', 'least follow', 'follow gpus', 'gpus optimized', 'optimized throughput', 'throughput cpus', 'cpus optimized', 'optimized latency', 'latency gpus', 'gpus way', 'way think', 'think theres', 'theres one', 'one command', 'command run', 'run many', 'many many', 'many cores', 'cores time', 'time different', 'different type', 'type data', 'data see', 'see gpu', 'gpu see', 'see many', 'many different', 'different cores', 'cores call', 'call streaming', 'streaming multiprocesses', 'multiprocesses different', 'different usual', 'usual cpu', 'cpu architecture', 'architecture think', 'think high', 'high throughput', 'throughput powerization', 'powerization gpus', 'gpus gpus', 'gpus optimized', 'optimized fast', 'fast matrix', 'matrix multiplication', 'multiplication every', 'every time', 'time something', 'something gpu', 'gpu matrix', 'matrix multiplication', 'multiplication going', 'going 10', '10 times', 'times faster', 'faster anything', 'anything else', 'else little', 'little bit', 'bit annoying', 'annoying means', 'means kind', 'kind bottlenecked', 'bottlenecked anything', 'anything matrix', 'matrix multiplications', 'multiplications another', 'another thing', 'thing note', 'note gpus', 'gpus compute', 'compute improving', 'improving faster', 'faster memory', 'memory communication', 'communication right', 'right gpus', 'gpus usually', 'usually hard', 'hard keep', 'keep data', 'data send', 'send cpus', 'cpus hard', 'hard keep', 'keep process', 'process gpus', 'gpus going', 'going idle', 'idle run', 'run normal', 'normal code', 'code dont', 'dont optimize', 'optimize code', 'code communication', 'communication continue', 'continue time', 'time another', 'another thing', 'thing know', 'know gpus', 'gpus theres', 'theres memory', 'memory hierarchy', 'hierarchy thing', 'thing cpus', 'cpus closer', 'closer cores', 'cores less', 'less memory', 'memory faster', 'faster things', 'things run', 'run memory', 'memory slower', 'slower ok', 'ok im', 'im going', 'going skip', 'skip ok', 'ok im', 'im going', 'going say', 'say told', 'told defective', 'defective communication', 'communication metric', 'metric people', 'people usually', 'usually look', 'look model', 'model flop', 'flop utilization', 'utilization theoretical', 'theoretical maximum', 'maximum gpu', 'gpu could', 'could run', 'run flops', 'flops could', 'could use', 'use per', 'per second', 'second divide', 'divide number', 'number observes', 'observes per', 'per divided', 'divided theoretical', 'theoretical maximum', 'maximum general', 'general reach', 'reach 50', '50 youre', 'youre happy', 'happy facebook', 'facebook looked', 'looked lama', 'lama 45', '45 something', 'something means', 'means data', 'data doesnt', 'doesnt come', 'come fast', 'fast enough', 'enough even', 'even big', 'big companies', 'companies one', 'one simple', 'simple thing', 'thing trick', 'trick might', 'might one', 'one im', 'im going', 'going tell', 'tell low', 'low precision', 'precision one', 'one simple', 'simple idea', 'idea well', 'well im', 'im going', 'going put', 'put floats', 'floats low', 'low precision', 'precision theres', 'theres going', 'going fewer', 'fewer bits', 'bits send', 'send gpus', 'gpus theres', 'theres fewer', 'fewer bits', 'bits faster', 'faster communication', 'communication lower', 'lower memory', 'memory consumption', 'consumption things', 'things going', 'going go', 'go faster', 'faster deep', 'deep planning', 'planning happens', 'happens decimal', 'decimal important', 'important matrix', 'matrix multiplication', 'multiplication example', 'example sgd', 'sgd already', 'already much', 'much noise', 'noise update', 'update something', 'something 001', '001 0015', '0015 cares', 'cares instead', 'instead using', 'using 32', '32 bits', 'bits per', 'per float', 'float people', 'people use', 'use use', 'use 64', '64 example', 'example would', 'would use', 'use domains', 'domains use', 'use 16', '16 bits', 'bits matrix', 'matrix multiplication', 'multiplication every', 'every float', 'float use', 'use 16', '16 bits', 'bits training', 'training type', 'type call', 'call automatic', 'automatic mix', 'mix precision', 'precision things', 'things 32', '32 bits', 'bits others', 'others 16', '16 bits', 'bits generally', 'generally way', 'way thinking', 'thinking weights', 'weights stored', 'stored model', 'model stored', 'stored 32', '32 bits', 'bits computation', 'computation put', 'put everything', 'everything 16', '16 16', '16 bits', 'bits computation', 'computation super', 'super fast', 'fast end', 'end update', 'update weights', 'weights 32', '32 bits', 'bits reason', 'reason updates', 'updates 32', '32 bits', 'bits think', 'think youre', 'youre learning', 'learning weight', 'weight example', 'example small', 'small still', 'still want', 'want able', 'able make', 'make difference', 'difference weights', 'weights computation', 'computation done', 'done 16', '16 bits', 'bits weights', 'weights stored', 'stored 32', '32 bits', 'bits thats', 'thats standard', 'standard way', 'way people', 'people ill', 'ill talk', 'talk ill', 'ill skip', 'skip rest', 'rest operate', 'operate fusion', 'fusion think', 'think pretty', 'pretty cool', 'cool said', 'said communication', 'communication slow', 'slow every', 'every time', 'time use', 'use pie', 'pie torch', 'torch line', 'line moves', 'moves variable', 'variable global', 'global memory', 'memory gpu', 'gpu something', 'something x', 'x dot', 'dot cosine', 'cosine equal', 'equal x1', 'x1 x1', 'x1 dot', 'dot cosine', 'cosine happening', 'happening behind', 'behind scenes', 'scenes take', 'take x', 'x data', 'data ship', 'ship actual', 'actual processes', 'processes gpus', 'gpus apply', 'apply cosine', 'cosine ship', 'ship back', 'back main', 'main memory', 'memory gpu', 'gpu see', 'see next', 'next line', 'line ship', 'ship back', 'back gpu', 'gpu processor', 'processor apply', 'apply another', 'another cosine', 'cosine ship', 'ship back', 'back another', 'another way', 'way see', 'see go', 'go dram', 'dram global', 'global memory', 'memory gpu', 'gpu ship', 'ship compute', 'compute ship', 'ship back', 'back every', 'every line', 'line naive', 'naive way', 'way seems', 'seems wasteful', 'wasteful idea', 'idea simple', 'simple idea', 'idea operating', 'operating fusion', 'fusion communicate', 'communicate computation', 'computation ship', 'ship backwards', 'backwards exactly', 'exactly kernels', 'kernels ever', 'ever want', 'want make', 'make computations', 'computations pytorch', 'pytorch much', 'much faster', 'faster apply', 'apply torchcomcom', 'torchcomcom model', 'model going', 'going make', 'make model', 'model around', 'around two', 'two times', 'times faster', 'faster simply', 'simply rewrites', 'rewrites code', 'code pytorch', 'pytorch code', 'code nc', 'nc cuda', 'cuda communication', 'communication operations', 'operations ship', 'ship back', 'back im', 'im going', 'going time', 'time talk', 'talk tiling', 'tiling tiling', 'tiling important', 'important powerization', 'powerization powerization', 'powerization important', 'important mixture', 'mixture experts', 'experts mixture', 'mixture experts', 'experts important', 'important outlook', 'outlook many', 'many things', 'things havent', 'havent talked', 'talked havent', 'havent talked', 'talked architectures', 'architectures definitely', 'definitely havent', 'havent talked', 'talked inference', 'inference many', 'many things', 'things important', 'important llms', 'llms ui', 'ui use', 'use mean', 'mean arguably', 'arguably chatgpt', 'chatgpt big', 'big novelty', 'novelty simple', 'simple ui', 'ui use', 'use multimodality', 'multimodality misuses', 'misuses could', 'could fact', 'fact might', 'might enough', 'enough data', 'data internet', 'internet train', 'train models', 'models quality', 'quality data', 'data collection', 'collection many', 'many things', 'things interested', 'interested topics', 'topics would', 'would suggest', 'suggest three', 'three classes', 'classes cs224n', 'cs224n probably', 'probably one', 'one touches', 'touches least', 'least llms', 'llms give', 'give background', 'background historical', 'historical context', 'context llms', 'llms give', 'give kind', 'kind jason', 'jason matillo', 'matillo cs324', 'cs324 think', 'think called', 'called think', 'think called', 'called large', 'large language', 'language models', 'models indepth', 'indepth reading', 'reading lectures', 'lectures everything', 'everything talked', 'talked cs336', 'cs336 large', 'large language', 'language model', 'model scratch', 'scratch build', 'build llm', 'llm amazing', 'amazing class', 'class also', 'also given', 'given two', 'two supervisors', 'supervisors heavy', 'heavy workloads', 'workloads careful', 'careful great']\n",
            "Trigram Phrases: ['lets get started', 'get started ill', 'started ill talking', 'ill talking building', 'talking building llms', 'building llms today', 'llms today think', 'today think lot', 'think lot heard', 'lot heard llms', 'heard llms quick', 'llms quick recap', 'quick recap llms', 'recap llms standing', 'llms standing large', 'standing large language', 'large language models', 'language models chat', 'models chat bots', 'chat bots youve', 'bots youve hearing', 'youve hearing recently', 'hearing recently chad', 'recently chad gpt', 'chad gpt openai', 'gpt openai cloud', 'openai cloud untropic', 'cloud untropic gemini', 'untropic gemini lama', 'gemini lama type', 'lama type models', 'type models today', 'models today well', 'today well talking', 'well talking work', 'talking work going', 'work going overview', 'going overview one', 'overview one lecture', 'one lecture hard', 'lecture hard compress', 'hard compress everything', 'compress everything hopefully', 'everything hopefully ill', 'hopefully ill touch', 'ill touch little', 'touch little bit', 'little bit components', 'bit components needed', 'components needed train', 'needed train llms', 'train llms also', 'llms also questions', 'also questions please', 'questions please interrupt', 'please interrupt ask', 'interrupt ask question', 'ask question likely', 'question likely people', 'likely people room', 'people room zoom', 'room zoom question', 'zoom question please', 'question please ask', 'please ask great', 'ask great matters', 'great matters training', 'matters training llms', 'training llms key', 'llms key components', 'key components matter', 'components matter one', 'matter one architecture', 'one architecture probably', 'architecture probably know', 'probably know lms', 'know lms neural', 'lms neural networks', 'neural networks think', 'networks think neural', 'think neural networks', 'neural networks think', 'networks think architecture', 'think architecture youre', 'architecture youre using', 'youre using another', 'using another component', 'another component really', 'component really important', 'really important training', 'important training loss', 'training loss training', 'loss training algorithm', 'training algorithm train', 'algorithm train models', 'train models data', 'models data train', 'data train models', 'train models evaluation', 'models evaluation know', 'evaluation know whether', 'know whether youre', 'whether youre making', 'youre making progress', 'making progress towards', 'progress towards goal', 'towards goal llms', 'goal llms system', 'llms system component', 'system component make', 'component make models', 'make models run', 'models run modern', 'run modern hardware', 'modern hardware really', 'hardware really important', 'really important models', 'important models really', 'models really large', 'really large ever', 'large ever systems', 'ever systems really', 'systems really important', 'really important topic', 'important topic llms', 'topic llms five', 'llms five components', 'five components probably', 'components probably know', 'probably know llms', 'know llms dont', 'llms dont know', 'dont know lms', 'know lms based', 'lms based transformers', 'based transformers least', 'transformers least version', 'least version transformers', 'version transformers im', 'transformers im going', 'im going talk', 'going talk architecture', 'talk architecture today', 'architecture today one', 'today one gave', 'one gave us', 'gave us lecture', 'us lecture transformers', 'lecture transformers weeks', 'transformers weeks ago', 'weeks ago two', 'ago two find', 'two find much', 'find much information', 'much information online', 'information online transformers', 'online transformers think', 'transformers think theres', 'think theres much', 'theres much less', 'much less information', 'less information four', 'information four topics', 'four topics really', 'topics really want', 'really want talk', 'want talk another', 'talk another thing', 'another thing say', 'thing say academia', 'say academia focuses', 'academia focuses architecture', 'focuses architecture training', 'architecture training algorithm', 'training algorithm losses', 'algorithm losses academics', 'losses academics done', 'academics done lot', 'done lot big', 'lot big part', 'big part career', 'part career simply', 'career simply thinking', 'simply thinking make', 'thinking make new', 'make new architectures', 'new architectures new', 'architectures new models', 'new models seems', 'models seems important', 'seems important reality', 'important reality honestly', 'reality honestly matters', 'honestly matters practice', 'matters practice mostly', 'practice mostly three', 'mostly three topics', 'three topics data', 'topics data evaluation', 'data evaluation systems', 'evaluation systems one', 'systems one industry', 'one industry focuses', 'industry focuses thats', 'focuses thats also', 'thats also one', 'also one reasons', 'one reasons dont', 'reasons dont want', 'dont want talk', 'want talk much', 'talk much architecture', 'much architecture really', 'architecture really rest', 'really rest super', 'rest super important', 'super important great', 'important great overview', 'great overview lecture', 'overview lecture ill', 'lecture ill talking', 'ill talking pretraining', 'talking pretraining pretraining', 'pretraining pretraining probably', 'pretraining probably heard', 'probably heard word', 'heard word general', 'word general word', 'general word kind', 'word kind classical', 'kind classical language', 'classical language modeling', 'language modeling paradigm', 'modeling paradigm train', 'paradigm train language', 'train language model', 'language model essentially', 'model essentially model', 'essentially model internet', 'model internet theres', 'internet theres post', 'theres post training', 'post training recent', 'training recent paradigm', 'recent paradigm taking', 'paradigm taking large', 'taking large language', 'large language models', 'language models making', 'models making essentially', 'making essentially ai', 'essentially ai assistants', 'ai assistants recent', 'assistants recent trend', 'recent trend since', 'trend since chatgpt', 'since chatgpt ever', 'chatgpt ever heard', 'ever heard gpt3', 'heard gpt3 gpt2', 'gpt3 gpt2 thats', 'gpt2 thats really', 'thats really pretraining', 'really pretraining land', 'pretraining land heard', 'land heard chatgpt', 'heard chatgpt probably', 'chatgpt probably really', 'probably really post', 'really post training', 'post training land', 'training land talk', 'land talk ill', 'talk ill start', 'ill start pretraining', 'start pretraining specifically', 'pretraining specifically ill', 'specifically ill talk', 'ill talk task', 'talk task pretraining', 'task pretraining lms', 'pretraining lms laws', 'lms laws people', 'laws people use', 'people use language', 'use language modeling', 'language modeling quick', 'modeling quick recap', 'quick recap language', 'recap language models', 'language models high', 'models high level', 'high level simply', 'level simply models', 'simply models probability', 'models probability distribution', 'probability distribution sequences', 'distribution sequences tokens', 'sequences tokens words', 'tokens words model', 'words model p', 'model p x1', 'p x1 excel', 'x1 excel x1', 'excel x1 word', 'x1 word wanted', 'word wanted excel', 'wanted excel last', 'excel last word', 'last word sequence', 'word sequence sentence', 'sequence sentence concretely', 'sentence concretely sentence', 'concretely sentence mouse', 'sentence mouse eight', 'mouse eight cheese', 'eight cheese language', 'cheese language model', 'language model gives', 'model gives simply', 'gives simply probability', 'simply probability sentence', 'probability sentence uttered', 'sentence uttered human', 'uttered human found', 'human found online', 'found online another', 'online another sentence', 'another sentence mouse', 'sentence mouse eight', 'mouse eight cheese', 'eight cheese theres', 'cheese theres grammatical', 'theres grammatical mistakes', 'grammatical mistakes model', 'mistakes model syntactic', 'model syntactic knowledge', 'syntactic knowledge know', 'knowledge know less', 'know less likelihood', 'less likelihood appearing', 'likelihood appearing online', 'appearing online another', 'online another sentence', 'another sentence cheese', 'sentence cheese eight', 'cheese eight mouse', 'eight mouse model', 'mouse model hopefully', 'model hopefully know', 'hopefully know fact', 'know fact usually', 'fact usually cheese', 'usually cheese dont', 'cheese dont eat', 'dont eat mouse', 'eat mouse theres', 'mouse theres semantic', 'theres semantic knowledge', 'semantic knowledge less', 'knowledge less likely', 'less likely first', 'likely first sentence', 'first sentence high', 'sentence high level', 'high level language', 'level language models', 'language models one', 'models one word', 'one word youve', 'word youve probably', 'youve probably hearing', 'probably hearing lot', 'hearing lot news', 'lot news generative', 'news generative models', 'generative models something', 'models something generate', 'something generate models', 'generate models generate', 'models generate sentences', 'generate sentences generate', 'sentences generate data', 'generate data reason', 'data reason know', 'reason know say', 'know say language', 'say language models', 'language models genitive', 'models genitive models', 'genitive models model', 'models model distribution', 'model distribution simply', 'distribution simply sample', 'simply sample model', 'sample model generate', 'model generate data', 'generate data generate', 'data generate sentences', 'generate sentences using', 'sentences using language', 'using language model', 'language model type', 'model type models', 'type models people', 'models people currently', 'people currently using', 'currently using call', 'using call autoregressive', 'call autoregressive language', 'autoregressive language models', 'language models key', 'models key idea', 'key idea autoregressive', 'idea autoregressive language', 'autoregressive language models', 'language models take', 'models take distribution', 'take distribution words', 'distribution words decompose', 'words decompose distribution', 'decompose distribution first', 'distribution first word', 'first word multiply', 'word multiply distribution', 'multiply distribution likelihood', 'distribution likelihood second', 'likelihood second word', 'second word given', 'word given first', 'given first word', 'first word multiply', 'word multiply p', 'multiply p third', 'p third word', 'third word given', 'word given first', 'given first two', 'first two words', 'two words theres', 'words theres approximation', 'theres approximation chain', 'approximation chain rule', 'chain rule probability', 'rule probability hopefully', 'probability hopefully know', 'hopefully know really', 'know really approximation', 'really approximation one', 'approximation one way', 'one way modeling', 'way modeling distribution', 'modeling distribution slightly', 'distribution slightly concisely', 'slightly concisely write', 'concisely write product', 'write product ps', 'product ps next', 'ps next word', 'next word given', 'word given everything', 'given everything happened', 'everything happened past', 'happened past context', 'past context call', 'context call autoregressive', 'call autoregressive language', 'autoregressive language models', 'language models really', 'models really way', 'really way modeling', 'way modeling distribution', 'modeling distribution one', 'distribution one way', 'one way benefits', 'way benefits downsides', 'benefits downsides one', 'downsides one downside', 'one downside autoregressive', 'downside autoregressive language', 'autoregressive language models', 'language models sample', 'models sample autoregressive', 'sample autoregressive language', 'autoregressive language model', 'language model full', 'model full loop', 'full loop generates', 'loop generates next', 'generates next word', 'next word conditions', 'word conditions next', 'conditions next word', 'next word regenerate', 'word regenerate words', 'regenerate words longer', 'words longer sentence', 'longer sentence want', 'sentence want generate', 'want generate takes', 'generate takes time', 'takes time generate', 'time generate downsides', 'generate downsides current', 'downsides current paradigm', 'current paradigm thats', 'paradigm thats currently', 'thats currently im', 'currently im going', 'im going talk', 'going talk one', 'talk one great', 'one great autoregressive', 'great autoregressive language', 'autoregressive language models', 'language models high', 'models high level', 'high level task', 'level task autoregressive', 'task autoregressive language', 'autoregressive language model', 'language model simply', 'model simply predicting', 'simply predicting next', 'predicting next word', 'next word said', 'word said sentence', 'said sentence likely', 'sentence likely prefers', 'likely prefers one', 'prefers one potential', 'one potential next', 'potential next word', 'next word might', 'word might dogs', 'might dogs way', 'dogs way first', 'way first tokenize', 'first tokenize take', 'tokenize take words', 'take words sub', 'words sub words', 'sub words tokenize', 'words tokenize give', 'tokenize give id', 'give id token', 'id token one', 'token one two', 'one two three', 'two three pass', 'three pass black', 'pass black box', 'black box already', 'box already said', 'already said going', 'said going talk', 'going talk architecture', 'talk architecture pass', 'architecture pass model', 'pass model get', 'model get distribution', 'get distribution probability', 'distribution probability distribution', 'probability distribution next', 'distribution next word', 'next word next', 'word next token', 'next token sample', 'token sample distribution', 'sample distribution get', 'distribution get new', 'get new token', 'new token detokenize', 'token detokenize get', 'detokenize get new', 'get new id', 'new id get', 'id get detokenize', 'get detokenize thats', 'detokenize thats sample', 'thats sample language', 'sample language model', 'language model one', 'model one thing', 'one thing important', 'thing important note', 'important note last', 'note last two', 'last two steps', 'two steps needed', 'steps needed inference', 'needed inference training', 'inference training need', 'training need predict', 'need predict likely', 'predict likely token', 'likely token compare', 'token compare real', 'compare real token', 'real token happened', 'token happened practice', 'happened practice change', 'practice change weights', 'change weights model', 'weights model increase', 'model increase probability', 'increase probability generating', 'probability generating token', 'generating token great', 'token great progressive', 'great progressive neural', 'progressive neural language', 'neural language models', 'language models slightly', 'models slightly specific', 'slightly specific still', 'specific still without', 'still without talking', 'without talking architecture', 'talking architecture first', 'architecture first thing', 'first thing yes', 'thing yes predicting', 'yes predicting probability', 'predicting probability next', 'probability next token', 'next token may', 'token may final', 'may final output', 'final output vector', 'output vector dimensionality', 'vector dimensionality number', 'dimensionality number tokens', 'number tokens yes', 'tokens yes deal', 'yes deal increase', 'deal increase adding', 'increase adding tokens', 'adding tokens tokens', 'tokens tokens private', 'tokens private sample', 'private sample yeah', 'sample yeah going', 'yeah going talk', 'going talk tokenization', 'talk tokenization later', 'tokenization later get', 'later get sense', 'get sense deal', 'sense deal adding', 'deal adding new', 'adding new tokens', 'new tokens im', 'tokens im kind', 'im kind exaggerating', 'kind exaggerating methods', 'exaggerating methods essentially', 'methods essentially people', 'essentially people dont', 'people dont really', 'dont really important', 'really important think', 'important think tokenize', 'think tokenize text', 'tokenize text thats', 'text thats well', 'thats well talk', 'well talk later', 'talk later good', 'later good point', 'good point notice', 'point notice vocabulary', 'notice vocabulary size', 'vocabulary size number', 'size number tokens', 'number tokens essentially', 'tokens essentially output', 'essentially output language', 'output language model', 'language model pretty', 'model pretty large', 'pretty large ok', 'large ok autoregressive', 'ok autoregressive new', 'autoregressive new language', 'new language models', 'language models first', 'models first thing', 'first thing take', 'thing take every', 'take every word', 'every word every', 'word every token', 'every token embed', 'token embed get', 'embed get vector', 'get vector representation', 'vector representation tokens', 'representation tokens pass', 'tokens pass neural', 'pass neural network', 'neural network said', 'network said transformer', 'said transformer get', 'transformer get representation', 'get representation words', 'representation words context', 'words context representation', 'context representation entire', 'representation entire sentence', 'entire sentence pass', 'sentence pass linear', 'pass linear layer', 'linear layer said', 'layer said map', 'said map number', 'map number output', 'number output number', 'output number outputs', 'number outputs number', 'outputs number tokens', 'number tokens pass', 'tokens pass softmax', 'pass softmax get', 'softmax get probability', 'get probability distribution', 'probability distribution next', 'distribution next words', 'next words given', 'words given every', 'given every word', 'every word context', 'word context last', 'context last use', 'last use essentially', 'use essentially task', 'essentially task classifying', 'task classifying next', 'classifying next token', 'next token simple', 'token simple kind', 'simple kind machine', 'kind machine learning', 'machine learning task', 'learning task use', 'task use crosscentral', 'use crosscentral p', 'crosscentral p loss', 'p loss look', 'loss look actual', 'look actual target', 'actual target happened', 'target happened target', 'happened target distribution', 'target distribution onehot', 'distribution onehot encoding', 'onehot encoding case', 'encoding case says', 'case says saw', 'says saw real', 'saw real one', 'real one happened', 'one happened cat', 'happened cat onehot', 'cat onehot distribution', 'onehot distribution cat', 'distribution cat actual', 'cat actual see', 'actual see mouse', 'see mouse oh', 'mouse oh yeah', 'oh yeah distribution', 'yeah distribution generate', 'distribution generate generated', 'generate generated see', 'generated see cross', 'see cross entropy', 'cross entropy really', 'entropy really increases', 'really increases probability', 'increases probability generating', 'probability generating cat', 'generating cat decreases', 'cat decreases probability', 'decreases probability generating', 'probability generating tokens', 'generating tokens one', 'tokens one thing', 'one thing notice', 'thing notice know', 'notice know equivalent', 'know equivalent maximizing', 'equivalent maximizing text', 'maximizing text log', 'text log text', 'log text log', 'text log likelihood', 'log likelihood rewrite', 'likelihood rewrite max', 'rewrite max probability', 'max probability autogressive', 'probability autogressive language', 'autogressive language modeling', 'language modeling task', 'modeling task minimum', 'task minimum added', 'minimum added log', 'added log minus', 'log minus minimum', 'minus minimum loss', 'minimum loss cross', 'loss cross entropy', 'cross entropy loss', 'entropy loss minimizing', 'loss minimizing loss', 'minimizing loss thing', 'loss thing maximizing', 'thing maximizing likelihood', 'maximizing likelihood text', 'likelihood text question', 'text question questions', 'question questions tokenizer', 'questions tokenizer one', 'tokenizer one thing', 'one thing people', 'thing people usually', 'people usually dont', 'usually dont talk', 'dont talk much', 'talk much tokenizers', 'much tokenizers extremely', 'tokenizers extremely important', 'extremely important really', 'important really important', 'really important kind', 'important kind understand', 'kind understand least', 'understand least high', 'least high level', 'high level need', 'level need tokenizers', 'need tokenizers first', 'tokenizers first place', 'first place first', 'place first general', 'first general words', 'general words one', 'words one simple', 'one simple thing', 'simple thing might', 'thing might think', 'might think oh', 'think oh going', 'oh going take', 'going take every', 'take every word', 'every word say', 'word say every', 'say every word', 'every word token', 'word token happens', 'token happens theres', 'happens theres typo', 'theres typo word', 'typo word might', 'word might token', 'might token associated', 'token associated word', 'associated word typo', 'word typo dont', 'typo dont know', 'dont know pass', 'know pass word', 'pass word typo', 'word typo large', 'typo large language', 'large language model', 'language model next', 'model next also', 'next also even', 'also even think', 'even think words', 'think words words', 'words words words', 'words words fine', 'words fine latinbased', 'fine latinbased languages', 'latinbased languages think', 'languages think language', 'think language thai', 'language thai wont', 'thai wont simple', 'wont simple way', 'simple way tokenizing', 'way tokenizing spaces', 'tokenizing spaces spaces', 'spaces spaces words', 'spaces words really', 'words really tokens', 'really tokens much', 'tokens much general', 'much general words', 'general words first', 'words first thing', 'first thing second', 'thing second thing', 'second thing might', 'thing might think', 'might think might', 'think might tokenize', 'might tokenize every', 'tokenize every sentence', 'every sentence character', 'sentence character character', 'character character might', 'character might say', 'might say one', 'say one token', 'one token b', 'token b another', 'b another token', 'another token would', 'token would work', 'would work probably', 'work probably well', 'probably well issue', 'well issue sequence', 'issue sequence becomes', 'sequence becomes super', 'becomes super long', 'super long probably', 'long probably remember', 'probably remember lecture', 'remember lecture transformers', 'lecture transformers complexity', 'transformers complexity grows', 'complexity grows quadratically', 'grows quadratically length', 'quadratically length sequences', 'length sequences really', 'sequences really dont', 'really dont want', 'dont want super', 'want super long', 'super long sequence', 'long sequence tokenizers', 'sequence tokenizers try', 'tokenizers try deal', 'try deal two', 'deal two problems', 'two problems give', 'problems give common', 'give common sub', 'common sub sequences', 'sub sequences certain', 'sequences certain token', 'certain token usually', 'token usually thinking', 'usually thinking around', 'thinking around average', 'around average every', 'average every token', 'every token around', 'token around three', 'around three four', 'three four letters', 'four letters many', 'letters many algorithms', 'many algorithms tokenization', 'algorithms tokenization ill', 'tokenization ill talk', 'ill talk one', 'talk one give', 'one give high', 'give high level', 'high level call', 'level call bytepaying', 'call bytepaying coding', 'bytepaying coding pretty', 'coding pretty common', 'pretty common one', 'common one two', 'one two common', 'two common tokenizers', 'common tokenizers way', 'tokenizers way train', 'way train tokenizer', 'train tokenizer first', 'tokenizer first start', 'first start large', 'start large corpus', 'large corpus text', 'corpus text im', 'text im really', 'im really talking', 'really talking training', 'talking training large', 'training large language', 'large language model', 'language model yet', 'model yet purely', 'yet purely tokenization', 'purely tokenization step', 'tokenization step large', 'step large corpus', 'large corpus text', 'corpus text five', 'text five words', 'five words associate', 'words associate every', 'associate every character', 'every character corpus', 'character corpus text', 'corpus text different', 'text different token', 'different token split', 'token split character', 'split character different', 'character different token', 'different token call', 'token call tokens', 'call tokens go', 'tokens go text', 'go text every', 'text every time', 'every time see', 'time see pairs', 'see pairs tokens', 'pairs tokens common', 'tokens common common', 'common common pair', 'common pair token', 'pair token merge', 'token merge see', 'merge see three', 'see three times', 'three times tokens', 'times tokens next', 'tokens next youre', 'next youre gon', 'youre gon na', 'gon na say', 'na say new', 'say new token', 'new token continue', 'token continue repeat', 'continue repeat talk', 'repeat talk happens', 'talk happens three', 'happens three times', 'three times talk', 'times talk e', 'talk e happens', 'e happens sorry', 'happens sorry two', 'sorry two times', 'two times token', 'times token happens', 'token happens twice', 'happens twice ex', 'twice ex also', 'ex also happened', 'also happened twice', 'happened twice train', 'twice train tokenizer', 'train tokenizer corpus', 'tokenizer corpus text', 'corpus text small', 'text small thats', 'small thats would', 'thats would finish', 'would finish token', 'finish token treat', 'token treat trained', 'treat trained tokenizer', 'trained tokenizer reality', 'tokenizer reality much', 'reality much larger', 'much larger corpus', 'larger corpus text', 'corpus text real', 'text real tokenizer', 'real tokenizer think', 'tokenizer think gpt3', 'think gpt3 chgpd', 'gpt3 chgpd see', 'chgpd see would', 'see would separate', 'would separate words', 'separate words see', 'words see thing', 'see thing gave', 'thing gave previous', 'gave previous example', 'previous example token', 'example token becomes', 'token becomes token', 'becomes token tokenizer', 'token tokenizer split', 'tokenizer split two', 'split two tokens', 'two tokens token', 'tokens token andizer', 'token andizer yeah', 'andizer yeah thats', 'yeah thats tokenizers', 'thats tokenizers question', 'tokenizers question yeah', 'question yeah yeah', 'yeah yeah yeah', 'yeah yeah theres', 'yeah theres step', 'theres step tokenizers', 'step tokenizers call', 'tokenizers call pre', 'call pre tokenizers', 'pre tokenizers exactly', 'tokenizers exactly said', 'exactly said mostly', 'said mostly theory', 'mostly theory theres', 'theory theres reason', 'theres reason deal', 'reason deal spaces', 'deal spaces punctuation', 'spaces punctuation separately', 'punctuation separately could', 'separately could say', 'could say every', 'say every space', 'every space gets', 'space gets token', 'gets token every', 'token every punctuation', 'every punctuation gets', 'punctuation gets token', 'gets token could', 'token could merging', 'could merging problem', 'merging problem theres', 'problem theres efficiency', 'theres efficiency question', 'efficiency question training', 'question training tokenizers', 'training tokenizers takes', 'tokenizers takes long', 'takes long time', 'long time youre', 'time youre better', 'youre better consider', 'better consider every', 'consider every pair', 'every pair token', 'pair token end', 'token end saying', 'end saying theres', 'saying theres space', 'theres space pre', 'space pre tokenizers', 'pre tokenizers english', 'tokenizers english specific', 'english specific say', 'specific say theres', 'say theres space', 'theres space going', 'space going start', 'going start looking', 'start looking token', 'looking token came', 'token came token', 'came token came', 'token came afterwards', 'came afterwards youre', 'afterwards youre merging', 'youre merging spaces', 'merging spaces computation', 'spaces computation optimization', 'computation optimization could', 'optimization could theoretically', 'could theoretically deal', 'theoretically deal way', 'deal way character', 'way character yeah', 'character yeah merge', 'yeah merge tokens', 'merge tokens top', 'tokens top tokens', 'top tokens merged', 'tokens merged height', 'merged height smaller', 'height smaller token', 'smaller token keep', 'token keep smaller', 'keep smaller tokens', 'smaller tokens mean', 'tokens mean reality', 'mean reality doesnt', 'reality doesnt matter', 'doesnt matter much', 'matter much usually', 'much usually large', 'usually large corpus', 'large corpus text', 'corpus text everything', 'text everything usually', 'everything usually keep', 'usually keep small', 'keep small ones', 'small ones reason', 'ones reason want', 'reason want case', 'want case theres', 'case theres said', 'theres said grammatical', 'said grammatical mistakes', 'grammatical mistakes typos', 'mistakes typos still', 'typos still want', 'still want able', 'want able represent', 'able represent words', 'represent words character', 'words character yeah', 'character yeah yes', 'yeah yes yes', 'yes yes tokens', 'yes tokens unique', 'tokens unique mean', 'unique mean say', 'mean say case', 'say case token', 'case token one', 'token one occurrence', 'one occurrence need', 'occurrence need need', 'need need multiple', 'need multiple occurrence', 'multiple occurrence take', 'occurrence take different', 'take different meetings', 'different meetings see', 'meetings see oh', 'see oh see', 'oh see would', 'see would say', 'would say every', 'say every token', 'every token unique', 'token unique id', 'unique id great', 'id great question', 'great question example', 'question example think', 'example think bank', 'think bank could', 'bank could bank', 'could bank money', 'bank money bank', 'money bank water', 'bank water token', 'water token model', 'token model learn', 'model learn transformer', 'learn transformer learn', 'transformer learn based', 'learn based words', 'based words around', 'words around associate', 'around associate im', 'associate im saying', 'im saying im', 'saying im hindrower', 'im hindrower associate', 'hindrower associate representation', 'associate representation either', 'representation either bank', 'either bank money', 'bank money side', 'money side bank', 'side bank water', 'bank water side', 'water side thats', 'side thats transformer', 'thats transformer tokenizer', 'transformer tokenizer yes', 'tokenizer yes yes', 'yes yes mentioned', 'yes mentioned tokenization', 'mentioned tokenization theres', 'tokenization theres smaller', 'theres smaller tokens', 'smaller tokens trying', 'tokens trying say', 'trying say keep', 'say keep dont', 'keep dont need', 'dont need tokenize', 'need tokenize external', 'tokenize external icon', 'external icon tokenize', 'icon tokenize lets', 'tokenize lets say', 'lets say maybe', 'say maybe didnt', 'maybe didnt even', 'didnt even tokenize', 'even tokenize data', 'tokenize data trying', 'data trying encode', 'trying encode token', 'encode token tokenizer', 'token tokenizer know', 'tokenizer know code', 'know code token', 'code token react', 'token react yes', 'react yes great', 'yes great question', 'great question tokenize', 'question tokenize thats', 'tokenize thats training', 'thats training tokenizer', 'training tokenizer apply', 'tokenizer apply tokenizer', 'apply tokenizer always', 'tokenizer always choose', 'always choose largest', 'choose largest token', 'largest token apply', 'token apply token', 'apply token never', 'token never always', 'never always token', 'always token theres', 'token theres people', 'theres people dont', 'people dont really', 'dont really talk', 'really talk much', 'talk much tokenizers', 'much tokenizers theres', 'tokenizers theres lot', 'theres lot computational', 'lot computational benefits', 'computational benefits computational', 'benefits computational tricks', 'computational tricks making', 'tricks making things', 'making things faster', 'things faster really', 'faster really dont', 'really dont think', 'dont think honestly', 'think honestly think', 'honestly think lot', 'think lot people', 'lot people think', 'people think get', 'think get away', 'get away tokenizers', 'away tokenizers kind', 'tokenizers kind tokenize', 'kind tokenize character', 'tokenize character character', 'character character bytes', 'character bytes bytes', 'bytes bytes said', 'bytes said right', 'said right issue', 'right issue length', 'issue length maybe', 'length maybe one', 'maybe one day', 'one day five', 'day five 10', 'five 10 years', '10 years well', 'years well different', 'well different architectures', 'different architectures dont', 'architectures dont scale', 'dont scale credetically', 'scale credetically length', 'credetically length sequence', 'length sequence maybe', 'sequence maybe well', 'maybe well move', 'well move away', 'move away tokenizers', 'away tokenizers sure', 'tokenizers sure us', 'sure us drawback', 'us drawback give', 'drawback give people', 'give people one', 'people one move', 'one move away', 'move away tokenizer', 'away tokenizer oh', 'tokenizer oh yeah', 'oh yeah think', 'yeah think one', 'think one good', 'one good example', 'good example math', 'example math think', 'math think math', 'think math numbers', 'math numbers right', 'numbers right tokenized', 'right tokenized example', 'tokenized example 327', 'example 327 might', '327 might token', 'might token means', 'token means models', 'means models see', 'models see numbers', 'see numbers dont', 'numbers dont see', 'dont see way', 'see way annoying', 'way annoying reason', 'annoying reason kind', 'reason kind generalize', 'kind generalize math', 'generalize math deal', 'math deal every', 'deal every letter', 'every letter separately', 'letter separately composition', 'separately composition know', 'composition know add', 'know add stuff', 'add stuff thing', 'stuff thing adding', 'thing adding every', 'adding every one', 'every one separately', 'one separately plus', 'separately plus whatever', 'plus whatever unit', 'whatever unit add', 'unit add special', 'add special tokenization', 'special tokenization one', 'tokenization one big', 'one big changes', 'big changes gpt', 'changes gpt forwarded', 'gpt forwarded changed', 'forwarded changed way', 'changed way tokenize', 'way tokenize code', 'tokenize code example', 'code example code', 'example code know', 'code know often', 'know often python', 'often python four', 'python four spaces', 'four spaces beginning', 'spaces beginning dealt', 'beginning dealt kind', 'dealt kind strangely', 'kind strangely result', 'strangely result model', 'result model couldnt', 'model couldnt really', 'couldnt really understand', 'really understand deal', 'understand deal code', 'deal code tokenization', 'code tokenization matters', 'tokenization matters lot', 'matters lot ill', 'lot ill move', 'ill move right', 'move right come', 'right come back', 'come back later', 'back later tokenizers', 'later tokenizers great', 'tokenizers great talked', 'great talked task', 'talked task last', 'task last tokenizer', 'last tokenizer lets', 'tokenizer lets talk', 'lets talk little', 'talk little bit', 'little bit evaluation', 'bit evaluation way', 'evaluation way llms', 'way llms usually', 'llms usually evaluated', 'usually evaluated call', 'evaluated call using', 'call using call', 'using call poplexity', 'call poplexity high', 'poplexity high level', 'high level validation', 'level validation loss', 'validation loss slight', 'loss slight difference', 'slight difference poplexity', 'difference poplexity use', 'poplexity use something', 'use something slightly', 'something slightly vulnerable', 'slightly vulnerable use', 'vulnerable use average', 'use average per', 'average per token', 'per token loss', 'token loss exponentiate', 'loss exponentiate reason', 'exponentiate reason exponentiate', 'reason exponentiate want', 'exponentiate want mean', 'want mean loss', 'mean loss log', 'loss log inside', 'log inside one', 'inside one humans', 'one humans pretty', 'humans pretty bad', 'pretty bad thinking', 'bad thinking log', 'thinking log space', 'log space two', 'space two logs', 'two logs depend', 'logs depend base', 'depend base log', 'base log exponentiate', 'log exponentiate everything', 'exponentiate everything kind', 'everything kind vocabulary', 'kind vocabulary size', 'vocabulary size unit', 'size unit average', 'unit average token', 'average token poplexity', 'token poplexity independent', 'poplexity independent length', 'independent length sequence', 'length sequence poplexity', 'sequence poplexity power', 'poplexity power average', 'power average loss', 'average loss sequence', 'loss sequence perplexity', 'sequence perplexity one', 'perplexity one length', 'one length vocabulary', 'length vocabulary tokenizer', 'vocabulary tokenizer one', 'tokenizer one simply', 'one simply well', 'simply well predict', 'well predict perfectly', 'predict perfectly thing', 'perfectly thing every', 'thing every word', 'every word every', 'word every word', 'every word product', 'word product ones', 'product ones best', 'ones best perplexity', 'best perplexity one', 'perplexity one really', 'one really idea', 'really idea predict', 'idea predict one', 'predict one divided', 'one divided size', 'divided size vocabulary', 'size vocabulary simple', 'vocabulary simple math', 'simple math get', 'math get perplexity', 'get perplexity size', 'perplexity size vocabulary', 'size vocabulary tuition', 'vocabulary tuition perplexity', 'tuition perplexity number', 'perplexity number tokens', 'number tokens youre', 'tokens youre model', 'youre model kind', 'model kind hesitating', 'kind hesitating youre', 'hesitating youre model', 'youre model perfect', 'model perfect doesnt', 'perfect doesnt hesitate', 'doesnt hesitate exactly', 'hesitate exactly word', 'exactly word really', 'word really idea', 'really idea hesitates', 'idea hesitates vocabulary', 'hesitates vocabulary perplexity', 'vocabulary perplexity really', 'perplexity really improved', 'really improved thats', 'improved thats perplexity', 'thats perplexity standard', 'perplexity standard data', 'standard data set', 'data set 2017', 'set 2017 2023', '2017 2023 went', '2023 went kind', 'went kind 70', 'kind 70 tokens', '70 tokens less', 'tokens less 10', 'less 10 tokens', '10 tokens five', 'tokens five six', 'five six years', 'six years means', 'years means models', 'means models previously', 'models previously dated', 'previously dated 70', 'dated 70 words', '70 words every', 'words every time', 'every time generating', 'time generating word', 'generating word dating', 'word dating less', 'dating less 10', 'less 10 words', '10 words thats', 'words thats much', 'thats much better', 'much better complexity', 'better complexity used', 'complexity used anymore', 'used anymore academic', 'anymore academic benchmarking', 'academic benchmarking sick', 'benchmarking sick depends', 'sick depends tokenizer', 'depends tokenizer use', 'tokenizer use depends', 'use depends actual', 'depends actual data', 'actual data people', 'data people evaluating', 'people evaluating still', 'evaluating still important', 'still important development', 'important development llms', 'development llms train', 'llms train llm', 'train llm people', 'llm people still', 'people still really', 'still really look', 'really look complexity', 'look complexity one', 'complexity one common', 'one common way', 'common way common', 'way common academia', 'common academia evaluating', 'academia evaluating llms', 'evaluating llms taking', 'llms taking classical', 'taking classical nlp', 'classical nlp benchmarks', 'nlp benchmarks ill', 'benchmarks ill give', 'ill give examples', 'give examples later', 'examples later kind', 'later kind aggregating', 'kind aggregating everything', 'aggregating everything collect', 'everything collect many', 'collect many automatically', 'many automatically evaluable', 'automatically evaluable benchmarks', 'evaluable benchmarks evaluate', 'benchmarks evaluate across', 'evaluate across one', 'across one two', 'one two benchmarks', 'two benchmarks call', 'benchmarks call helm', 'call helm stanford', 'helm stanford another', 'stanford another one', 'another one hugging', 'one hugging face', 'hugging face open', 'face open llm', 'open llm lead', 'llm lead award', 'lead award probably', 'award probably two', 'probably two common', 'two common ones', 'common ones right', 'ones right give', 'right give idea', 'give idea type', 'idea type tasks', 'type tasks mostly', 'tasks mostly things', 'mostly things easily', 'things easily evaluated', 'easily evaluated question', 'evaluated question answering', 'question answering think', 'answering think many', 'think many different', 'many different question', 'different question answering', 'question answering tasks', 'answering tasks benefit', 'tasks benefit question', 'benefit question answering', 'question answering usually', 'answering usually know', 'usually know real', 'know real answer', 'real answer way', 'answer way evaluate', 'way evaluate models', 'evaluate models ill', 'models ill give', 'ill give concrete', 'give concrete example', 'concrete example one', 'example one second', 'one second look', 'second look likely', 'look likely language', 'likely language model', 'language model generate', 'model generate real', 'generate real answer', 'real answer compared', 'answer compared answers', 'compared answers thats', 'answers thats essentially', 'thats essentially high', 'essentially high level', 'high level evaluate', 'level evaluate models', 'evaluate models give', 'models give specific', 'give specific example', 'specific example mmlu', 'example mmlu probably', 'mmlu probably common', 'probably common academic', 'common academic benchmark', 'academic benchmark lms', 'benchmark lms collection', 'lms collection many', 'collection many question', 'many question answers', 'question answers domains', 'answers domains example', 'domains example college', 'example college medicine', 'college medicine college', 'medicine college physics', 'college physics astronomy', 'physics astronomy type', 'astronomy type topics', 'type topics questions', 'topics questions things', 'questions things astronomy', 'things astronomy true', 'astronomy true type', 'true type 1a', 'type 1a supernova', '1a supernova give', 'supernova give 4', 'give 4 different', '4 different potential', 'different potential answers', 'potential answers ask', 'answers ask model', 'ask model one', 'model one likely', 'one likely many', 'likely many different', 'many different ways', 'different ways either', 'ways either look', 'either look likelihood', 'look likelihood generating', 'likelihood generating answers', 'generating answers ask', 'answers ask model', 'ask model one', 'model one likely', 'one likely different', 'likely different ways', 'different ways prompt', 'ways prompt model', 'prompt model high', 'model high level', 'high level know', 'level know one', 'know one correct', 'one correct three', 'correct three mistakes', 'three mistakes yes', 'mistakes yes creating', 'yes creating unconstrained', 'creating unconstrained text', 'unconstrained text thats', 'text thats funny', 'thats funny yeah', 'funny yeah downtothemodel', 'yeah downtothemodel gives', 'downtothemodel gives something', 'gives something thats', 'something thats know', 'thats know semantically', 'know semantically completely', 'semantically completely identical', 'completely identical exact', 'identical exact totalist', 'exact totalist expect', 'totalist expect yeah', 'expect yeah thats', 'yeah thats great', 'thats great question', 'great question ill', 'question ill talk', 'ill talk later', 'talk later case', 'later case dont', 'case dont unconstrained', 'dont unconstrained way', 'unconstrained way would', 'way would evaluate', 'would evaluate mmlu', 'evaluate mmlu either', 'mmlu either look', 'either look first', 'look first question', 'first question look', 'question look likelihood', 'look likelihood model', 'likelihood model generating', 'model generating likelihood', 'generating likelihood model', 'likelihood model generating', 'model generating b', 'generating b c', 'b c look', 'c look one', 'look one likely', 'one likely oh', 'likely oh ask', 'oh ask model', 'ask model abcd', 'model abcd one', 'abcd one likely', 'one likely look', 'likely look model', 'look model look', 'model look extokin', 'look extokin b', 'extokin b c', 'b c stream', 'c stream model', 'stream model say', 'model say answer', 'say answer four', 'answer four things', 'four things say', 'things say stream', 'say stream model', 'stream model yeah', 'model yeah stream', 'yeah stream prompt', 'stream prompt mean', 'prompt mean whole', 'mean whole probability', 'whole probability distribution', 'probability distribution outfits', 'distribution outfits youre', 'outfits youre comparing', 'youre comparing outfits', 'comparing outfits youre', 'outfits youre comparing', 'youre comparing atunkin', 'comparing atunkin yeah', 'atunkin yeah second', 'yeah second case', 'second case gave', 'case gave would', 'gave would exactly', 'would exactly would', 'exactly would first', 'would first model', 'first model saying', 'model saying b', 'saying b c', 'b c plus', 'c plus would', 'plus would consume', 'would consume look', 'consume look four', 'look four tokens', 'four tokens first', 'tokens first case', 'first case dont', 'case dont even', 'dont even need', 'even need generate', 'need generate anything', 'generate anything first', 'anything first case', 'first case literally', 'case literally look', 'literally look given', 'look given language', 'given language model', 'language model give', 'model give distribution', 'give distribution sentences', 'distribution sentences look', 'sentences look likelihood', 'look likelihood generating', 'likelihood generating words', 'generating words likelihood', 'words likelihood generating', 'likelihood generating second', 'generating second choice', 'second choice look', 'choice look whether', 'look whether likely', 'whether likely sentence', 'likely sentence real', 'sentence real answer', 'real answer youre', 'answer youre sample', 'youre sample really', 'sample really use', 'really use p', 'use p x1', 'p x1 xl', 'x1 xl make', 'xl make sense', 'make sense sense', 'sense sense said', 'sense said evaluation', 'said evaluation openended', 'evaluation openended questions', 'openended questions something', 'questions something going', 'something going talk', 'going talk later', 'talk later really', 'later really important', 'really important really', 'important really challenging', 'really challenging yes', 'challenging yes earlier', 'yes earlier mentioned', 'earlier mentioned metrics', 'mentioned metrics complexity', 'metrics complexity usually', 'complexity usually used', 'usually used depends', 'used depends design', 'depends design choices', 'design choices also', 'choices also want', 'also want speak', 'want speak oh', 'speak oh yeah', 'oh yeah think', 'yeah think complexity', 'think complexity told', 'complexity told complexity', 'told complexity one', 'complexity one vocabulary', 'one vocabulary size', 'vocabulary size imagine', 'size imagine chatgpt', 'imagine chatgpt uses', 'chatgpt uses tokenizer', 'uses tokenizer 10000', 'tokenizer 10000 tokens', '10000 tokens gemini', 'tokens gemini google', 'gemini google uses', 'google uses tokenizer', 'uses tokenizer 100000', 'tokenizer 100000 potential', '100000 potential tokens', 'potential tokens gemini', 'tokens gemini one', 'gemini one upper', 'one upper bound', 'upper bound complexity', 'bound complexity get', 'complexity get worse', 'get worse gemini', 'worse gemini chatgpt', 'gemini chatgpt make', 'chatgpt make sense', 'make sense thats', 'sense thats idea', 'thats idea little', 'idea little bit', 'little bit complicated', 'bit complicated theres', 'complicated theres one', 'theres one first', 'one first bit', 'first bit see', 'bit see tokenizer', 'see tokenizer matters', 'tokenizer matters great', 'matters great ok', 'great ok evaluation', 'ok evaluation challenges', 'evaluation challenges many', 'challenges many ill', 'many ill talk', 'ill talk two', 'talk two really', 'two really briefly', 'really briefly one', 'briefly one told', 'one told two', 'told two ways', 'two ways evaluation', 'ways evaluation mml', 'evaluation mml views', 'mml views many', 'views many two', 'many two give', 'two give two', 'give two examples', 'two examples happens', 'examples happens long', 'happens long time', 'long time even', 'time even though', 'even though classical', 'though classical benchmark', 'classical benchmark everyone', 'benchmark everyone used', 'everyone used different', 'used different companies', 'different companies different', 'companies different organization', 'different organization using', 'organization using different', 'using different ways', 'different ways evaluating', 'ways evaluating mml', 'evaluating mml view', 'mml view result', 'view result get', 'result get completely', 'get completely different', 'completely different results', 'different results example', 'results example lamas', 'example lamas 65b', 'lamas 65b first', '65b first model', 'first model meta', 'model meta lamas', 'meta lamas series', 'lamas series helm', 'series helm 637', 'helm 637 accuracy', '637 accuracy benchmark', 'accuracy benchmark 488', 'benchmark 488 really', '488 really way', 'really way evaluate', 'way evaluate even', 'evaluate even talking', 'even talking prompting', 'talking prompting really', 'prompting really kind', 'really kind way', 'kind way evaluate', 'way evaluate models', 'evaluate models promoting', 'models promoting another', 'promoting another issue', 'another issue really', 'issue really lot', 'really lot inconsistencies', 'lot inconsistencies easy', 'inconsistencies easy looks', 'easy looks first', 'looks first thing', 'first thing yeah', 'thing yeah sorry', 'yeah sorry make', 'sorry make sure', 'make sure models', 'sure models arent', 'models arent trained', 'arent trained bench', 'trained bench model', 'bench model second', 'model second thing', 'second thing great', 'thing great question', 'great question train', 'question train test', 'train test contamination', 'test contamination something', 'contamination something would', 'something would say', 'would say really', 'say really important', 'really important academia', 'important academia given', 'academia given talk', 'given talk mostly', 'talk mostly training', 'mostly training large', 'training large language', 'large language models', 'language models companies', 'models companies maybe', 'companies maybe important', 'maybe important know', 'important know trained', 'know trained us', 'trained us idea', 'us idea far', 'idea far real', 'far real problem', 'real problem many', 'problem many different', 'many different ways', 'different ways trying', 'ways trying test', 'trying test set', 'test set sorry', 'set sorry whether', 'sorry whether test', 'whether test set', 'test set training', 'set training set', 'training set one', 'set one kind', 'one kind cut', 'kind cut trick', 'cut trick people', 'trick people lab', 'people lab tetsus', 'lab tetsus lab', 'tetsus lab found', 'lab found given', 'found given data', 'given data set', 'data set online', 'set online randomized', 'online randomized look', 'randomized look language', 'look language models', 'language models predict', 'models predict next', 'predict next word', 'next word look', 'word look entire', 'look entire test', 'entire test set', 'test set generate', 'set generate examples', 'generate examples order', 'examples order versus', 'order versus examples', 'versus examples different', 'examples different order', 'different order likely', 'order likely generate', 'likely generate thing', 'generate thing order', 'thing order given', 'order given theres', 'given theres real', 'theres real order', 'real order means', 'order means probably', 'means probably training', 'probably training set', 'training set make', 'set make sense', 'make sense many', 'sense many thats', 'many thats one', 'thats one many', 'one many ways', 'many ways train', 'ways train test', 'train test contamination', 'test contamination important', 'contamination important development', 'important development really', 'development really important', 'really important academic', 'important academic benchmarking', 'academic benchmarking great', 'benchmarking great many', 'great many challenges', 'many challenges ill', 'challenges ill move', 'ill move great', 'move great data', 'great data data', 'data data another', 'data another really', 'another really big', 'really big topic', 'big topic high', 'topic high level', 'high level people', 'level people say', 'people say oh', 'say oh train', 'oh train large', 'train large language', 'large language models', 'language models internet', 'models internet even', 'internet even mean', 'even mean people', 'mean people sometimes', 'people sometimes say', 'sometimes say clean', 'say clean internet', 'clean internet even', 'internet even less', 'even less fun', 'less fun internet', 'fun internet dirty', 'internet dirty really', 'dirty really representative', 'really representative one', 'representative one practice', 'one practice download', 'practice download random', 'download random website', 'random website right', 'website right would', 'right would shocked', 'would shocked definitely', 'shocked definitely wikipedia', 'definitely wikipedia ill', 'wikipedia ill go', 'ill go really', 'go really briefly', 'really briefly people', 'briefly people answer', 'people answer questions', 'answer questions data', 'questions data huge', 'data huge topic', 'huge topic first', 'topic first download', 'first download internet', 'download internet means', 'internet means use', 'means use web', 'use web crawlers', 'web crawlers go', 'crawlers go every', 'go every web', 'every web page', 'web page internet', 'page internet every', 'internet every web', 'every web page', 'web page google', 'page google around', 'google around 250', 'around 250 billion', '250 billion pages', 'billion pages right', 'pages right thats', 'right thats around', 'thats around one', 'around one petabyte', 'one petabyte data', 'petabyte data common', 'data common crawl', 'common crawl one', 'crawl one web', 'one web crawler', 'web crawler people', 'crawler people usually', 'people usually write', 'usually write web', 'write web crawlers', 'web crawlers use', 'crawlers use standard', 'use standard web', 'standard web crawlers', 'web crawlers common', 'crawlers common crawl', 'common crawl one', 'crawl one every', 'one every month', 'every month adds', 'month adds new', 'adds new websites', 'new websites added', 'websites added internet', 'added internet found', 'internet found google', 'found google put', 'google put big', 'put big big', 'big big data', 'big data set', 'data set thats', 'set thats common', 'thats common quall', 'common quall around', 'quall around 250', 'around 250 billion', '250 billion pages', 'billion pages right', 'pages right 1', 'right 1 e6', '1 e6 gigabytes', 'e6 gigabytes data', 'gigabytes data random', 'data random web', 'random web page', 'web page literally', 'page literally random', 'literally random common', 'random common quall', 'common quall see', 'quall see im', 'see im one', 'im one really', 'one really doesnt', 'really doesnt look', 'doesnt look type', 'look type things', 'type things would', 'things would usually', 'would usually see', 'usually see html', 'see html page', 'html page hard', 'page hard see', 'hard see look', 'see look see', 'look see content', 'see content example', 'content example test', 'example test king', 'test king world', 'king world ultimate', 'world ultimate source', 'ultimate source system', 'source system xhigh', 'system xhigh performance', 'xhigh performance server', 'performance server three', 'server three dots', 'three dots dont', 'dots dont even', 'dont even sentence', 'even sentence even', 'sentence even finished', 'even finished thats', 'finished thats random', 'thats random internet', 'random internet looks', 'internet looks course', 'looks course useful', 'course useful train', 'useful train large', 'train large language', 'large language model', 'language model generate', 'model generate things', 'generate things steps', 'things steps needed', 'steps needed first', 'needed first one', 'first one extract', 'one extract text', 'extract text html', 'text html thats', 'html thats tried', 'thats tried looking', 'tried looking correct', 'looking correct text', 'correct text lot', 'text lot challenges', 'lot challenges example', 'challenges example extracting', 'example extracting math', 'extracting math common', 'math common complicated', 'common complicated pretty', 'complicated pretty important', 'pretty important training', 'important training large', 'training large language', 'large language models', 'language models example', 'models example boilerplates', 'example boilerplates lot', 'boilerplates lot forums', 'lot forums type', 'forums type headers', 'type headers type', 'headers type footers', 'type footers dont', 'footers dont want', 'dont want repeat', 'want repeat data', 'repeat data filter', 'data filter undesirable', 'filter undesirable content', 'undesirable content safe', 'content safe work', 'safe work harmful', 'work harmful content', 'harmful content pii', 'content pii usually', 'pii usually every', 'usually every company', 'every company blacklist', 'company blacklist websites', 'blacklist websites dont', 'websites dont want', 'dont want train', 'want train models', 'train models blacklist', 'models blacklist long', 'blacklist long say', 'long say comes', 'say comes dont', 'comes dont train', 'dont train ways', 'train ways things', 'ways things train', 'things train small', 'train small model', 'small model classifying', 'model classifying pii', 'classifying pii removing', 'pii removing things', 'removing things hard', 'things hard every', 'hard every point', 'every point im', 'point im going', 'im going show', 'going show hard', 'show hard amount', 'hard amount work', 'amount work im', 'work im going', 'im going go', 'going go quickly', 'go quickly filter', 'quickly filter undesirable', 'filter undesirable content', 'undesirable content second', 'content second fourth', 'second fourth duplication', 'fourth duplication said', 'duplication said might', 'said might things', 'might things headers', 'things headers footers', 'headers footers forums', 'footers forums always', 'forums always want', 'always want remove', 'want remove another', 'remove another thing', 'another thing might', 'thing might lot', 'might lot urls', 'lot urls different', 'urls different show', 'different show website', 'show website might', 'website might also', 'might also lot', 'also lot paragraphs', 'lot paragraphs come', 'paragraphs come common', 'come common books', 'common books dedoubligated', 'books dedoubligated thousand', 'dedoubligated thousand times', 'thousand times 10000', 'times 10000 times', '10000 times internet', 'times internet need', 'internet need dedoubligate', 'need dedoubligate also', 'dedoubligate also challenging', 'also challenging scale', 'challenging scale dedoubligation', 'scale dedoubligation heuristic', 'dedoubligation heuristic filtering', 'heuristic filtering try', 'filtering try remove', 'try remove lowquality', 'remove lowquality documents', 'lowquality documents way', 'documents way things', 'way things rulesbased', 'things rulesbased filtering', 'rulesbased filtering example', 'filtering example see', 'example see outlier', 'see outlier tokens', 'outlier tokens distribution', 'tokens distribution tokens', 'distribution tokens website', 'tokens website different', 'website different usual', 'different usual distribution', 'usual distribution tokens', 'distribution tokens probably', 'tokens probably outlier', 'probably outlier see', 'outlier see length', 'see length words', 'length words website', 'words website super', 'website super long', 'super long theres', 'long theres something', 'theres something strange', 'something strange going', 'strange going website', 'going website see', 'website see website', 'see website three', 'website three words', 'three words maybe', 'words maybe worth', 'maybe worth training', 'worth training maybe', 'training maybe 10', 'maybe 10 million', '10 million words', 'million words maybe', 'words maybe theres', 'maybe theres something', 'theres something also', 'something also wrong', 'also wrong going', 'wrong going page', 'going page lot', 'page lot rules', 'lot rules yes', 'rules yes undesirable', 'yes undesirable content', 'undesirable content data', 'content data set', 'data set instead', 'set instead kind', 'instead kind supervised', 'kind supervised mass', 'supervised mass say', 'mass say heres', 'say heres hate', 'heres hate speech', 'hate speech website', 'speech website thats', 'website thats actively', 'thats actively trying', 'actively trying actively', 'trying actively penalize', 'actively penalize data', 'penalize data well', 'data well exactly', 'well exactly step', 'exactly step thats', 'step thats post', 'thats post training', 'post training come', 'training come pretraining', 'come pretraining idea', 'pretraining idea say', 'idea say want', 'say want model', 'want model kind', 'model kind humans', 'kind humans speak', 'humans speak essentially', 'speak essentially want', 'essentially want remove', 'want remove headers', 'remove headers photos', 'headers photos menus', 'photos menus things', 'menus things good', 'things good idea', 'good idea thats', 'idea thats exactly', 'thats exactly well', 'exactly well later', 'well later next', 'later next step', 'next step model', 'step model base', 'model base field', 'base field training', 'field training youve', 'training youve filtered', 'youve filtered lot', 'filtered lot data', 'lot data thats', 'data thats cute', 'thats cute trick', 'cute trick take', 'trick take wikipedia', 'take wikipedia look', 'wikipedia look links', 'look links linked', 'links linked wikipedia', 'linked wikipedia pages', 'wikipedia pages probably', 'pages probably something', 'probably something wikipedia', 'something wikipedia probably', 'wikipedia probably highquality', 'probably highquality website', 'highquality website train', 'website train classifier', 'train classifier predict', 'classifier predict whether', 'predict whether something', 'whether something comes', 'something comes whether', 'comes whether document', 'whether document comes', 'document comes one', 'comes one references', 'one references wikipedia', 'references wikipedia whether', 'wikipedia whether random', 'whether random web', 'random web try', 'web try say', 'try say want', 'say want things', 'want things come', 'things come wikipedia', 'come wikipedia references', 'wikipedia references make', 'references make sense', 'make sense yeah', 'sense yeah train', 'yeah train machine', 'train machine learning', 'machine learning model', 'learning model usually', 'model usually also', 'usually also simple', 'also simple models', 'simple models need', 'models need really', 'need really scale', 'really scale mean', 'scale mean think', 'mean think 250', 'think 250 billion', '250 billion pages', 'billion pages next', 'pages next one', 'next one try', 'one try classify', 'try classify data', 'classify data different', 'data different domains', 'different domains say', 'domains say ok', 'say ok entertainment', 'ok entertainment books', 'entertainment books code', 'books code type', 'code type domains', 'type domains try', 'domains try either', 'try either downweight', 'either downweight domains', 'downweight domains example', 'domains example might', 'example might say', 'might say might', 'say might see', 'might see train', 'see train code', 'train code model', 'code model becomes', 'model becomes better', 'becomes better reasoning', 'better reasoning thats', 'reasoning thats something', 'thats something people', 'something people people', 'people people usually', 'people usually say', 'usually say handwaver', 'say handwaver way', 'handwaver way train', 'way train model', 'train model code', 'model code helps', 'code helps reasoning', 'helps reasoning want', 'reasoning want upweight', 'want upweight coding', 'upweight coding distribution', 'coding distribution helps', 'distribution helps general', 'helps general language', 'general language modeling', 'language modeling skills', 'modeling skills books', 'skills books usually', 'books usually also', 'usually also another', 'also another one', 'another one people', 'one people usually', 'people usually upweight', 'usually upweight entertainment', 'upweight entertainment usually', 'entertainment usually downweight', 'usually downweight things', 'downweight things course', 'things course want', 'course want people', 'want people used', 'people used maybe', 'used maybe kind', 'maybe kind heuristically', 'kind heuristically theres', 'heuristically theres entire', 'theres entire pipelines', 'entire pipelines well', 'pipelines well talk', 'well talk things', 'talk things slightly', 'things slightly automatically', 'slightly automatically end', 'automatically end training', 'end training usually', 'training usually training', 'usually training data', 'training data saw', 'data saw usually', 'saw usually train', 'usually train highquality', 'train highquality data', 'highquality data end', 'data end training', 'end training large', 'training large language', 'large language model', 'language model decrease', 'model decrease learning', 'decrease learning rate', 'learning rate means', 'rate means youre', 'means youre kind', 'youre kind overfitting', 'kind overfitting model', 'overfitting model highquality', 'model highquality data', 'highquality data usually', 'data usually wikipedia', 'usually wikipedia overfit', 'wikipedia overfit wikipedia', 'overfit wikipedia overfit', 'wikipedia overfit human', 'overfit human data', 'human data collected', 'data collected thing', 'collected thing continue', 'thing continue pretraining', 'continue pretraining forgetting', 'pretraining forgetting longer', 'forgetting longer context', 'longer context im', 'context im going', 'im going skip', 'going skip things', 'skip things give', 'things give sense', 'give sense hard', 'sense hard people', 'hard people say', 'people say oh', 'say oh im', 'oh im going', 'im going train', 'going train internet', 'train internet thats', 'internet thats lot', 'thats lot work', 'lot work really', 'work really havent', 'really havent figured', 'havent figured yet', 'figured yet collecting', 'yet collecting well', 'collecting well data', 'well data huge', 'data huge part', 'huge part practical', 'part practical large', 'practical large language', 'large language model', 'language model might', 'model might say', 'might say key', 'say key yes', 'key yes data', 'yes data theres', 'data theres question', 'theres question usually', 'question usually would', 'usually would install', 'would install term', 'install term write', 'term write data', 'write data go', 'data go masters', 'go masters suppose', 'masters suppose typical', 'suppose typical amount', 'typical amount large', 'amount large seems', 'large seems big', 'seems big deal', 'big deal go', 'deal go data', 'go data steps', 'data steps took', 'steps took question', 'took question large', 'question large data', 'large data filter', 'data filter yes', 'filter yes feel', 'yes feel good', 'feel good go', 'good go large', 'go large seems', 'large seems need', 'seems need go', 'need go field', 'go field order', 'field order future', 'order future systems', 'future systems slow', 'systems slow many', 'slow many people', 'many people would', 'people would need', 'would need oh', 'need oh going', 'oh going video', 'going video ok', 'video ok thats', 'ok thats great', 'thats great question', 'great question im', 'question im going', 'im going somewhat', 'going somewhat answer', 'somewhat answer data', 'answer data large', 'data large dataset', 'large dataset end', 'dataset end slide', 'end slide number', 'slide number people', 'number people work', 'people work thats', 'work thats great', 'thats great question', 'great question im', 'question im quite', 'im quite sure', 'quite sure would', 'sure would say', 'would say yeah', 'say yeah dont', 'yeah dont quite', 'dont quite know', 'quite know would', 'know would say', 'would say probably', 'say probably even', 'probably even bigger', 'even bigger number', 'bigger number people', 'number people work', 'people work kind', 'work kind tuning', 'kind tuning pretraining', 'tuning pretraining model', 'pretraining model data', 'model data bigger', 'data bigger kind', 'bigger kind modeling', 'kind modeling aspect', 'modeling aspect yeah', 'aspect yeah dont', 'yeah dont think', 'dont think good', 'think good sense', 'good sense would', 'sense would say', 'would say probably', 'say probably lamas', 'probably lamas team', 'lamas team 70', 'team 70 hp', '70 hp people', 'hp people would', 'people would say', 'would say maybe', 'say maybe 15', 'maybe 15 work', '15 work data', 'work data yeah', 'data yeah things', 'yeah things dont', 'things dont need', 'dont need many', 'need many people', 'many people need', 'people need lot', 'need lot computer', 'lot computer also', 'computer also data', 'also data need', 'data need lot', 'need lot cpus', 'lot cpus yeah', 'cpus yeah ill', 'yeah ill answer', 'ill answer second', 'answer second question', 'second question end', 'question end slide', 'end slide kind', 'slide kind alluded', 'kind alluded really', 'alluded really installed', 'really installed data', 'installed data pretraining', 'data pretraining theres', 'pretraining theres lot', 'theres lot research', 'lot research done', 'research done first', 'done first process', 'first process things', 'process things super', 'things super efficiently', 'super efficiently second', 'efficiently second balance', 'second balance different', 'balance different domains', 'different domains synthetic', 'domains synthetic data', 'synthetic data generation', 'data generation thats', 'generation thats big', 'thats big one', 'big one right', 'one right dont', 'right dont well', 'dont well talk', 'well talk later', 'talk later dont', 'later dont enough', 'dont enough data', 'enough data internet', 'data internet use', 'internet use multimodal', 'use multimodal data', 'multimodal data instead', 'data instead text', 'instead text data', 'text data improve', 'data improve even', 'improve even text', 'even text performance', 'text performance theres', 'performance theres lot', 'theres lot secrecy', 'lot secrecy really', 'secrecy really key', 'really key pretrained', 'key pretrained large', 'pretrained large language', 'large language models', 'language models competitive', 'models competitive dynamics', 'competitive dynamics usually', 'dynamics usually companies', 'usually companies dont', 'companies dont talk', 'dont talk data', 'talk data collection', 'data collection also', 'collection also theres', 'also theres copyright', 'theres copyright liability', 'copyright liability issue', 'liability issue definitely', 'issue definitely dont', 'definitely dont want', 'dont want tell', 'want tell theyve', 'tell theyve trained', 'theyve trained books', 'trained books even', 'books even though', 'even though sue', 'though sue common', 'sue common academic', 'common academic benchmarks', 'academic benchmarks kind', 'benchmarks kind answer', 'kind answer asked', 'answer asked smaller', 'asked smaller ones', 'smaller ones names', 'ones names important', 'names important decide', 'important decide head', 'decide head around', 'head around 150', 'around 150 billion', '150 billion tokens', 'billion tokens around', 'tokens around 800', 'around 800 gigabytes', '800 gigabytes data', 'gigabytes data around', 'data around 15', 'around 15 trillion', '15 trillion tokens', 'trillion tokens also', 'tokens also size', 'also size models', 'size models right', 'models right best', 'right best models', 'best models probably', 'models probably trained', 'probably trained amount', 'trained amount data', 'amount data 15', 'data 15 trillion', '15 trillion tokens', 'trillion tokens probably', 'tokens probably guess', 'probably guess two', 'guess two bigger', 'two bigger 80', 'bigger 80 e3', '80 e3 gigabyte', 'e3 gigabyte would', 'gigabyte would around', 'would around 100', 'around 100 1000', '100 1000 times', '1000 times filtering', 'times filtering common', 'filtering common crawl', 'common crawl im', 'crawl im mistaken', 'im mistaken yeah', 'mistaken yeah one', 'yeah one famous', 'one famous one', 'famous one pile', 'one pile academic', 'pile academic benchmark', 'academic benchmark pile', 'benchmark pile look', 'pile look distribution', 'look distribution data', 'distribution data sings', 'data sings archive', 'sings archive pubmed', 'archive pubmed central', 'pubmed central biology', 'central biology stuff', 'biology stuff wikipedia', 'stuff wikipedia see', 'wikipedia see stack', 'see stack exchange', 'stack exchange github', 'exchange github books', 'github books things', 'books things smaller', 'things smaller side', 'smaller side look', 'side look 280b', 'look 280b reality', '280b reality 100', 'reality 100 times', '100 times bigger', 'times bigger much', 'bigger much github', 'much github wikipedia', 'github wikipedia terms', 'wikipedia terms closed', 'terms closed source', 'closed source models', 'source models give', 'models give idea', 'give idea lamat', 'idea lamat 2', 'lamat 2 trained', '2 trained two', 'trained two trillion', 'two trillion tokens', 'trillion tokens lamat', 'tokens lamat 3', 'lamat 3 15', '3 15 trillion', '15 trillion tokens', 'trillion tokens currently', 'tokens currently best', 'currently best model', 'best model know', 'model know much', 'know much trained', 'much trained thing', 'trained thing best', 'thing best academic', 'best academic biggest', 'academic biggest academic', 'biggest academic benchmark', 'academic benchmark 15', 'benchmark 15 trillion', '15 trillion tokens', 'trillion tokens gpd', 'tokens gpd 4', 'gpd 4 dont', '4 dont really', 'dont really know', 'really know probably', 'know probably order', 'probably order magnitude', 'order magnitude probably', 'magnitude probably around', 'probably around probably', 'around probably around', 'probably around 13', 'around 13 leaks', '13 leaks leaks', 'leaks leaks true', 'leaks true great', 'true great scaling', 'great scaling loss', 'scaling loss questions', 'loss questions data', 'questions data go', 'data go scaling', 'go scaling loss', 'scaling loss sorry', 'loss sorry know', 'sorry know im', 'know im giving', 'im giving lot', 'giving lot information', 'lot information theres', 'information theres lot', 'theres lot training', 'lot training large', 'training large language', 'large language models', 'language models great', 'models great scaling', 'great scaling loss', 'scaling loss idea', 'loss idea people', 'idea people saw', 'people saw around', 'saw around 2020', 'around 2020 least', '2020 least long', 'least long time', 'long time theyve', 'time theyve able', 'theyve able kind', 'able kind theoretically', 'kind theoretically show', 'theoretically show impurity', 'show impurity show', 'impurity show since', 'show since 2020', 'since 2020 data', '2020 data train', 'data train models', 'train models larger', 'models larger models', 'larger models better', 'models better performance', 'better performance pretty', 'performance pretty different', 'pretty different youve', 'different youve seen', 'youve seen class', 'seen class class', 'class class teach', 'class teach overfitting', 'teach overfitting overfitting', 'overfitting overfitting doesnt', 'overfitting doesnt happen', 'doesnt happen large', 'happen large language', 'large language models', 'language models larger', 'models larger models', 'larger models better', 'models better performance', 'better performance something', 'performance something really', 'something really took', 'really took long', 'took long time', 'long time community', 'time community took', 'community took type', 'took type class', 'type class realize', 'class realize exam', 'realize exam overfitting', 'exam overfitting exists', 'overfitting exists idea', 'exists idea scaling', 'idea scaling loss', 'scaling loss given', 'loss given know', 'given know data', 'know data larger', 'data larger models', 'larger models always', 'models always give', 'always give better', 'give better performance', 'better performance predict', 'performance predict much', 'predict much better', 'much better performance', 'better performance increase', 'performance increase amount', 'increase amount data', 'amount data size', 'data size model', 'size model surprisingly', 'model surprisingly works', 'surprisingly works see', 'works see three', 'see three plus', 'three plus famous', 'plus famous paper', 'famous paper called', 'paper called scaling', 'called scaling loss', 'scaling loss openai', 'loss openai see', 'openai see xaxis', 'see xaxis compute', 'xaxis compute much', 'compute much train', 'much train much', 'train much compute', 'much compute spent', 'compute spent training', 'spent training see', 'training see test', 'see test loss', 'test loss essentially', 'loss essentially mean', 'essentially mean perplexity', 'mean perplexity validation', 'perplexity validation loss', 'validation loss log', 'loss log perplexity', 'log perplexity put', 'perplexity put two', 'put two log', 'two log scale', 'log scale see', 'scale see performance', 'see performance sorry', 'performance sorry scaling', 'sorry scaling law', 'scaling law linear', 'law linear means', 'linear means increase', 'means increase compute', 'increase compute certain', 'compute certain amount', 'certain amount say', 'amount say much', 'say much test', 'much test loss', 'test loss decrease', 'loss decrease thing', 'decrease thing data', 'thing data thing', 'data thing parameters', 'thing parameters increase', 'parameters increase data', 'increase data set', 'data set size', 'set size loss', 'size loss decrease', 'loss decrease amount', 'decrease amount somewhat', 'amount somewhat predictable', 'somewhat predictable increase', 'predictable increase number', 'increase number parameters', 'number parameters decrease', 'parameters decrease loss', 'decrease loss decrease', 'loss decrease amount', 'decrease amount somewhat', 'amount somewhat predictable', 'somewhat predictable really', 'predictable really amazing', 'really amazing surprising', 'amazing surprising mean', 'surprising mean looks', 'mean looks innocuous', 'looks innocuous look', 'innocuous look type', 'look type plots', 'type plots thats', 'plots thats crazy', 'thats crazy means', 'crazy means predict', 'means predict well', 'predict well going', 'well going perform', 'going perform two', 'perform two three', 'two three years', 'three years depending', 'years depending much', 'depending much compute', 'much compute add', 'compute add assuming', 'add assuming things', 'assuming things hold', 'things hold theres', 'hold theres nothing', 'theres nothing theoretical', 'nothing theoretical yes', 'theoretical yes loss', 'yes loss user', 'loss user proplexity', 'user proplexity said', 'proplexity said proplexity', 'said proplexity 2', 'proplexity 2 power', '2 power loss', 'power loss power', 'loss power proplexity', 'power proplexity second', 'proplexity second thing', 'second thing dont', 'thing dont increase', 'dont increase number', 'increase number parameters', 'number parameters increase', 'parameters increase total', 'increase total data', 'total data set', 'data set size', 'set size number', 'size number application', 'number application time', 'application time doesnt', 'time doesnt increase', 'doesnt increase compute', 'increase compute work', 'compute work many', 'work many data', 'many data oh', 'data oh yes', 'oh yes great', 'yes great question', 'great question compute', 'question compute factor', 'compute factor two', 'factor two things', 'two things data', 'things data parameter', 'data parameter im', 'parameter im showing', 'im showing well', 'showing well going', 'well going talk', 'going talk details', 'talk details increase', 'details increase number', 'increase number parameters', 'number parameters increase', 'parameters increase number', 'increase number data', 'number data dont', 'data dont go', 'dont go multiple', 'go multiple times', 'multiple times data', 'times data set', 'data set one', 'set one epochs', 'one epochs least', 'epochs least yet', 'least yet havent', 'yet havent still', 'havent still kind', 'still kind enough', 'kind enough data', 'enough data yeah', 'data yeah trend', 'yeah trend increased', 'trend increased compute', 'increased compute decreased', 'compute decreased loss', 'decreased loss yes', 'loss yes seen', 'yes seen numbers', 'seen numbers last', 'numbers last two', 'last two years', 'two years still', 'years still holding', 'still holding still', 'holding still holding', 'still holding dont', 'holding dont good', 'dont good numbers', 'good numbers show', 'numbers show still', 'show still holding', 'still holding surprisingly', 'holding surprisingly yes', 'surprisingly yes draw', 'yes draw evidence', 'draw evidence procoevent', 'evidence procoevent youve', 'procoevent youve never', 'youve never thought', 'never thought cant', 'thought cant draw', 'cant draw expected', 'draw expected value', 'expected value right', 'value right empirical', 'right empirical evidence', 'empirical evidence plateauing', 'evidence plateauing time', 'plateauing time soon', 'time soon dont', 'soon dont know', 'dont know well', 'know well happened', 'well happened probably', 'happened probably mean', 'probably mean doesnt', 'mean doesnt need', 'doesnt need log', 'need log scale', 'log scale go', 'scale go plateau', 'go plateau mathematically', 'plateau mathematically could', 'mathematically could continue', 'could continue decreasing', 'continue decreasing mean', 'decreasing mean people', 'mean people think', 'people think probably', 'think probably plateau', 'probably plateau point', 'plateau point dont', 'point dont know', 'dont know thats', 'know thats talk', 'thats talk scaling', 'talk scaling loss', 'scaling loss scaling', 'loss scaling loss', 'scaling loss really', 'loss really cool', 'really cool imagine', 'cool imagine give', 'imagine give youre', 'give youre fortunate', 'youre fortunate give', 'fortunate give 10000', 'give 10000 gpus', '10000 gpus month', 'gpus month model', 'month model train', 'model train even', 'train even go', 'even go answering', 'go answering question', 'answering question mean', 'question mean hypothetical', 'mean hypothetical thats', 'hypothetical thats exactly', 'thats exactly companies', 'exactly companies faced', 'companies faced old', 'faced old pipeline', 'old pipeline two', 'pipeline two high', 'two high parameters', 'high parameters big', 'parameters big models', 'big models lets', 'models lets say', 'lets say 30', 'say 30 days', '30 days train', 'days train 30', 'train 30 models', '30 models one', 'models one day', 'one day pick', 'day pick best', 'pick best one', 'best one final', 'one final model', 'final model use', 'model use production', 'use production means', 'production means model', 'means model used', 'model used trained', 'used trained one', 'trained one day', 'one day new', 'day new pipeline', 'new pipeline first', 'pipeline first find', 'first find scaling', 'find scaling recipe', 'scaling recipe find', 'recipe find something', 'find something tells', 'something tells example', 'tells example one', 'example one common', 'one common thing', 'common thing increase', 'thing increase size', 'increase size model', 'size model decrease', 'model decrease learning', 'decrease learning rate', 'learning rate find', 'rate find scaling', 'find scaling recipe', 'scaling recipe know', 'recipe know increase', 'know increase size', 'increase size model', 'size model heres', 'model heres high', 'heres high parameters', 'high parameters tune', 'parameters tune high', 'tune high parameters', 'high parameters smaller', 'parameters smaller models', 'smaller models different', 'models different sizes', 'different sizes lets', 'sizes lets say', 'lets say say', 'say say three', 'say three days', 'three days 30', 'days 30 days', '30 days train', 'days train many', 'train many different', 'many different models', 'different models highpreparameter', 'models highpreparameter tuning', 'highpreparameter tuning small', 'tuning small models', 'small models different', 'models different sizes', 'different sizes fit', 'sizes fit scaling', 'fit scaling law', 'scaling law try', 'law try extrapolate', 'try extrapolate smaller', 'extrapolate smaller models', 'smaller models one', 'models one best', 'one best train', 'best train much', 'train much longer', 'much longer oh', 'longer oh sorry', 'oh sorry train', 'sorry train larger', 'train larger model', 'larger model train', 'model train final', 'train final huge', 'final huge model', 'huge model 27', 'model 27 days', '27 days instead', 'days instead one', 'instead one day', 'one day new', 'day new pipeline', 'new pipeline train', 'pipeline train things', 'train things highpreparameter', 'things highpreparameter tuning', 'highpreparameter tuning real', 'tuning real scale', 'real scale model', 'scale model youre', 'model youre going', 'youre going use', 'going use practice', 'use practice things', 'practice things smaller', 'things smaller ones', 'smaller ones different', 'ones different scales', 'different scales try', 'scales try predict', 'try predict well', 'predict well perform', 'well perform make', 'perform make bigger', 'make bigger give', 'bigger give give', 'give give concrete', 'give concrete example', 'concrete example right', 'example right lets', 'right lets say', 'lets say transformers', 'say transformers versus', 'transformers versus lstms', 'versus lstms lets', 'lstms lets say', 'lets say youre', 'say youre yous', 'youre yous 10000', 'yous 10000 gpus', '10000 gpus youre', 'gpus youre sure', 'youre sure one', 'sure one using', 'one using using', 'using using transformable', 'using transformable base', 'transformable base model', 'base model scm', 'model scm base', 'scm base model', 'base model train', 'model train transformers', 'train transformers different', 'transformers different scales', 'different scales see', 'scales see different', 'see different parameters', 'different parameters xaxis', 'parameters xaxis yaxis', 'xaxis yaxis test', 'yaxis test source', 'test source show', 'source show different', 'show different lstms', 'different lstms different', 'lstms different scales', 'different scales points', 'scales points see', 'points see oh', 'see oh kind', 'oh kind fits', 'kind fits scaling', 'fits scaling law', 'scaling law fit', 'law fit scaling', 'fit scaling law', 'scaling law able', 'law able predict', 'able predict oh', 'predict oh 10', 'oh 10 times', '10 times compute', 'times compute heres', 'compute heres well', 'heres well would', 'well would perform', 'would perform lstm', 'perform lstm slightly', 'lstm slightly less', 'slightly less linear', 'less linear lstm', 'linear lstm could', 'lstm could probably', 'could probably try', 'probably try predict', 'try predict would', 'predict would end', 'would end clearly', 'end clearly plot', 'clearly plot would', 'plot would see', 'would see transformers', 'see transformers better', 'transformers better one', 'better one thing', 'one thing notice', 'thing notice read', 'notice read types', 'read types scaling', 'types scaling laws', 'scaling laws two', 'laws two things', 'two things important', 'things important one', 'important one really', 'one really scaling', 'really scaling rate', 'scaling rate kind', 'rate kind slope', 'kind slope scaling', 'slope scaling law', 'scaling law thing', 'law thing intercept', 'thing intercept could', 'intercept could start', 'could start worse', 'start worse become', 'worse become better', 'become better time', 'better time happens', 'time happens lstms', 'happens lstms worse', 'lstms worse could', 'worse could show', 'could show another', 'show another one', 'another one things', 'one things predict', 'things predict certain', 'predict certain scale', 'certain scale youre', 'scale youre better', 'youre better using', 'better using type', 'using type model', 'type model others', 'model others thats', 'others thats scaling', 'thats scaling laws', 'scaling laws really', 'laws really useful', 'really useful questions', 'useful questions yeah', 'questions yeah kind', 'yeah kind sensitive', 'kind sensitive art', 'sensitive art small', 'art small difference', 'small difference architecture', 'difference architecture one', 'architecture one light', 'one light transfer', 'light transfer architecture', 'transfer architecture versus', 'architecture versus another', 'versus another transfer', 'another transfer architecture', 'transfer architecture pick', 'architecture pick curve', 'pick curve say', 'curve say oh', 'say oh scaling', 'oh scaling tell', 'scaling tell logarithmic', 'tell logarithmic function', 'logarithmic function yeah', 'function yeah yeah', 'yeah yeah usually', 'yeah usually example', 'usually example youre', 'example youre academic', 'youre academic want', 'academic want least', 'want least thats', 'least thats pretty', 'thats pretty recent', 'pretty recent want', 'recent want propose', 'want propose new', 'propose new activation', 'new activation thats', 'activation thats exactly', 'thats exactly fit', 'exactly fit scaling', 'fit scaling law', 'scaling law show', 'law show another', 'show another scaling', 'another scaling law', 'scaling law standard', 'law standard dont', 'standard dont know', 'dont know gailu', 'know gailu say', 'gailu say better', 'say better reality', 'better reality start', 'reality start thinking', 'start thinking scaling', 'thinking scaling laws', 'scaling laws terms', 'laws terms really', 'terms really realize', 'really realize architecture', 'realize architecture differences', 'architecture differences make', 'differences make small', 'make small minor', 'small minor ones', 'minor ones maybe', 'ones maybe changed', 'maybe changed little', 'changed little bit', 'little bit intercept', 'bit intercept really', 'intercept really doesnt', 'really doesnt matter', 'doesnt matter train', 'matter train 10', 'train 10 hours', '10 hours longer', 'hours longer wait', 'longer wait next', 'wait next gpus', 'next gpus things', 'gpus things really', 'things really secondary', 'really secondary exactly', 'secondary exactly telling', 'exactly telling originally', 'telling originally people', 'originally people spend', 'people spend much', 'spend much time', 'much time architecture', 'time architecture losses', 'architecture losses reality', 'losses reality things', 'reality things dont', 'things dont matter', 'dont matter much', 'matter much data', 'much data though', 'data though use', 'though use good', 'use good data', 'good data much', 'data much better', 'much better scaling', 'better scaling loss', 'scaling loss use', 'loss use bad', 'use bad data', 'bad data really', 'data really matters', 'really matters another', 'matters another really', 'another really cool', 'really cool thing', 'cool thing scaling', 'thing scaling loss', 'scaling loss ask', 'loss ask optimally', 'ask optimally allocate', 'optimally allocate training', 'allocate training resources', 'training resources train', 'resources train larger', 'train larger models', 'larger models thought', 'models thought better', 'thought better train', 'better train larger', 'train larger models', 'larger models thought', 'models thought also', 'thought also better', 'also better use', 'better use data', 'use data one', 'data one train', 'one train data', 'train data smaller', 'data smaller model', 'smaller model train', 'model train larger', 'train larger model', 'larger model less', 'model less data', 'less data chintilla', 'data chintilla famous', 'chintilla famous paper', 'famous paper first', 'paper first showed', 'first showed way', 'showed way want', 'way want give', 'want give little', 'give little bit', 'little bit sense', 'bit sense plots', 'sense plots see', 'plots see training', 'see training loss', 'training loss xaxis', 'loss xaxis see', 'xaxis see parameter', 'see parameter differences', 'parameter differences sorry', 'differences sorry number', 'sorry number parameters', 'number parameters size', 'parameters size model', 'size model curves', 'model curves call', 'curves call isoflops', 'call isoflops models', 'isoflops models curve', 'models curve trained', 'curve trained amount', 'trained amount compute', 'amount compute way', 'compute way change', 'way change vary', 'change vary number', 'vary number tokens', 'number tokens trained', 'tokens trained size', 'trained size models', 'size models vary', 'models vary way', 'vary way total', 'way total compute', 'total compute constant', 'compute constant curves', 'constant curves see', 'curves see different', 'see different colors', 'different colors different', 'colors different amount', 'different amount compute', 'amount compute trained', 'compute trained take', 'trained take best', 'take best one', 'best one curves', 'one curves best', 'curves best one', 'best one curves', 'one curves plot', 'curves plot much', 'plot much flops', 'much flops curve', 'flops curve much', 'curve much parameters', 'much parameters use', 'parameters use training', 'use training specific', 'training specific point', 'specific point put', 'point put log', 'put log log', 'log log scale', 'log scale fit', 'scale fit scaling', 'fit scaling log', 'scaling log something', 'log something tells', 'something tells want', 'tells want train', 'want train model', 'train model 10', 'model 10 power', '10 power 23', 'power 23 flops', '23 flops heres', 'flops heres exactly', 'heres exactly number', 'exactly number parameters', 'number parameters using', 'parameters using 100', 'using 100 b', '100 b thing', 'b thing flops', 'thing flops tokens', 'flops tokens predict', 'tokens predict tell', 'predict tell exactly', 'tell exactly one', 'exactly one month', 'one month compute', 'month compute size', 'compute size model', 'size model training', 'model training figure', 'training figure scaling', 'figure scaling law', 'scaling law tell', 'law tell course', 'tell course looks', 'course looks beautiful', 'looks beautiful reality', 'beautiful reality theres', 'reality theres lot', 'theres lot small', 'lot small things', 'small things counting', 'things counting embedding', 'counting embedding parameters', 'embedding parameters theres', 'parameters theres lot', 'theres lot complexities', 'lot complexities things', 'complexities things well', 'things well things', 'well things hold', 'things hold optimal', 'hold optimal number', 'optimal number parameters', 'number parameters shinchilla', 'parameters shinchilla people', 'shinchilla people found', 'people found use', 'found use 20', 'use 20 tokens', '20 tokens every', 'tokens every parameter', 'every parameter train', 'parameter train add', 'train add one', 'add one parameter', 'one parameter train', 'parameter train thing', 'train thing model', 'thing model 20', 'model 20 tokens', '20 tokens one', 'tokens one caveat', 'one caveat optimal', 'caveat optimal training', 'optimal training resources', 'training resources telling', 'resources telling 10', 'telling 10 power', '10 power 23', 'power 23 flops', '23 flops 100', 'flops 100 dont', '100 dont know', 'dont know much', 'know much 100', 'much 100 million', '100 million 5', 'million 5 million', '5 million 10', 'million 10 would', '10 would smudge', 'would smudge less', 'smudge less id', 'less id say', 'id say 5', 'say 5 million', '5 million train', 'million train best', 'train best model', 'best model gets', 'model gets lowest', 'gets lowest loss', 'lowest loss would', 'loss would train', 'would train reality', 'train reality companies', 'reality companies need', 'companies need think', 'need think inference', 'think inference also', 'inference also smaller', 'also smaller model', 'smaller model spend', 'model spend less', 'spend less time', 'less time consider', 'time consider inference', 'consider inference cost', 'inference cost papers', 'cost papers try', 'papers try show', 'try show around', 'show around 150', 'around 150 parameters', '150 parameters sorry', 'parameters sorry tokens', 'sorry tokens per', 'tokens per parameters', 'per parameters prefer', 'parameters prefer smaller', 'prefer smaller model', 'smaller model time', 'model time youre', 'time youre going', 'youre going spend', 'going spend less', 'spend less money', 'less money inference', 'money inference models', 'inference models 150', 'models 150 one', '150 one thats', 'one thats around', 'thats around best', 'around best models', 'best models trained', 'models trained right', 'trained right least', 'right least ones', 'least ones used', 'ones used practice', 'used practice production', 'practice production great', 'production great question', 'great question chichol', 'question chichol great', 'chichol great im', 'great im sorry', 'im sorry expensive', 'sorry expensive really', 'expensive really small', 'really small really', 'small really good', 'really good train', 'good train expensive', 'train expensive talk', 'expensive talk first', 'talk first would', 'first would another', 'would another entire', 'another entire lecture', 'entire lecture think', 'lecture think chat', 'think chat gpt', 'chat gpt dont', 'gpt dont know', 'dont know much', 'know much 600', 'much 600 million', '600 million people', 'million people use', 'people use thats', 'use thats lot', 'thats lot expensive', 'lot expensive theres', 'expensive theres lot', 'theres lot optimization', 'lot optimization inference', 'optimization inference though', 'inference though thats', 'though thats entire', 'thats entire lecture', 'entire lecture im', 'lecture im going', 'im going skip', 'going skip time', 'skip time interesting', 'time interesting ok', 'interesting ok two', 'ok two things', 'two things said', 'things said many', 'said many things', 'many things answer', 'things answer scaling', 'answer scaling loss', 'scaling loss try', 'loss try give', 'try give two', 'give two examples', 'two examples really', 'examples really many', 'really many things', 'many things data', 'things data use', 'data use mixer', 'use mixer data', 'mixer data mixing', 'data mixing waiting', 'mixing waiting use', 'waiting use data', 'use data mixers', 'data mixers thats', 'mixers thats talked', 'thats talked architecture', 'talked architecture use', 'architecture use whether', 'use whether make', 'whether make models', 'make models wider', 'models wider deeper', 'wider deeper paying', 'deeper paying gpus', 'paying gpus collecting', 'gpus collecting data', 'collecting data things', 'data things things', 'things things try', 'things try answer', 'try answer scaling', 'answer scaling loss', 'scaling loss one', 'loss one thing', 'one thing want', 'thing want say', 'want say bitter', 'say bitter lesson', 'bitter lesson ever', 'lesson ever heard', 'ever heard richard', 'heard richard sutton', 'richard sutton famous', 'sutton famous blog', 'famous blog post', 'blog post 2019', 'post 2019 realized', '2019 realized think', 'realized think enough', 'think enough people', 'enough people realized', 'people realized didnt', 'realized didnt definitely', 'didnt definitely realize', 'definitely realize time', 'realize time see', 'time see type', 'see type scaling', 'type scaling loss', 'scaling loss know', 'loss know compute', 'know compute better', 'compute better models', 'better models get', 'models get scale', 'get scale get', 'scale get better', 'get better model', 'better model also', 'model also know', 'also know mozilla', 'know mozilla type', 'mozilla type variants', 'type variants mozilla', 'variants mozilla always', 'mozilla always better', 'always better compute', 'better compute thing', 'compute thing matters', 'thing matters architectures', 'matters architectures leverage', 'architectures leverage computation', 'leverage computation matters', 'computation matters systems', 'matters systems data', 'systems data less', 'data less architecture', 'less architecture small', 'architecture small architecture', 'small architecture differences', 'architecture differences activation', 'differences activation things', 'activation things think', 'things think thats', 'think thats one', 'thats one reasons', 'one reasons research', 'reasons research focuses', 'research focuses things', 'focuses things industry', 'things industry matters', 'industry matters less', 'matters less one', 'less one researchers', 'one researchers large', 'researchers large part', 'large part career', 'part career dont', 'career dont spend', 'dont spend time', 'spend time overcomplicating', 'time overcomplicating simple', 'overcomplicating simple things', 'simple things well', 'things well seal', 'well seal thats', 'seal thats really', 'thats really openai', 'really openai taught', 'openai taught us', 'taught us chatgpt', 'us chatgpt gps', 'chatgpt gps ok', 'gps ok want', 'ok want give', 'want give backoftheenvelope', 'give backoftheenvelope computations', 'backoftheenvelope computations might', 'computations might factors', 'might factors want', 'factors want give', 'want give sense', 'give sense costly', 'sense costly train', 'costly train models', 'train models ill', 'models ill give', 'ill give example', 'give example lamat', 'example lamat 300b', 'lamat 300b currently', '300b currently best', 'currently best open', 'best open source', 'open source model', 'source model get', 'model get trained', 'get trained 156', 'trained 156 tokens', '156 tokens 405', 'tokens 405 billion', '405 billion parameters', 'billion parameters know', 'parameters know optimal', 'know optimal tokens', 'optimal tokens parameter', 'tokens parameter thats', 'parameter thats around', 'thats around 40', 'around 40 thats', '40 thats little', 'thats little bit', 'little bit chinchilla', 'bit chinchilla less', 'chinchilla less inference', 'less inference optimal', 'inference optimal model', 'optimal model went', 'model went training', 'went training optimality', 'training optimality flops', 'optimality flops model', 'flops model one', 'model one simple', 'one simple way', 'simple way compute', 'way compute flops', 'compute flops six', 'flops six times', 'six times number', 'times number parameters', 'number parameters times', 'parameters times number', 'times number data', 'number data train', 'data train simple', 'train simple calculation', 'simple calculation 38e25', 'calculation 38e25 flops', '38e25 flops reason', 'flops reason important', 'reason important follow', 'important follow little', 'follow little bit', 'little bit news', 'bit news theres', 'news theres executive', 'theres executive order', 'executive order biden', 'order biden says', 'biden says want', 'says want 1e26', 'want 1e26 parameters', '1e26 parameters sorry', 'parameters sorry flops', 'sorry flops special', 'flops special scrutiny', 'special scrutiny models', 'scrutiny models went', 'models went 2x', 'went 2x less', '2x less really', 'less really went', 'really went right', 'went right special', 'right special scrutiny', 'special scrutiny 3', 'scrutiny 3 8', '3 8 might', '8 might little', 'might little bit', 'little bit definitely', 'bit definitely 1e26', 'definitely 1e26 p', '1e26 p parameters', 'p parameters n', 'parameters n data', 'n data number', 'data number tokens', 'number tokens approximation', 'tokens approximation yeah', 'approximation yeah compute', 'yeah compute know', 'compute know train', 'know train 16000', 'train 16000 h100s', '16000 h100s know', 'h100s know throughput', 'know throughput set', 'throughput set computation', 'set computation takes', 'computation takes around', 'takes around 70', 'around 70 days', '70 days 26', 'days 26 million', '26 million gpu', 'million gpu hours', 'gpu hours least', 'hours least thats', 'least thats backoftheenvelope', 'thats backoftheenvelope computation', 'backoftheenvelope computation said', 'computation said used', 'said used 30', 'used 30 million', '30 million instead', 'million instead 26', 'instead 26 million', '26 million gpu', 'million gpu hours', 'gpu hours maybe', 'hours maybe challenges', 'maybe challenges dont', 'challenges dont really', 'dont really know', 'really know follow', 'know follow simple', 'follow simple computation', 'simple computation around', 'computation around 70', 'around 70 days', '70 days cost', 'days cost mean', 'cost mean hard', 'mean hard approximate', 'hard approximate im', 'approximate im going', 'im going say', 'going say kind', 'say kind rent', 'kind rent rent', 'rent rent h100s', 'rent h100s many', 'h100s many h100s', 'many h100s many', 'h100s many days', 'many days much', 'days much pay', 'much pay h100', 'pay h100 lower', 'h100 lower bound', 'lower bound renting', 'bound renting cost', 'renting cost h100', 'cost h100 around', 'h100 around two', 'around two hours', 'two hours 2', 'hours 2 per', '2 per hour', 'per hour multiply', 'hour multiply 26', 'multiply 26 million', '26 million hours', 'million hours get', 'hours get 52', 'get 52 million', '52 million probably', 'million probably pay', 'probably pay less', 'pay less much', 'less much less', 'much less services', 'less services rent', 'services rent gpus', 'rent gpus dont', 'gpus dont make', 'dont make much', 'make much money', 'much money probably', 'money probably slightly', 'probably slightly less', 'slightly less much', 'less much less', 'much less salary', 'less salary said', 'salary said 50', 'said 50 employees', '50 employees 500k', 'employees 500k per', '500k per year', 'per year yeah', 'year yeah probably', 'yeah probably right', 'probably right bullpock', 'right bullpock 25', 'bullpock 25 million', '25 million put', 'million put together', 'put together around', 'together around 75', 'around 75 million', '75 million dollars', 'million dollars training', 'dollars training slammer', 'training slammer model', 'slammer model im', 'model im probably', 'im probably 10', 'probably 10 million', '10 million thats', 'million thats kind', 'thats kind right', 'kind right bullpock', 'right bullpock carbon', 'bullpock carbon emitted', 'carbon emitted lot', 'emitted lot people', 'lot people might', 'people might ask', 'might ask also', 'ask also cost', 'also cost thing', 'cost thing important', 'thing important computation', 'important computation around', 'computation around 4000', 'around 4000 tons', '4000 tons co2', 'tons co2 equivalent', 'co2 equivalent 2000', 'equivalent 2000 return', '2000 return tickets', 'return tickets jfk', 'tickets jfk london', 'jfk london right', 'london right carbon', 'right carbon emitted', 'carbon emitted mean', 'emitted mean huge', 'mean huge meaningful', 'huge meaningful yet', 'meaningful yet think', 'yet think maybe', 'think maybe gpt', 'maybe gpt 6', 'gpt 6 gpt', '6 gpt multiply', 'gpt multiply 100', 'multiply 100 might', '100 might become', 'might become real', 'become real issue', 'real issue right', 'issue right still', 'right still think', 'still think issue', 'think issue grand', 'issue grand scheme', 'grand scheme things', 'scheme things next', 'things next model', 'next model way', 'model way thinking', 'way thinking models', 'thinking models every', 'models every new', 'every new generation', 'new generation number', 'generation number flops', 'number flops essentially', 'flops essentially multiplies', 'essentially multiplies 10x', 'multiplies 10x well', '10x well least', 'well least thats', 'least thats try', 'thats try enough', 'try enough energy', 'enough energy buy', 'energy buy enough', 'buy enough gpus', 'enough gpus great', 'gpus great question', 'great question backup', 'question backup dna', 'backup dna envelope', 'dna envelope math', 'envelope math talked', 'math talked pretraining', 'talked pretraining wanted', 'pretraining wanted also', 'wanted also chat', 'also chat systems', 'chat systems know', 'systems know compute', 'know compute really', 'compute really important', 'really important theres', 'important theres question', 'theres question optimize', 'question optimize compute', 'optimize compute leave', 'compute leave end', 'leave end im', 'end im sure', 'im sure much', 'sure much time', 'much time think', 'time think important', 'think important hopefully', 'important hopefully ill', 'hopefully ill able', 'ill able talk', 'able talk later', 'talk later slightly', 'later slightly different', 'slightly different weve', 'different weve talking', 'weve talking right', 'talking right ill', 'right ill move', 'ill move posttraining', 'move posttraining task', 'posttraining task posttraining', 'task posttraining reason', 'posttraining reason need', 'reason need posttraining', 'need posttraining told', 'posttraining told make', 'told make ai', 'make ai assistance', 'ai assistance language', 'assistance language modeling', 'language modeling really', 'modeling really thing', 'really thing want', 'thing want ai', 'want ai assistant', 'ai assistant example', 'assistant example ask', 'example ask gpt3', 'ask gpt3 purely', 'gpt3 purely language', 'purely language model', 'language model pure', 'model pure language', 'pure language model', 'language model aligned', 'model aligned one', 'aligned one ask', 'one ask question', 'ask question explain', 'question explain moon', 'explain moon landing', 'moon landing sixyearold', 'landing sixyearold conclusion', 'sixyearold conclusion would', 'conclusion would get', 'would get something', 'get something explain', 'something explain theory', 'explain theory gravity', 'theory gravity sixyearold', 'gravity sixyearold learned', 'sixyearold learned internet', 'learned internet one', 'internet one question', 'one question usually', 'question usually maybe', 'usually maybe another', 'maybe another bullet', 'another bullet point', 'bullet point similar', 'point similar questions', 'similar questions dont', 'questions dont usually', 'dont usually question', 'usually question answer', 'question answer later', 'answer later want', 'later want ai', 'want ai assistant', 'ai assistant alignment', 'assistant alignment posttraining', 'alignment posttraining making', 'posttraining making models', 'making models assistance', 'models assistance goal', 'assistance goal alignment', 'goal alignment get', 'alignment get lms', 'get lms follow', 'lms follow instructions', 'follow instructions given', 'instructions given users', 'given users sign', 'users sign maybe', 'sign maybe designers', 'maybe designers kind', 'designers kind desires', 'kind desires think', 'desires think moderation', 'think moderation dont', 'moderation dont want', 'dont want model', 'want model openair', 'model openair definitely', 'openair definitely doesnt', 'definitely doesnt want', 'doesnt want model', 'want model say', 'model say stuff', 'say stuff toxic', 'stuff toxic see', 'toxic see left', 'see left hand', 'left hand side', 'hand side ask', 'side ask question', 'ask question provides', 'question provides real', 'provides real answer', 'real answer llm', 'answer llm right', 'llm right hand', 'right hand side', 'hand side see', 'side see would', 'see would ask', 'would ask write', 'ask write tweet', 'write tweet describing', 'tweet describing certain', 'describing certain part', 'certain part population', 'part population evil', 'population evil say', 'evil say thats', 'say thats kind', 'thats kind alignment', 'kind alignment background', 'alignment background data', 'background data want', 'data want training', 'want training models', 'training models know', 'models know want', 'know want asking', 'want asking humans', 'asking humans question', 'humans question answer', 'question answer want', 'answer want thing', 'want thing expensive', 'thing expensive collect', 'expensive collect data', 'collect data hard', 'data hard find', 'hard find online', 'find online contrast', 'online contrast pretraining', 'contrast pretraining data', 'pretraining data want', 'data want theres', 'want theres lot', 'theres lot main', 'lot main idea', 'main idea simply', 'idea simply take', 'simply take pretrained', 'take pretrained large', 'pretrained large language', 'large language model', 'language model pretrained', 'model pretrained internet', 'pretrained internet fine', 'internet fine tune', 'fine tune change', 'tune change little', 'change little bit', 'little bit weights', 'bit weights type', 'weights type data', 'type data want', 'data want hopefully', 'want hopefully given', 'hopefully given youre', 'given youre already', 'youre already pretrained', 'already pretrained internet', 'pretrained internet learns', 'internet learns knows', 'learns knows speak', 'knows speak english', 'speak english knows', 'english knows standard', 'knows standard language', 'standard language syntax', 'language syntax really', 'syntax really fine', 'really fine tune', 'fine tune little', 'tune little data', 'little data ok', 'data ok sft', 'ok sft supervised', 'sft supervised fine', 'supervised fine tuning', 'fine tuning really', 'tuning really exactly', 'really exactly said', 'exactly said idea', 'said idea fine', 'idea fine tuning', 'fine tuning large', 'tuning large language', 'large language model', 'language model desired', 'model desired answers', 'desired answers collected', 'answers collected humans', 'collected humans called', 'humans called supervised', 'called supervised fine', 'supervised fine tuning', 'fine tuning want', 'tuning want language', 'want language modeling', 'language modeling real', 'modeling real answers', 'real answers language', 'answers language modeling', 'language modeling next', 'modeling next word', 'next word prediction', 'word prediction thats', 'prediction thats fine', 'thats fine tuning', 'fine tuning part', 'tuning part want', 'part want desired', 'want desired answers', 'desired answers given', 'answers given humans', 'given humans thats', 'humans thats call', 'thats call supervised', 'call supervised collect', 'supervised collect data', 'collect data well', 'data well said', 'well said ask', 'said ask humans', 'ask humans tell', 'humans tell question', 'tell question answer', 'question answer would', 'answer would want', 'would want something', 'want something models', 'something models example', 'models example cant', 'example cant read', 'cant read well', 'read well computer', 'well computer kid', 'computer kid needs', 'kid needs science', 'needs science lets', 'science lets read', 'lets read one', 'read one write', 'one write short', 'write short introduction', 'short introduction relevance', 'introduction relevance term', 'relevance term monopsony', 'term monopsony says', 'monopsony says monopsony', 'says monopsony refers', 'monopsony refers market', 'refers market structure', 'market structure blah', 'structure blah blah', 'blah blah blah', 'blah blah thats', 'blah thats human', 'thats human number', 'human number open', 'number open assistant', 'open assistant way', 'assistant way collect', 'way collect data', 'collect data online', 'data online humans', 'online humans type', 'humans type supervised', 'type supervised fine', 'supervised fine tuning', 'fine tuning im', 'tuning im really', 'im really key', 'really key chat', 'key chat gpt', 'chat gpt made', 'gpt made big', 'made big jump', 'big jump gpt3', 'jump gpt3 mostly', 'gpt3 mostly something', 'mostly something known', 'something known ai', 'known ai researchers', 'ai researchers chat', 'researchers chat gpt', 'chat gpt became', 'gpt became known', 'became known everyone', 'known everyone problem', 'everyone problem human', 'problem human data', 'human data slow', 'data slow collect', 'slow collect expensive', 'collect expensive one', 'expensive one percent', 'one percent possible', 'percent possible simple', 'possible simple idea', 'simple idea use', 'idea use lms', 'use lms scale', 'lms scale data', 'scale data collection', 'data collection thats', 'collection thats exactly', 'thats exactly alpaca', 'exactly alpaca one', 'alpaca one year', 'one year ago', 'year ago asked', 'ago asked humans', 'asked humans use', 'humans use data', 'use data set', 'data set human', 'set human question', 'human question answers', 'question answers 175', 'answers 175 question', '175 question answers', 'question answers asked', 'answers asked best', 'asked best time', 'best time texas', 'time texas vincis', 'texas vincis user', 'vincis user three', 'user three generate', 'three generate many', 'generate many question', 'many question answers', 'question answers humans', 'answers humans would', 'humans would write', 'would write write', 'write write similar', 'write similar answers', 'similar answers similar', 'answers similar questions', 'similar questions collected', 'questions collected 52000', 'collected 52000 llm', '52000 llm generated', 'llm generated question', 'generated question answers', 'question answers simply', 'answers simply took', 'simply took lamas', 'took lamas 7b', 'lamas 7b best', '7b best pretrained', 'best pretrained model', 'pretrained model time', 'model time fine', 'time fine tuned', 'fine tuned supervised', 'tuned supervised fine', 'supervised fine tuning', 'fine tuning told', 'tuning told thats', 'told thats got', 'thats got alpaca', 'got alpaca 7b', 'alpaca 7b model', '7b model type', 'model type data', 'type data collected', 'data collected things', 'collected things algorithm', 'things algorithm mean', 'algorithm mean algorithm', 'mean algorithm step', 'algorithm step step', 'step step set', 'step set instruction', 'set instruction used', 'instruction used solve', 'used solve problem', 'solve problem achieve', 'problem achieve goal', 'achieve goal blah', 'goal blah blah', 'blah blah blah', 'blah blah data', 'blah data pretty', 'data pretty good', 'pretty good given', 'good given lm', 'given lm gen', 'lm gen generated', 'gen generated llms', 'generated llms essentially', 'llms essentially two', 'essentially two generations', 'two generations ago', 'generations ago really', 'ago really started', 'really started least', 'started least us', 'least us kind', 'us kind academic', 'kind academic replication', 'academic replication chatgpt', 'replication chatgpt really', 'chatgpt really big', 'really big field', 'big field synthetic', 'field synthetic data', 'synthetic data generation', 'data generation use', 'generation use llms', 'use llms make', 'llms make development', 'make development llms', 'development llms faster', 'llms faster decreasing', 'faster decreasing amount', 'decreasing amount human', 'amount human hours', 'human hours need', 'hours need quantity', 'need quantity data', 'quantity data talked', 'data talked type', 'talked type data', 'type data collected', 'data collected one', 'collected one thing', 'one thing surprising', 'thing surprising sft', 'surprising sft dont', 'sft dont need', 'dont need much', 'need much data', 'much data paper', 'data paper showed', 'paper showed called', 'showed called lima', 'called lima scale', 'lima scale amount', 'scale amount data', 'amount data use', 'data use supervised', 'use supervised fine', 'supervised fine training', 'fine training 2000', 'training 2000 32000', '2000 32000 really', '32000 really doesnt', 'really doesnt help', 'doesnt help much', 'help much scaling', 'much scaling loss', 'scaling loss definitely', 'loss definitely dont', 'definitely dont help', 'dont help intuition', 'help intuition learn', 'intuition learn learn', 'learn learn format', 'learn format desired', 'format desired answers', 'desired answers another', 'answers another way', 'another way seeing', 'way seeing pretrained', 'seeing pretrained models', 'pretrained models essentially', 'models essentially model', 'essentially model distribution', 'model distribution every', 'distribution every user', 'every user internet', 'user internet one', 'internet one might', 'one might write', 'might write bullet', 'write bullet points', 'bullet points another', 'points another one', 'another one might', 'one might answer', 'might answer question', 'answer question answer', 'question answer tell', 'answer tell model', 'tell model wait', 'model wait optimizing', 'wait optimizing type', 'optimizing type user', 'type user another', 'user another one', 'another one youre', 'one youre teaching', 'youre teaching anything', 'teaching anything sft', 'anything sft supervised', 'sft supervised fine', 'supervised fine tuning', 'fine tuning tell', 'tuning tell model', 'tell model kind', 'model kind optimize', 'kind optimize one', 'optimize one type', 'one type user', 'type user already', 'user already pretrained', 'already pretrained dataset', 'pretrained dataset knowledge', 'dataset knowledge already', 'knowledge already pretrained', 'already pretrained llm', 'pretrained llm specialize', 'llm specialize one', 'specialize one type', 'one type user', 'type user great', 'user great question', 'great question sft', 'question sft yes', 'sft yes know', 'yes know big', 'know big issue', 'big issue synthetic', 'issue synthetic data', 'synthetic data keep', 'data keep generating', 'keep generating data', 'generating data distribution', 'data distribution eventually', 'distribution eventually youre', 'eventually youre learning', 'youre learning new', 'learning new distribution', 'new distribution youre', 'distribution youre essentially', 'youre essentially playing', 'essentially playing puts', 'playing puts track', 'puts track surely', 'track surely cant', 'surely cant scale', 'cant scale way', 'scale way keep', 'way keep going', 'keep going generating', 'going generating data', 'generating data hope', 'data hope learn', 'hope learn something', 'learn something new', 'something new active', 'new active area', 'active area research', 'area research youve', 'research youve thought', 'youve thought around', 'thought around people', 'around people maybe', 'people maybe thinking', 'maybe thinking around', 'thinking around better', 'around better ways', 'better ways bootstrap', 'ways bootstrap give', 'bootstrap give idea', 'give idea realize', 'idea realize chart', 'realize chart shows', 'chart shows dont', 'shows dont need', 'dont need many', 'need many get', 'many get humans', 'get humans generate', 'humans generate 2000', 'generate 2000 radiability', '2000 radiability yeah', 'radiability yeah thats', 'yeah thats good', 'thats good question', 'good question data', 'question data stuff', 'data stuff im', 'stuff im saying', 'im saying important', 'saying important sett', 'important sett another', 'sett another thing', 'another thing well', 'thing well talk', 'well talk right', 'talk right data', 'right data matter', 'data matter intuition', 'matter intuition based', 'intuition based much', 'based much empirical', 'much empirical results', 'empirical results still', 'results still get', 'still get even', 'get even though', 'even though use', 'though use lms', 'use lms use', 'lms use purely', 'use purely lm', 'purely lm generated', 'lm generated text', 'generated text three', 'text three four', 'three four generations', 'four generations lms', 'generations lms agree', 'lms agree probably', 'agree probably wont', 'probably wont improve', 'wont improve much', 'improve much important', 'much important use', 'important use human', 'use human loop', 'human loop lms', 'loop lms purely', 'lms purely lms', 'purely lms purely', 'lms purely humans', 'purely humans maybe', 'humans maybe model', 'maybe model generate', 'model generate new', 'generate new text', 'new text humans', 'text humans write', 'humans write edits', 'write edits much', 'edits much f', 'much f faster', 'f faster writing', 'faster writing entire', 'writing entire text', 'entire text think', 'text think type', 'think type collaboration', 'type collaboration information', 'collaboration information theoretical', 'information theoretical point', 'theoretical point view', 'point view still', 'view still get', 'still get additional', 'get additional information', 'additional information youre', 'information youre much', 'youre much faster', 'much faster use', 'faster use humans', 'use humans think', 'humans think field', 'think field well', 'field well probably', 'well probably move', 'probably move towards', 'move towards type', 'towards type things', 'type things really', 'things really finding', 'really finding examples', 'finding examples important', 'examples important asking', 'important asking humans', 'asking humans kind', 'humans kind active', 'kind active learning', 'active learning asking', 'learning asking humans', 'asking humans exactly', 'humans exactly need', 'exactly need get', 'need get inputs', 'get inputs yes', 'inputs yes youre', 'yes youre trying', 'youre trying make', 'trying make loss', 'make loss function', 'loss function general', 'function general training', 'general training supervised', 'training supervised learning', 'supervised learning pretraining', 'learning pretraining right', 'pretraining right examples', 'right examples showed', 'examples showed think', 'showed think important', 'think important thing', 'important thing good', 'thing good examples', 'good examples theyre', 'examples theyre super', 'theyre super actionoriented', 'super actionoriented theres', 'actionoriented theres complex', 'theres complex things', 'complex things still', 'things still changing', 'still changing loss', 'changing loss thats', 'loss thats didnt', 'thats didnt maybe', 'didnt maybe didnt', 'maybe didnt emphasize', 'didnt emphasize enough', 'emphasize enough language', 'enough language modeling', 'language modeling finetune', 'modeling finetune language', 'finetune language model', 'language model desired', 'model desired answers', 'desired answers literally', 'answers literally loss', 'literally loss different', 'loss different two', 'different two seconds', 'two seconds first', 'seconds first step', 'first step sft', 'step sft literally', 'sft literally loss', 'literally loss say', 'loss say want', 'say want specialize', 'want specialize type', 'specialize type data', 'type data theres', 'data theres even', 'theres even question', 'even question pretraining', 'question pretraining posttraining', 'pretraining posttraining reality', 'posttraining reality different', 'reality different data', 'different data use', 'data use reason', 'use reason usually', 'reason usually call', 'usually call posttraining', 'call posttraining way', 'posttraining way collect', 'way collect data', 'collect data different', 'data different great', 'different great great', 'great great questions', 'great questions yes', 'questions yes maybe', 'yes maybe question', 'maybe question would', 'question would 2000', 'would 2000 examples', '2000 examples overweighted', 'examples overweighted influence', 'overweighted influence internet', 'influence internet thats', 'internet thats also', 'thats also thats', 'also thats another', 'thats another reason', 'another reason call', 'reason call posttraining', 'call posttraining use', 'posttraining use different', 'use different type', 'different type hyper', 'type hyper parameters', 'hyper parameters know', 'parameters know told', 'know told end', 'told end pretraining', 'end pretraining essentially', 'pretraining essentially end', 'essentially end learning', 'end learning rate', 'learning rate zero', 'rate zero youre', 'zero youre going', 'youre going increase', 'going increase learning', 'increase learning rate', 'learning rate 1', 'rate 1 e', '1 e minus', 'e minus 5', 'minus 5 1', '5 1 e', '1 e minus', 'e minus yeah', 'minus yeah way', 'yeah way give', 'way give different', 'give different ok', 'different ok second', 'ok second step', 'second step second', 'step second part', 'second part posttraining', 'part posttraining call', 'posttraining call reinforcement', 'call reinforcement learning', 'reinforcement learning human', 'learning human feedback', 'human feedback hf', 'feedback hf might', 'hf might heard', 'might heard idea', 'heard idea sft', 'idea sft problem', 'sft problem namely', 'problem namely behavioral', 'namely behavioral cloning', 'behavioral cloning means', 'cloning means try', 'means try clone', 'try clone humans', 'clone humans would', 'humans would say', 'would say many', 'say many issues', 'many issues one', 'issues one youre', 'one youre bound', 'youre bound human', 'bound human abilities', 'human abilities humans', 'abilities humans humans', 'humans humans wont', 'humans wont generate', 'wont generate things', 'generate things think', 'things think best', 'think best thing', 'best thing generate', 'thing generate ask', 'generate ask write', 'ask write book', 'write book mean', 'book mean definitely', 'mean definitely enjoy', 'definitely enjoy book', 'enjoy book probably', 'book probably say', 'probably say one', 'say one book', 'one book better', 'book better another', 'better another im', 'another im definitely', 'im definitely going', 'definitely going good', 'going good writing', 'good writing book', 'writing book want', 'book want read', 'want read youre', 'read youre going', 'youre going bound', 'going bound human', 'bound human ability', 'human ability generate', 'ability generate things', 'generate things even', 'things even though', 'even though humans', 'though humans might', 'humans might better', 'might better distinguishing', 'better distinguishing things', 'distinguishing things thats', 'things thats one', 'thats one issue', 'one issue issue', 'issue issue number', 'issue number two', 'number two find', 'two find pretty', 'find pretty interesting', 'pretty interesting ever', 'interesting ever heard', 'ever heard word', 'heard word house', 'word house cination', 'house cination llms', 'cination llms generating', 'llms generating false', 'generating false information', 'false information house', 'information house cination', 'house cination might', 'cination might people', 'might people hypothesized', 'people hypothesized come', 'hypothesized come supervised', 'come supervised fine', 'supervised fine tuning', 'fine tuning even', 'tuning even supervised', 'even supervised fine', 'supervised fine tuning', 'fine tuning data', 'tuning data correct', 'data correct reason', 'correct reason given', 'reason given told', 'given told sft', 'told sft little', 'sft little data', 'little data data', 'data data doesnt', 'data doesnt model', 'doesnt model doesnt', 'model doesnt learn', 'doesnt learn anything', 'learn anything new', 'anything new human', 'new human gives', 'human gives answer', 'gives answer model', 'answer model didnt', 'model didnt know', 'didnt know true', 'know true model', 'true model perspective', 'model perspective human', 'perspective human telling', 'human telling model', 'telling model generate', 'model generate thing', 'generate thing seems', 'thing seems plausible', 'seems plausible idea', 'plausible idea true', 'idea true give', 'true give concrete', 'give concrete example', 'concrete example go', 'example go back', 'go back monopsony', 'back monopsony example', 'monopsony example write', 'example write blah', 'write blah blah', 'blah blah blah', 'blah blah monopsony', 'blah monopsony imagine', 'monopsony imagine human', 'imagine human rotor', 'human rotor reference', 'rotor reference type', 'reference type book', 'type book book', 'book book might', 'book might exist', 'might exist might', 'exist might correct', 'might correct reference', 'correct reference llm', 'reference llm never', 'llm never saw', 'never saw reference', 'saw reference pretraining', 'reference pretraining doesnt', 'pretraining doesnt know', 'doesnt know correct', 'know correct reference', 'correct reference really', 'reference really tell', 'really tell model', 'tell model generate', 'model generate make', 'generate make plausibly', 'make plausibly sounding', 'plausibly sounding reference', 'sounding reference rather', 'reference rather tell', 'rather tell real', 'tell real reference', 'real reference arguing', 'reference arguing pretraining', 'arguing pretraining hallucination', 'pretraining hallucination might', 'hallucination might might', 'might might caused', 'might caused sft', 'caused sft thats', 'sft thats problem', 'thats problem number', 'problem number two', 'number two make', 'two make sense', 'make sense great', 'sense great problem', 'great problem number', 'problem number three', 'number three price', 'three price generating', 'price generating ideal', 'generating ideal answers', 'ideal answers pricing', 'answers pricing comes', 'pricing comes back', 'comes back question', 'back question humans', 'question humans writing', 'humans writing entire', 'writing entire answer', 'entire answer pretty', 'answer pretty expensive', 'pretty expensive thats', 'expensive thats hf', 'thats hf comes', 'hf comes idea', 'comes idea instead', 'idea instead cloning', 'instead cloning behaviors', 'cloning behaviors humans', 'behaviors humans going', 'humans going maximize', 'going maximize human', 'maximize human preference', 'human preference way', 'preference way going', 'way going pipeline', 'going pipeline certain', 'pipeline certain every', 'certain every instruction', 'every instruction youre', 'instruction youre going', 'youre going ask', 'going ask model', 'ask model generate', 'model generate two', 'generate two answers', 'two answers usually', 'answers usually use', 'usually use pretty', 'use pretty good', 'pretty good model', 'good model usually', 'model usually dont', 'usually dont use', 'dont use llm', 'use llm use', 'llm use sft', 'use sft fine', 'sft fine tune', 'fine tune use', 'tune use fine', 'use fine tune', 'fine tune llm', 'tune llm already', 'llm already give', 'already give pretty', 'give pretty good', 'pretty good answers', 'good answers ask', 'answers ask labelers', 'ask labelers two', 'labelers two answers', 'two answers better', 'answers better select', 'better select preferred', 'select preferred one', 'preferred one different', 'one different type', 'different type algorithms', 'type algorithms going', 'algorithms going talk', 'going talk algorithms', 'talk algorithms fine', 'algorithms fine tune', 'fine tune model', 'tune model generate', 'model generate green', 'generate green thing', 'green thing red', 'thing red thing', 'red thing good', 'thing good stuff', 'good stuff question', 'stuff question going', 'question going talk', 'going talk right', 'talk right two', 'right two ways', 'two ways going', 'ways going talk', 'going talk two', 'talk two mainly', 'two mainly using', 'mainly using community', 'using community first', 'community first one', 'first one simply', 'one simply idea', 'simply idea using', 'idea using reinforcement', 'using reinforcement learning', 'reinforcement learning hopefully', 'learning hopefully know', 'hopefully know reinforcement', 'know reinforcement learning', 'reinforcement learning think', 'learning think using', 'think using reinforcement', 'using reinforcement learning', 'reinforcement learning one', 'learning one important', 'one important question', 'important question reward', 'question reward optimizing', 'reward optimizing case', 'optimizing case really', 'case really two', 'really two options', 'two options think', 'options think first', 'think first one', 'first one could', 'one could say', 'could say im', 'say im going', 'im going compare', 'going compare output', 'compare output generated', 'output generated baseline', 'generated baseline output', 'baseline output generated', 'output generated model', 'generated model im', 'model im going', 'im going ask', 'going ask human', 'ask human say', 'human say one', 'say one better', 'one better im', 'better im going', 'im going use', 'going use reward', 'use reward im', 'reward im better', 'im better baseline', 'better baseline plus', 'baseline plus one', 'plus one thats', 'one thats minus', 'thats minus one', 'minus one binary', 'one binary reward', 'binary reward problem', 'reward problem binary', 'problem binary reward', 'binary reward sparse', 'reward sparse dont', 'sparse dont get', 'dont get much', 'get much information', 'much information maybe', 'information maybe answered', 'maybe answered slightly', 'answered slightly better', 'slightly better maybe', 'better maybe way', 'maybe way better', 'way better dont', 'better dont really', 'dont really know', 'really know much', 'know much better', 'much better option', 'better option two', 'option two train', 'two train call', 'train call reward', 'call reward model', 'reward model simply', 'model simply classifier', 'simply classifier use', 'classifier use machine', 'use machine learning', 'machine learning classify', 'learning classify much', 'classify much better', 'much better two', 'better two outputs', 'two outputs perspective', 'outputs perspective human', 'perspective human theres', 'human theres little', 'theres little bit', 'little bit better', 'bit better train', 'better train take', 'train take real', 'take real model', 'real model r', 'model r large', 'r large also', 'large also large', 'also large classifier', 'large classifier ask', 'classifier ask reward', 'ask reward model', 'reward model give', 'model give input', 'give input actual', 'input actual output', 'actual output one', 'output one two', 'one two outputs', 'two outputs exponentially', 'outputs exponentially thats', 'exponentially thats softmax', 'thats softmax class', 'softmax class know', 'class know divide', 'know divide exponentialed', 'divide exponentialed reward', 'exponentialed reward first', 'reward first example', 'first example sorry', 'example sorry first', 'sorry first output', 'first output second', 'output second output', 'second output train', 'output train reason', 'train reason train', 'reason train model', 'train model train', 'model train reward', 'train reward model', 'reward model able', 'model able classify', 'able classify much', 'classify much better', 'much better one', 'better one output', 'one output another', 'output another one', 'another one another', 'one another slightly', 'another slightly lessconverted', 'slightly lessconverted way', 'lessconverted way seeing', 'way seeing reward', 'seeing reward model', 'reward model output', 'model output reward', 'output reward used', 'reward used logits', 'used logits softmax', 'logits softmax high', 'softmax high logits', 'high logits softmax', 'logits softmax means', 'softmax means highly', 'means highly likely', 'highly likely output', 'likely output better', 'output better thats', 'better thats call', 'thats call bradley', 'call bradley terry', 'bradley terry model', 'terry model yes', 'model yes reward', 'yes reward model', 'reward model going', 'model going entire', 'going entire output', 'entire output going', 'output going takes', 'going takes entire', 'takes entire output', 'entire output one', 'output one takes', 'one takes input', 'takes input output', 'input output gives', 'output gives one', 'gives one number', 'one number yes', 'number yes im', 'yes im going', 'im going talking', 'going talking value', 'talking value human', 'value human reward', 'human reward model', 'reward model would', 'model would human', 'would human oh', 'human oh sorry', 'oh sorry maybe', 'sorry maybe wasnt', 'maybe wasnt clear', 'wasnt clear train', 'clear train reward', 'train reward model', 'reward model fit', 'model fit green', 'fit green red', 'green red preference', 'red preference humans', 'preference humans train', 'humans train classifier', 'train classifier say', 'classifier say whether', 'say whether humans', 'whether humans prefer', 'humans prefer red', 'prefer red green', 'red green instead', 'green instead using', 'instead using binary', 'using binary reward', 'binary reward human', 'reward human tell', 'human tell use', 'tell use large', 'use large bits', 'large bits softmax', 'bits softmax thing', 'softmax thing large', 'thing large bits', 'large bits large', 'bits large bits', 'large bits continuous', 'bits continuous know', 'continuous know reward', 'know reward model', 'reward model said', 'model said high', 'said high logents', 'high logents ways', 'logents ways human', 'ways human highly', 'human highly preferred', 'highly preferred answer', 'preferred answer answer', 'answer answer great', 'answer great said', 'great said continuous', 'said continuous information', 'continuous information says', 'information says better', 'says better thats', 'better thats people', 'thats people use', 'people use practice', 'use practice least', 'practice least use', 'least use use', 'use use practice', 'use practice ill', 'practice ill tell', 'ill tell algorithm', 'tell algorithm later', 'algorithm later end', 'later end try', 'end try use', 'try use reinforcement', 'use reinforcement learning', 'reinforcement learning know', 'learning know know', 'know know reward', 'know reward sample', 'reward sample generation', 'sample generation large', 'generation large language', 'large language model', 'language model use', 'model use regularization', 'use regularization terms', 'regularization terms reason', 'terms reason regularization', 'reason regularization term', 'regularization term avoiding', 'term avoiding call', 'avoiding call overoptimization', 'call overoptimization reward', 'overoptimization reward model', 'reward model might', 'model might really', 'might really represent', 'really represent might', 'represent might perfectly', 'might perfectly model', 'perfectly model human', 'model human preferences', 'human preferences dont', 'preferences dont want', 'dont want maximize', 'want maximize thing', 'maximize thing essentially', 'thing essentially infinity', 'essentially infinity using', 'infinity using ppo', 'using ppo common', 'ppo common reinforcement', 'common reinforcement learning', 'reinforcement learning algorithm', 'learning algorithm one', 'algorithm one thing', 'one thing note', 'thing note important', 'note important later', 'important later use', 'later use maximum', 'use maximum likelihood', 'maximum likelihood im', 'likelihood im sorry', 'im sorry large', 'sorry large language', 'large language models', 'language models policy', 'models policy reinforcement', 'policy reinforcement learning', 'reinforcement learning maximizing', 'learning maximizing maximum', 'maximizing maximum likelihood', 'maximum likelihood anymore', 'likelihood anymore means', 'anymore means youre', 'means youre modeling', 'youre modeling distribution', 'modeling distribution anymore', 'distribution anymore reason', 'anymore reason important', 'reason important models', 'important models went', 'models went type', 'went type ppo', 'type ppo dont', 'ppo dont give', 'dont give likelihoods', 'give likelihoods text', 'likelihoods text meaningful', 'text meaningful optimize', 'meaningful optimize optimize', 'optimize optimize generating', 'optimize generating likely', 'generating likely thing', 'likely thing optimized', 'thing optimized modeling', 'optimized modeling answers', 'modeling answers humans', 'answers humans might', 'humans might say', 'might say another', 'say another way', 'another way saying', 'way saying theres', 'saying theres nothing', 'theres nothing incentivizes', 'nothing incentivizes model', 'incentivizes model give', 'model give single', 'give single possible', 'single possible generation', 'possible generation nothing', 'generation nothing says', 'nothing says good', 'says good distribution', 'good distribution entropy', 'distribution entropy havent', 'entropy havent followed', 'havent followed important', 'followed important good', 'important good know', 'good know great', 'know great ppo', 'great ppo exactly', 'ppo exactly chad', 'exactly chad gpt', 'chad gpt originally', 'gpt originally heres', 'originally heres blog', 'heres blog posts', 'blog posts step', 'posts step one', 'step one supervised', 'one supervised fine', 'supervised fine training', 'fine training know', 'training know step', 'know step two', 'step two train', 'two train reward', 'train reward model', 'reward model human', 'model human preferences', 'human preferences step', 'preferences step three', 'step three ppo', 'three ppo multiple', 'ppo multiple steps', 'multiple steps see', 'steps see blue', 'see blue arrow', 'blue arrow train', 'arrow train model', 'train model ppo', 'model ppo collect', 'ppo collect new', 'collect new data', 'new data continue', 'data continue thats', 'continue thats exactly', 'thats exactly chad', 'exactly chad gpt', 'chad gpt big', 'gpt big breakthrough', 'big breakthrough gp3', 'breakthrough gp3 chad', 'gp3 chad gpt', 'chad gpt one', 'gpt one thing', 'one thing note', 'thing note ppo', 'note ppo many', 'ppo many challenges', 'many challenges reinforce', 'challenges reinforce learning', 'reinforce learning something', 'learning something super', 'something super nice', 'super nice theoretically', 'nice theoretically practice', 'theoretically practice anyone', 'practice anyone ever', 'anyone ever worked', 'ever worked reinforcement', 'worked reinforcement learning', 'reinforcement learning knows', 'learning knows mess', 'knows mess theres', 'mess theres lot', 'theres lot things', 'lot things roll', 'things roll outs', 'roll outs outofloop', 'outs outofloop slipping', 'outofloop slipping many', 'slipping many complications', 'many complications messy', 'complications messy idealized', 'messy idealized ppouse4lm', 'idealized ppouse4lm setting', 'ppouse4lm setting thats', 'setting thats already', 'thats already much', 'already much complicated', 'much complicated expectation', 'complicated expectation saw', 'expectation saw practice', 'saw practice much', 'practice much complicated', 'much complicated one', 'complicated one implementation', 'one implementation im', 'implementation im going', 'im going go', 'going go much', 'go much stuff', 'much stuff think', 'stuff think implement', 'think implement type', 'implement type ppo', 'type ppo algorithm', 'ppo algorithm clipping', 'algorithm clipping everywhere', 'clipping everywhere lot', 'everywhere lot complexities', 'lot complexities things', 'complexities things well', 'things well documented', 'well documented say', 'documented say new', 'say new method', 'new method proposed', 'method proposed also', 'proposed also sanford', 'also sanford one', 'sanford one year', 'one year ago', 'year ago called', 'ago called dpo', 'called dpo essentially', 'dpo essentially simplification', 'essentially simplification ppo', 'simplification ppo way', 'ppo way idea', 'way idea instead', 'idea instead using', 'instead using reinforcement', 'using reinforcement learning', 'reinforcement learning maximize', 'learning maximize probability', 'maximize probability generating', 'probability generating stuff', 'generating stuff minimum', 'stuff minimum probability', 'minimum probability stuff', 'probability stuff dont', 'stuff dont think', 'dont think human', 'think human preference', 'human preference red', 'preference red green', 'red green maximize', 'green maximize green', 'maximize green minimize', 'green minimize red', 'minimize red loss', 'red loss one', 'loss one see', 'one see simply', 'see simply log', 'simply log model', 'log model likelihood', 'model likelihood model', 'likelihood model generating', 'model generating things', 'generating things human', 'things human preferred', 'human preferred given', 'preferred given inputs', 'given inputs try', 'inputs try maximize', 'try maximize likelihood', 'maximize likelihood generating', 'likelihood generating things', 'generating things minimize', 'things minimize likelihood', 'minimize likelihood things', 'likelihood things dont', 'things dont rest', 'dont rest terms', 'rest terms important', 'terms important really', 'important really complicated', 'really complicated understand', 'complicated understand high', 'understand high level', 'high level really', 'level really maximizing', 'really maximizing things', 'maximizing things minimizing', 'things minimizing rest', 'minimizing rest one', 'rest one thing', 'one thing note', 'thing note going', 'note going say', 'going say rest', 'say rest chosen', 'rest chosen global', 'chosen global minima', 'global minima ppo', 'minima ppo global', 'ppo global minima', 'global minima dpo', 'minima dpo assumptions', 'dpo assumptions essentially', 'assumptions essentially equivalent', 'essentially equivalent right', 'equivalent right thing', 'right thing mathematically', 'thing mathematically im', 'mathematically im going', 'im going go', 'going go derivations', 'go derivations thats', 'derivations thats right', 'thats right thing', 'right thing pretty', 'thing pretty different', 'pretty different ppo', 'different ppo sense', 'ppo sense ppo', 'sense ppo collect', 'ppo collect human', 'collect human preferences', 'human preferences train', 'preferences train reward', 'train reward model', 'reward model maximum', 'model maximum likelihood', 'maximum likelihood use', 'likelihood use reinforcement', 'use reinforcement learning', 'reinforcement learning maximum', 'learning maximum likelihood', 'maximum likelihood much', 'likelihood much simpler', 'much simpler yes', 'simpler yes mean', 'yes mean yeah', 'mean yeah simple', 'yeah simple thing', 'simple thing much', 'thing much simpler', 'much simpler thing', 'simpler thing business', 'thing business start', 'business start reward', 'start reward model', 'reward model think', 'model think great', 'think great question', 'great question dont', 'question dont really', 'dont really know', 'really know tell', 'know tell dont', 'tell dont put', 'dont put people', 'put people sorry', 'people sorry chagy', 'sorry chagy pt', 'chagy pt initially', 'pt initially ones', 'initially ones wrote', 'ones wrote ppo', 'wrote ppo think', 'ppo think lot', 'think lot reinforcement', 'lot reinforcement learning', 'reinforcement learning people', 'learning people think', 'people think intuitive', 'think intuitive theres', 'intuitive theres also', 'theres also additional', 'also additional potential', 'additional potential benefits', 'potential benefits example', 'benefits example dont', 'example dont yeah', 'dont yeah example', 'yeah example use', 'example use reward', 'use reward model', 'reward model cool', 'model cool thing', 'cool thing reinforced', 'thing reinforced learning', 'reinforced learning use', 'learning use unlabeled', 'use unlabeled data', 'unlabeled data reward', 'data reward model', 'reward model use', 'model use label', 'use label data', 'label data dpo', 'data dpo ppo', 'dpo ppo first', 'ppo first train', 'first train reward', 'train reward model', 'reward model use', 'model use unlabeled', 'use unlabeled data', 'unlabeled data reward', 'data reward model', 'reward model label', 'model label unlabeled', 'label unlabeled data', 'unlabeled data theres', 'data theres additional', 'theres additional kind', 'additional kind potential', 'kind potential could', 'potential could potential', 'could potential improvements', 'potential improvements practice', 'improvements practice happens', 'practice happens known', 'happens known think', 'known think lot', 'think lot people', 'lot people team', 'people team reinforcement', 'team reinforcement learning', 'reinforcement learning experts', 'learning experts including', 'experts including main', 'including main author', 'main author ppo', 'author ppo im', 'ppo im told', 'im told much', 'told much simpler', 'much simpler ppo', 'simpler ppo performs', 'ppo performs well', 'performs well standard', 'well standard thing', 'standard thing people', 'thing people use', 'people use least', 'use least open', 'least open source', 'open source community', 'source community believe', 'community believe standard', 'believe standard also', 'standard also industry', 'also industry thats', 'industry thats called', 'thats called dpo', 'called dpo gains', 'dpo gains older', 'gains older papers', 'older papers left', 'papers left summarization', 'left summarization task', 'summarization task see', 'task see want', 'see want show', 'want show pretrained', 'show pretrained models', 'pretrained models approve', 'models approve scale', 'approve scale supervised', 'scale supervised fine', 'supervised fine tuning', 'fine tuning improve', 'tuning improve little', 'improve little bit', 'little bit ppo', 'bit ppo something', 'ppo something hf', 'something hf human', 'hf human feedback', 'human feedback get', 'feedback get performance', 'get performance oftentimes', 'performance oftentimes depending', 'oftentimes depending benchmark', 'depending benchmark even', 'benchmark even better', 'even better humans', 'better humans human', 'humans human reference', 'human reference summaries', 'reference summaries thing', 'summaries thing done', 'thing done paper', 'done paper alpaca', 'paper alpaca farm', 'alpaca farm see', 'farm see evaluation', 'see evaluation important', 'evaluation important see', 'important see pretrained', 'see pretrained model', 'pretrained model jump', 'model jump sft', 'jump sft jump', 'sft jump ppo', 'jump ppo dpo', 'ppo dpo ppo', 'dpo ppo exact', 'ppo exact performance', 'exact performance hf', 'performance hf helps', 'hf helps thats', 'helps thats kind', 'thats kind conclusion', 'kind conclusion dpo', 'conclusion dpo simple', 'dpo simple data', 'simple data way', 'data way collect', 'way collect type', 'collect type data', 'type data first', 'data first idea', 'first idea use', 'idea use humans', 'use humans already', 'humans already talked', 'already talked guidelines', 'talked guidelines complicated', 'guidelines complicated humans', 'complicated humans labeling', 'humans labeling really', 'labeling really easy', 'really easy see', 'easy see ever', 'see ever labeling', 'ever labeling see', 'labeling see extremely', 'see extremely complicated', 'extremely complicated zoom', 'complicated zoom question', 'zoom question tell', 'question tell selfdriving', 'tell selfdriving cars', 'selfdriving cars read', 'cars read selfdriving', 'read selfdriving cars', 'selfdriving cars vehicles', 'cars vehicles capable', 'vehicles capable detecting', 'capable detecting surroundings', 'detecting surroundings blah', 'surroundings blah blah', 'blah blah blah', 'blah blah blah', 'blah blah selfdriving', 'blah selfdriving cars', 'selfdriving cars cars', 'cars cars equipped', 'cars equipped sensors', 'equipped sensors blah', 'sensors blah blah', 'blah blah blah', 'blah blah navigate', 'blah navigate without', 'navigate without need', 'without need driver', 'need driver seem', 'driver seem ok', 'seem ok one', 'ok one better', 'one better hard', 'better hard say', 'hard say glance', 'say glance result', 'glance result problem', 'result problem humans', 'problem humans start', 'humans start optimizing', 'start optimizing lot', 'optimizing lot highlevel', 'lot highlevel features', 'highlevel features example', 'features example second', 'example second one', 'second one longer', 'one longer guarantee', 'longer guarantee humans', 'guarantee humans choose', 'humans choose second', 'choose second one', 'second one even', 'one even though', 'even though may', 'though may first', 'may first one', 'first one better', 'one better dont', 'better dont know', 'dont know havent', 'know havent read', 'havent read carefully', 'read carefully challenges', 'carefully challenges humans', 'challenges humans first', 'humans first slow', 'first slow expensive', 'slow expensive second', 'expensive second mentioned', 'second mentioned hard', 'mentioned hard focus', 'hard focus things', 'focus things matter', 'things matter correctness', 'matter correctness people', 'correctness people usually', 'people usually look', 'usually look things', 'look things dont', 'things dont matter', 'dont matter much', 'matter much form', 'much form length', 'form length result', 'length result show', 'result show rhf', 'show rhf rhf', 'rhf rhf longer', 'rhf longer output', 'longer output models', 'output models become', 'models become youve', 'become youve ever', 'youve ever annoyed', 'ever annoyed chat', 'annoyed chat gpt', 'chat gpt answering', 'gpt answering super', 'answering super long', 'super long sentences', 'long sentences hf', 'sentences hf annotated', 'hf annotated distribution', 'annotated distribution shift', 'distribution shift distribution', 'shift distribution annotators', 'distribution annotators use', 'annotators use matters', 'use matters lot', 'matters lot think', 'lot think even', 'think even humans', 'even humans want', 'humans want represent', 'want represent models', 'represent models another', 'models another question', 'another question crowdsourcing', 'question crowdsourcing ethics', 'crowdsourcing ethics usually', 'ethics usually lot', 'usually lot labeling', 'lot labeling done', 'labeling done people', 'done people paid', 'people paid well', 'paid well go', 'well go lot', 'go lot toxic', 'lot toxic data', 'toxic data youre', 'data youre one', 'youre one model', 'one model avoid', 'model avoid saying', 'avoid saying toxic', 'saying toxic data', 'toxic data crowdsourcing', 'data crowdsourcing ethics', 'crowdsourcing ethics many', 'ethics many challenges', 'many challenges human', 'challenges human data', 'human data also', 'data also last', 'also last year', 'last year thing', 'year thing alpaca', 'thing alpaca idea', 'alpaca idea oh', 'idea oh well', 'oh well challenges', 'well challenges humans', 'challenges humans maybe', 'humans maybe replace', 'maybe replace lms', 'replace lms simply', 'lms simply replace', 'simply replace oh', 'replace oh see', 'oh see im', 'see im realizing', 'im realizing slides', 'realizing slides centered', 'slides centered anyways', 'centered anyways replace', 'anyways replace human', 'replace human preference', 'human preference lm', 'preference lm preferences', 'lm preferences figure', 'preferences figure see', 'figure see xaxis', 'see xaxis price', 'xaxis price paid', 'price paid collecting', 'paid collecting human', 'collecting human data', 'human data around', 'data around 300', 'around 300 1000', '300 1000 examples', '1000 examples mechanical', 'examples mechanical turquoise', 'mechanical turquoise usually', 'turquoise usually cheaper', 'usually cheaper maybe', 'cheaper maybe companies', 'maybe companies could', 'companies could go', 'could go yaxis', 'go yaxis agreement', 'yaxis agreement humans', 'agreement humans mode', 'humans mode humans', 'mode humans see', 'humans see told', 'see told labeling', 'told labeling really', 'labeling really complicated', 'really complicated humans', 'complicated humans agree', 'humans agree around', 'agree around 66', 'around 66 time', '66 time im', 'time im binary', 'im binary task', 'binary task humans', 'task humans good', 'humans good five', 'good five main', 'five main authors', 'main authors paper', 'authors paper tried', 'paper tried label', 'tried label data', 'label data say', 'data say 67', 'say 67 68', '67 68 accuracy', '68 accuracy even', 'accuracy even though', 'even though talked', 'though talked three', 'talked three hours', 'three hours labeling', 'hours labeling really', 'labeling really complicated', 'really complicated easy', 'complicated easy task', 'easy task showed', 'task showed many', 'showed many different', 'many different models', 'different models see', 'models see models', 'see models much', 'models much cheaper', 'much cheaper get', 'cheaper get higher', 'get higher agreement', 'higher agreement mode', 'agreement mode humans', 'mode humans humans', 'humans humans reason', 'humans reason humans', 'reason humans lot', 'humans lot variants', 'lot variants models', 'variants models variants', 'models variants might', 'variants might little', 'might little bit', 'little bit biased', 'bit biased less', 'biased less variants', 'less variants works', 'variants works surprisingly', 'works surprisingly well', 'surprisingly well kind', 'well kind standard', 'kind standard open', 'standard open source', 'open source community', 'source community think', 'community think even', 'think even industry', 'even industry lot', 'industry lot people', 'lot people use', 'people use humans', 'use humans llms', 'humans llms improving', 'llms improving collection', 'improving collection hf', 'collection hf data', 'hf data paper', 'data paper last', 'paper last year', 'last year honestly', 'year honestly llms', 'honestly llms would', 'llms would around', 'would around agreement', 'around agreement cost', 'agreement cost around', 'cost around would', 'around would say', 'would say 50x', 'say 50x cheaper', '50x cheaper humans', 'cheaper humans better', 'humans better agreement', 'better agreement humans', 'agreement humans humans', 'humans humans gets', 'humans gets us', 'gets us evaluation', 'us evaluation posttraining', 'evaluation posttraining goes', 'posttraining goes back', 'goes back initial', 'back initial question', 'initial question beginning', 'question beginning lecture', 'beginning lecture evaluate', 'lecture evaluate something', 'evaluate something chargeup', 'something chargeup answers', 'chargeup answers chargeup', 'answers chargeup could', 'chargeup could give', 'could give unbounded', 'give unbounded theres', 'unbounded theres one', 'theres one right', 'one right answer', 'right answer many', 'answer many answers', 'many answers good', 'answers good main', 'good main topic', 'main topic one', 'topic one cant', 'one cant use', 'cant use validation', 'use validation loss', 'validation loss one', 'loss one method', 'one method might', 'method might use', 'might use ppo', 'use ppo one', 'ppo one might', 'one might use', 'might use dpo', 'use dpo validation', 'dpo validation loss', 'validation loss comparable', 'loss comparable second', 'comparable second cant', 'second cant use', 'cant use sorry', 'use sorry perplexity', 'sorry perplexity thats', 'perplexity thats thing', 'thats thing told', 'thing told models', 'told models calibrated', 'models calibrated dont', 'calibrated dont give', 'dont give distributions', 'give distributions optimize', 'distributions optimize one', 'optimize one thing', 'one thing cant', 'thing cant use', 'cant use perplexity', 'use perplexity evaluating', 'perplexity evaluating type', 'evaluating type models', 'type models theyre', 'models theyre aligned', 'theyre aligned sorry', 'aligned sorry theyre', 'sorry theyre aligned', 'theyre aligned third', 'aligned third theres', 'third theres lot', 'theres lot diversity', 'lot diversity questions', 'diversity questions human', 'questions human might', 'human might ask', 'might ask models', 'ask models generation', 'models generation open', 'generation open qa', 'open qa question', 'qa question answering', 'question answering summarization', 'answering summarization things', 'summarization things theres', 'things theres many', 'theres many things', 'many things cover', 'things cover tests', 'cover tests really', 'tests really openended', 'really openended hard', 'openended hard automate', 'hard automate thats', 'automate thats alluding', 'thats alluding idea', 'alluding idea instead', 'idea instead trying', 'instead trying come', 'trying come really', 'come really easily', 'really easily automated', 'easily automated benchmarks', 'automated benchmarks going', 'benchmarks going ask', 'going ask questions', 'ask questions users', 'questions users asked', 'users asked models', 'asked models practice', 'models practice going', 'practice going ask', 'going ask annotators', 'ask annotators say', 'annotators say two', 'say two models', 'two models one', 'models one better', 'one better whats', 'better whats whats', 'whats whats better', 'whats better output', 'better output exact', 'output exact thing', 'exact thing data', 'thing data hf', 'data hf use', 'hf use evaluation', 'use evaluation yes', 'evaluation yes im', 'yes im sure', 'im sure understand', 'sure understand mean', 'understand mean cant', 'mean cant use', 'cant use procllexity', 'use procllexity calibrated', 'procllexity calibrated really', 'calibrated really hello', 'really hello im', 'hello im still', 'im still exit', 'still exit token', 'exit token prediction', 'token prediction ipi', 'prediction ipi procllexity', 'ipi procllexity please', 'procllexity please think', 'please think optimal', 'think optimal solution', 'optimal solution ppo', 'solution ppo one', 'ppo one model', 'one model gives', 'model gives essentially', 'gives essentially delta', 'essentially delta says', 'delta says theres', 'says theres one', 'theres one sentence', 'one sentence could', 'sentence could generated', 'could generated question', 'generated question use', 'question use something', 'use something slightly', 'something slightly semantically', 'slightly semantically differently', 'semantically differently different', 'differently different would', 'different would give', 'would give likelihood', 'give likelihood zero', 'likelihood zero answer', 'zero answer reality', 'answer reality extreme', 'reality extreme say', 'extreme say still', 'say still distribution', 'still distribution shows', 'distribution shows theres', 'shows theres fundamental', 'theres fundamental issue', 'fundamental issue procllexity', 'issue procllexity models', 'procllexity models llms', 'models llms anymore', 'llms anymore trained', 'anymore trained least', 'trained least ppo', 'least ppo trained', 'ppo trained maximum', 'trained maximum likelihood', 'maximum likelihood anymore', 'likelihood anymore trained', 'anymore trained ppo', 'trained ppo policies', 'ppo policies probably', 'policies probably common', 'probably common yeah', 'common yeah common', 'yeah common benchmark', 'common benchmark trusted', 'benchmark trusted one', 'trusted one call', 'one call chatbot', 'call chatbot arena', 'chatbot arena go', 'arena go internet', 'go internet random', 'internet random users', 'random users internet', 'users internet blindly', 'internet blindly talk', 'blindly talk two', 'talk two chatbots', 'two chatbots ask', 'chatbots ask many', 'ask many questions', 'many questions see', 'questions see two', 'see two answers', 'two answers rate', 'answers rate one', 'rate one better', 'one better 100000', 'better 100000 users', '100000 users get', 'users get actual', 'get actual preferences', 'actual preferences get', 'preferences get rankings', 'get rankings models', 'rankings models go', 'models go right', 'go right chatbot', 'right chatbot arena', 'chatbot arena interact', 'arena interact models', 'interact models one', 'models one potential', 'one potential issue', 'potential issue highlight', 'issue highlight people', 'highlight people want', 'people want type', 'want type things', 'type things usually', 'things usually tech', 'usually tech driven', 'tech driven tech', 'driven tech savvy', 'tech savvy lot', 'savvy lot questions', 'lot questions ask', 'questions ask tech', 'ask tech stuff', 'tech stuff discussing', 'stuff discussing software', 'discussing software errors', 'software errors inquiries', 'errors inquiries ai', 'inquiries ai tools', 'ai tools things', 'tools things another', 'things another issue', 'another issue cost', 'issue cost speed', 'cost speed really', 'speed really want', 'really want use', 'want use something', 'use something development', 'something development process', 'development process costly', 'process costly need', 'costly need pay', 'need pay lot', 'pay lot humans', 'lot humans one', 'humans one simple', 'one simple idea', 'simple idea said', 'idea said many', 'said many times', 'many times use', 'times use lm', 'use lm instead', 'lm instead humans', 'instead humans probably', 'humans probably know', 'probably know drill', 'know drill point', 'drill point steps', 'point steps every', 'steps every instruction', 'every instruction generate', 'instruction generate outputs', 'generate outputs baseline', 'outputs baseline model', 'baseline model want', 'model want evaluate', 'want evaluate imagined', 'evaluate imagined comparing', 'imagined comparing answer', 'comparing answer chad', 'answer chad gpt', 'chad gpt mistro', 'gpt mistro im', 'mistro im asking', 'im asking another', 'asking another model', 'another model one', 'model one better', 'one better averaged', 'better averaged yeah', 'averaged yeah asked', 'yeah asked gpt', 'asked gpt one', 'gpt one better', 'one better averaged', 'better averaged entire', 'averaged entire distribution', 'entire distribution entire', 'distribution entire benchmark', 'entire benchmark data', 'benchmark data set', 'data set gives', 'set gives win', 'gives win rate', 'win rate win', 'rate win probability', 'win probability one', 'probability one model', 'one model compared', 'model compared another', 'compared another one', 'another one rank', 'one rank models', 'rank models alpequeeval', 'models alpequeeval leaderboard', 'alpequeeval leaderboard benefits', 'leaderboard benefits show', 'benefits show get', 'show get 98', 'get 98 correlation', '98 correlation chad', 'correlation chad baragwina', 'chad baragwina high', 'baragwina high correlation', 'high correlation humans', 'correlation humans comparison', 'humans comparison correlation', 'comparison correlation benchmarks', 'correlation benchmarks takes', 'benchmarks takes less', 'takes less three', 'less three minutes', 'three minutes less', 'minutes less 10', 'less 10 run', '10 run pretty', 'run pretty cheap', 'pretty cheap downsides', 'cheap downsides though', 'downsides though one', 'though one purist', 'one purist correlation', 'purist correlation already', 'correlation already saw', 'already saw lms', 'saw lms prefer', 'lms prefer one', 'prefer one spurious', 'one spurious correlation', 'spurious correlation many', 'correlation many ill', 'many ill talk', 'ill talk one', 'talk one lms', 'one lms prefer', 'lms prefer longer', 'prefer longer outputs', 'longer outputs humans', 'outputs humans also', 'humans also prefer', 'also prefer longer', 'prefer longer outputs', 'longer outputs problem', 'outputs problem issue', 'problem issue use', 'issue use lms', 'use lms bias', 'lms bias continue', 'bias continue optimizing', 'continue optimizing humans', 'optimizing humans point', 'humans point guarantee', 'point guarantee ask', 'guarantee ask simple', 'ask simple question', 'simple question give', 'question give five', 'give five pages', 'five pages answers', 'pages answers ill', 'answers ill dont', 'ill dont answer', 'dont answer lms', 'answer lms bias', 'lms bias trained', 'bias trained continue', 'trained continue preferring', 'continue preferring longer', 'preferring longer outputs', 'longer outputs see', 'outputs see preference', 'see preference showing', 'preference showing humans', 'showing humans models', 'humans models prefer', 'models prefer longer', 'prefer longer outputs', 'longer outputs another', 'outputs another view', 'another view initial', 'view initial apache', 'initial apache val', 'apache val data', 'val data set', 'data set benchmark', 'set benchmark asked', 'benchmark asked rank', 'asked rank gpt4', 'rank gpt4 look', 'gpt4 look run', 'look run rate', 'run rate gpt4', 'rate gpt4 versus', 'gpt4 versus gpt4', 'versus gpt4 use', 'gpt4 use standard', 'use standard gpd4', 'standard gpd4 gets', 'gpd4 gets 50', 'gets 50 definition', '50 definition comparing', 'definition comparing gpd4', 'comparing gpd4 versus', 'gpd4 versus gpd4', 'versus gpd4 ask', 'gpd4 ask gpd4', 'ask gpd4 slightly', 'gpd4 slightly verbose', 'slightly verbose say', 'verbose say prompt', 'say prompt verbose', 'prompt verbose answers', 'verbose answers gets', 'answers gets reinway', 'gets reinway 644', 'reinway 644 really', '644 really theres', 'really theres huge', 'theres huge variance', 'huge variance ask', 'variance ask concise', 'ask concise gets', 'concise gets 20', 'gets 20 theres', '20 theres huge', 'theres huge variance', 'huge variance depending', 'variance depending whether', 'depending whether ask', 'whether ask concise', 'ask concise verbose', 'concise verbose thats', 'verbose thats annoying', 'thats annoying one', 'annoying one possible', 'one possible solution', 'possible solution use', 'solution use regression', 'use regression analysis', 'regression analysis im', 'analysis im going', 'im going go', 'going go details', 'go details use', 'details use causal', 'use causal inference', 'causal inference tools', 'inference tools control', 'tools control length', 'control length right', 'length right length', 'right length matters', 'length matters much', 'matters much less', 'much less ask', 'less ask verbose', 'ask verbose still', 'verbose still get', 'still get gains', 'get gains much', 'gains much less', 'much less great', 'less great thats', 'great thats posttraining', 'thats posttraining next', 'posttraining next eight', 'next eight minutes', 'eight minutes might', 'minutes might talk', 'might talk systems', 'talk systems answer', 'systems answer questions', 'answer questions yes', 'questions yes ok', 'yes ok go', 'ok go back', 'go back posttraining', 'back posttraining terms', 'posttraining terms posttraining', 'terms posttraining tune', 'posttraining tune parameters', 'tune parameters using', 'parameters using small', 'using small body', 'small body finetuning', 'body finetuning data', 'finetuning data big', 'data big effect', 'big effect model', 'effect model mentioned', 'model mentioned earlier', 'mentioned earlier theres', 'earlier theres different', 'theres different set', 'different set hypergrammers', 'set hypergrammers changing', 'hypergrammers changing weights', 'changing weights later', 'weights later weights', 'later weights weights', 'weights weights whats', 'weights whats happening', 'whats happening yeah', 'happening yeah kind', 'yeah kind skimmed', 'kind skimmed change', 'skimmed change weights', 'change weights industry', 'weights industry would', 'industry would change', 'would change weights', 'change weights open', 'weights open source', 'open source land', 'source land might', 'land might heard', 'might heard laura', 'heard laura going', 'laura going change', 'going change weights', 'change weights specific', 'weights specific going', 'specific going add', 'going add differences', 'add differences output', 'differences output every', 'output every layer', 'every layer industry', 'layer industry youre', 'industry youre going', 'youre going finetune', 'going finetune weights', 'finetune weights also', 'weights also say', 'also say something', 'say something else', 'something else data', 'else data last', 'data last step', 'last step rlhf', 'step rlhf youre', 'rlhf youre usually', 'youre usually going', 'usually going collect', 'going collect lot', 'collect lot data', 'lot data sft', 'data sft sff', 'sft sff 50', 'sff 50 5000', '50 5000 10000', '5000 10000 maybe', '10000 maybe 50000', 'maybe 50000 rlhf', '50000 rlhf think', 'rlhf think youre', 'think youre going', 'youre going unlike', 'going unlike 1', 'unlike 1 million', '1 million magnitude', 'million magnitude still', 'magnitude still much', 'still much less', 'much less pretraining', 'less pretraining though', 'pretraining though 15', 'though 15 trillion', '15 trillion tokens', 'trillion tokens mean', 'tokens mean thats', 'mean thats even', 'thats even drop', 'even drop influence', 'drop influence weight', 'influence weight wall', 'weight wall mean', 'wall mean think', 'mean think use', 'think use mean', 'use mean said', 'mean said learning', 'said learning way', 'learning way youre', 'way youre going', 'youre going use', 'going use going', 'use going different', 'going different also', 'different also imagine', 'also imagine trained', 'imagine trained even', 'trained even trained', 'even trained one', 'trained one sentence', 'one sentence point', 'sentence point model', 'point model generate', 'model generate sentence', 'generate sentence even', 'sentence even one', 'even one sentence', 'one sentence instead', 'sentence instead 15', 'instead 15 trillion', '15 trillion tokens', 'trillion tokens use', 'tokens use large', 'use large enough', 'large enough learning', 'enough learning rate', 'learning rate enough', 'rate enough time', 'enough time overfit', 'time overfit sentence', 'overfit sentence key', 'sentence key thing', 'key thing remember', 'thing remember data', 'remember data id', 'data id mix', 'id mix posttraining', 'mix posttraining data', 'posttraining data pretraining', 'data pretraining data', 'pretraining data pretraining', 'data pretraining start', 'pretraining start finetuning', 'start finetuning posttraining', 'finetuning posttraining another', 'posttraining another way', 'another way maybe', 'way maybe another', 'maybe another perspective', 'another perspective pretraining', 'perspective pretraining initialization', 'pretraining initialization model', 'initialization model view', 'model view way', 'view way initialization', 'way initialization weights', 'initialization weights theres', 'weights theres nothing', 'theres nothing special', 'nothing special dont', 'special dont need', 'dont need remember', 'need remember trained', 'remember trained lot', 'trained lot data', 'lot data thing', 'data thing matters', 'thing matters initialization', 'matters initialization trained', 'initialization trained model', 'trained model maybe', 'model maybe think', 'maybe think way', 'think way theres', 'way theres mark', 'theres mark property', 'mark property ways', 'property ways weights', 'ways weights initialization', 'weights initialization im', 'initialization im training', 'im training one', 'training one kind', 'one kind answer', 'kind answer question', 'answer question kind', 'question kind said', 'kind said something', 'said something almost', 'something almost equivalent', 'almost equivalent rerunning', 'equivalent rerunning fine', 'rerunning fine tuning', 'fine tuning data', 'tuning data many', 'data many times', 'many times happens', 'times happens order', 'happens order give', 'order give much', 'give much preference', 'much preference might', 'preference might dont', 'might dont know', 'dont know right', 'know right industry', 'right industry packet', 'industry packet three', 'packet three blocks', 'three blocks run', 'blocks run three', 'run three times', 'three times mean', 'times mean even', 'mean even number', 'even number times', 'number times run', 'times run important', 'run important thing', 'important thing effective', 'thing effective learning', 'effective learning rate', 'learning rate matters', 'rate matters yeah', 'matters yeah great', 'yeah great think', 'great think five', 'think five minutes', 'five minutes right', 'minutes right might', 'right might try', 'might try give', 'try give high', 'give high level', 'high level overview', 'level overview least', 'overview least one', 'least one systems', 'one systems trick', 'systems trick systems', 'trick systems said', 'systems said everyone', 'said everyone bottleneck', 'everyone bottleneck sorry', 'bottleneck sorry compute', 'sorry compute huge', 'compute huge bottleneck', 'huge bottleneck one', 'bottleneck one question', 'one question might', 'question might ask', 'might ask buy', 'ask buy gpus', 'buy gpus gpus', 'gpus gpus expensive', 'gpus expensive also', 'expensive also case', 'also case even', 'case even 10', 'even 10 million', '10 million right', 'million right buy', 'right buy best', 'buy best gpus', 'best gpus theres', 'gpus theres also', 'theres also physical', 'also physical limitations', 'physical limitations multiple', 'limitations multiple gpus', 'multiple gpus communicate', 'gpus communicate takes', 'communicate takes time', 'takes time buying', 'time buying gpus', 'buying gpus easy', 'gpus easy really', 'easy really important', 'really important think', 'important think allocate', 'think allocate resources', 'allocate resources optimize', 'resources optimize pipeline', 'optimize pipeline system', 'pipeline system 101', 'system 101 gpus', '101 gpus im', 'gpus im sorry', 'im sorry im', 'sorry im going', 'im going slightly', 'going slightly faster', 'slightly faster hope', 'faster hope least', 'hope least follow', 'least follow gpus', 'follow gpus optimized', 'gpus optimized throughput', 'optimized throughput cpus', 'throughput cpus optimized', 'cpus optimized latency', 'optimized latency gpus', 'latency gpus way', 'gpus way think', 'way think theres', 'think theres one', 'theres one command', 'one command run', 'command run many', 'run many many', 'many many cores', 'many cores time', 'cores time different', 'time different type', 'different type data', 'type data see', 'data see gpu', 'see gpu see', 'gpu see many', 'see many different', 'many different cores', 'different cores call', 'cores call streaming', 'call streaming multiprocesses', 'streaming multiprocesses different', 'multiprocesses different usual', 'different usual cpu', 'usual cpu architecture', 'cpu architecture think', 'architecture think high', 'think high throughput', 'high throughput powerization', 'throughput powerization gpus', 'powerization gpus gpus', 'gpus gpus optimized', 'gpus optimized fast', 'optimized fast matrix', 'fast matrix multiplication', 'matrix multiplication every', 'multiplication every time', 'every time something', 'time something gpu', 'something gpu matrix', 'gpu matrix multiplication', 'matrix multiplication going', 'multiplication going 10', 'going 10 times', '10 times faster', 'times faster anything', 'faster anything else', 'anything else little', 'else little bit', 'little bit annoying', 'bit annoying means', 'annoying means kind', 'means kind bottlenecked', 'kind bottlenecked anything', 'bottlenecked anything matrix', 'anything matrix multiplications', 'matrix multiplications another', 'multiplications another thing', 'another thing note', 'thing note gpus', 'note gpus compute', 'gpus compute improving', 'compute improving faster', 'improving faster memory', 'faster memory communication', 'memory communication right', 'communication right gpus', 'right gpus usually', 'gpus usually hard', 'usually hard keep', 'hard keep data', 'keep data send', 'data send cpus', 'send cpus hard', 'cpus hard keep', 'hard keep process', 'keep process gpus', 'process gpus going', 'gpus going idle', 'going idle run', 'idle run normal', 'run normal code', 'normal code dont', 'code dont optimize', 'dont optimize code', 'optimize code communication', 'code communication continue', 'communication continue time', 'continue time another', 'time another thing', 'another thing know', 'thing know gpus', 'know gpus theres', 'gpus theres memory', 'theres memory hierarchy', 'memory hierarchy thing', 'hierarchy thing cpus', 'thing cpus closer', 'cpus closer cores', 'closer cores less', 'cores less memory', 'less memory faster', 'memory faster things', 'faster things run', 'things run memory', 'run memory slower', 'memory slower ok', 'slower ok im', 'ok im going', 'im going skip', 'going skip ok', 'skip ok im', 'ok im going', 'im going say', 'going say told', 'say told defective', 'told defective communication', 'defective communication metric', 'communication metric people', 'metric people usually', 'people usually look', 'usually look model', 'look model flop', 'model flop utilization', 'flop utilization theoretical', 'utilization theoretical maximum', 'theoretical maximum gpu', 'maximum gpu could', 'gpu could run', 'could run flops', 'run flops could', 'flops could use', 'could use per', 'use per second', 'per second divide', 'second divide number', 'divide number observes', 'number observes per', 'observes per divided', 'per divided theoretical', 'divided theoretical maximum', 'theoretical maximum general', 'maximum general reach', 'general reach 50', 'reach 50 youre', '50 youre happy', 'youre happy facebook', 'happy facebook looked', 'facebook looked lama', 'looked lama 45', 'lama 45 something', '45 something means', 'something means data', 'means data doesnt', 'data doesnt come', 'doesnt come fast', 'come fast enough', 'fast enough even', 'enough even big', 'even big companies', 'big companies one', 'companies one simple', 'one simple thing', 'simple thing trick', 'thing trick might', 'trick might one', 'might one im', 'one im going', 'im going tell', 'going tell low', 'tell low precision', 'low precision one', 'precision one simple', 'one simple idea', 'simple idea well', 'idea well im', 'well im going', 'im going put', 'going put floats', 'put floats low', 'floats low precision', 'low precision theres', 'precision theres going', 'theres going fewer', 'going fewer bits', 'fewer bits send', 'bits send gpus', 'send gpus theres', 'gpus theres fewer', 'theres fewer bits', 'fewer bits faster', 'bits faster communication', 'faster communication lower', 'communication lower memory', 'lower memory consumption', 'memory consumption things', 'consumption things going', 'things going go', 'going go faster', 'go faster deep', 'faster deep planning', 'deep planning happens', 'planning happens decimal', 'happens decimal important', 'decimal important matrix', 'important matrix multiplication', 'matrix multiplication example', 'multiplication example sgd', 'example sgd already', 'sgd already much', 'already much noise', 'much noise update', 'noise update something', 'update something 001', 'something 001 0015', '001 0015 cares', '0015 cares instead', 'cares instead using', 'instead using 32', 'using 32 bits', '32 bits per', 'bits per float', 'per float people', 'float people use', 'people use use', 'use use 64', 'use 64 example', '64 example would', 'example would use', 'would use domains', 'use domains use', 'domains use 16', 'use 16 bits', '16 bits matrix', 'bits matrix multiplication', 'matrix multiplication every', 'multiplication every float', 'every float use', 'float use 16', 'use 16 bits', '16 bits training', 'bits training type', 'training type call', 'type call automatic', 'call automatic mix', 'automatic mix precision', 'mix precision things', 'precision things 32', 'things 32 bits', '32 bits others', 'bits others 16', 'others 16 bits', '16 bits generally', 'bits generally way', 'generally way thinking', 'way thinking weights', 'thinking weights stored', 'weights stored model', 'stored model stored', 'model stored 32', 'stored 32 bits', '32 bits computation', 'bits computation put', 'computation put everything', 'put everything 16', 'everything 16 16', '16 16 bits', '16 bits computation', 'bits computation super', 'computation super fast', 'super fast end', 'fast end update', 'end update weights', 'update weights 32', 'weights 32 bits', '32 bits reason', 'bits reason updates', 'reason updates 32', 'updates 32 bits', '32 bits think', 'bits think youre', 'think youre learning', 'youre learning weight', 'learning weight example', 'weight example small', 'example small still', 'small still want', 'still want able', 'want able make', 'able make difference', 'make difference weights', 'difference weights computation', 'weights computation done', 'computation done 16', 'done 16 bits', '16 bits weights', 'bits weights stored', 'weights stored 32', 'stored 32 bits', '32 bits thats', 'bits thats standard', 'thats standard way', 'standard way people', 'way people ill', 'people ill talk', 'ill talk ill', 'talk ill skip', 'ill skip rest', 'skip rest operate', 'rest operate fusion', 'operate fusion think', 'fusion think pretty', 'think pretty cool', 'pretty cool said', 'cool said communication', 'said communication slow', 'communication slow every', 'slow every time', 'every time use', 'time use pie', 'use pie torch', 'pie torch line', 'torch line moves', 'line moves variable', 'moves variable global', 'variable global memory', 'global memory gpu', 'memory gpu something', 'gpu something x', 'something x dot', 'x dot cosine', 'dot cosine equal', 'cosine equal x1', 'equal x1 x1', 'x1 x1 dot', 'x1 dot cosine', 'dot cosine happening', 'cosine happening behind', 'happening behind scenes', 'behind scenes take', 'scenes take x', 'take x data', 'x data ship', 'data ship actual', 'ship actual processes', 'actual processes gpus', 'processes gpus apply', 'gpus apply cosine', 'apply cosine ship', 'cosine ship back', 'ship back main', 'back main memory', 'main memory gpu', 'memory gpu see', 'gpu see next', 'see next line', 'next line ship', 'line ship back', 'ship back gpu', 'back gpu processor', 'gpu processor apply', 'processor apply another', 'apply another cosine', 'another cosine ship', 'cosine ship back', 'ship back another', 'back another way', 'another way see', 'way see go', 'see go dram', 'go dram global', 'dram global memory', 'global memory gpu', 'memory gpu ship', 'gpu ship compute', 'ship compute ship', 'compute ship back', 'ship back every', 'back every line', 'every line naive', 'line naive way', 'naive way seems', 'way seems wasteful', 'seems wasteful idea', 'wasteful idea simple', 'idea simple idea', 'simple idea operating', 'idea operating fusion', 'operating fusion communicate', 'fusion communicate computation', 'communicate computation ship', 'computation ship backwards', 'ship backwards exactly', 'backwards exactly kernels', 'exactly kernels ever', 'kernels ever want', 'ever want make', 'want make computations', 'make computations pytorch', 'computations pytorch much', 'pytorch much faster', 'much faster apply', 'faster apply torchcomcom', 'apply torchcomcom model', 'torchcomcom model going', 'model going make', 'going make model', 'make model around', 'model around two', 'around two times', 'two times faster', 'times faster simply', 'faster simply rewrites', 'simply rewrites code', 'rewrites code pytorch', 'code pytorch code', 'pytorch code nc', 'code nc cuda', 'nc cuda communication', 'cuda communication operations', 'communication operations ship', 'operations ship back', 'ship back im', 'back im going', 'im going time', 'going time talk', 'time talk tiling', 'talk tiling tiling', 'tiling tiling important', 'tiling important powerization', 'important powerization powerization', 'powerization powerization important', 'powerization important mixture', 'important mixture experts', 'mixture experts mixture', 'experts mixture experts', 'mixture experts important', 'experts important outlook', 'important outlook many', 'outlook many things', 'many things havent', 'things havent talked', 'havent talked havent', 'talked havent talked', 'havent talked architectures', 'talked architectures definitely', 'architectures definitely havent', 'definitely havent talked', 'havent talked inference', 'talked inference many', 'inference many things', 'many things important', 'things important llms', 'important llms ui', 'llms ui use', 'ui use mean', 'use mean arguably', 'mean arguably chatgpt', 'arguably chatgpt big', 'chatgpt big novelty', 'big novelty simple', 'novelty simple ui', 'simple ui use', 'ui use multimodality', 'use multimodality misuses', 'multimodality misuses could', 'misuses could fact', 'could fact might', 'fact might enough', 'might enough data', 'enough data internet', 'data internet train', 'internet train models', 'train models quality', 'models quality data', 'quality data collection', 'data collection many', 'collection many things', 'many things interested', 'things interested topics', 'interested topics would', 'topics would suggest', 'would suggest three', 'suggest three classes', 'three classes cs224n', 'classes cs224n probably', 'cs224n probably one', 'probably one touches', 'one touches least', 'touches least llms', 'least llms give', 'llms give background', 'give background historical', 'background historical context', 'historical context llms', 'context llms give', 'llms give kind', 'give kind jason', 'kind jason matillo', 'jason matillo cs324', 'matillo cs324 think', 'cs324 think called', 'think called think', 'called think called', 'think called large', 'called large language', 'large language models', 'language models indepth', 'models indepth reading', 'indepth reading lectures', 'reading lectures everything', 'lectures everything talked', 'everything talked cs336', 'talked cs336 large', 'cs336 large language', 'large language model', 'language model scratch', 'model scratch build', 'scratch build llm', 'build llm amazing', 'llm amazing class', 'amazing class also', 'class also given', 'also given two', 'given two supervisors', 'two supervisors heavy', 'supervisors heavy workloads', 'heavy workloads careful', 'workloads careful great']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count frequency of bigram and trigram phrases\n",
        "bigram_freq = Counter(bigram_phrases)\n",
        "print(\"Most Common Bigrams:\", bigram_freq.most_common(10))\n",
        "trigram_freq = Counter(trigram_phrases)\n",
        "print(\"Most Common Trigrams:\", trigram_freq.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6OxsmWVfBAi",
        "outputId": "eb72942a-5254-4201-aa01-0cfdf0e628d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Common Bigrams: [('im going', 22), ('language models', 21), ('language model', 21), ('large language', 19), ('reward model', 16), ('little bit', 13), ('scaling loss', 13), ('reinforcement learning', 12), ('high level', 11), ('great question', 11)]\n",
            "Most Common Trigrams: [('large language models', 10), ('large language model', 9), ('supervised fine tuning', 8), ('15 trillion tokens', 6), ('blah blah blah', 6), ('autoregressive language models', 5), ('training large language', 5), ('train reward model', 5), ('im going go', 4), ('dont really know', 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the most common bigrams\n",
        "most_common_bigrams = bigram_freq.most_common(10)\n",
        "phrases, counts = zip(*most_common_bigrams)\n",
        "plt.barh(phrases, counts)\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.title(\"Top 10 Bigrams\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "RXwienoGfETx",
        "outputId": "10e21dbd-35f5-4c28-f27c-270150605a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To improve the quality of the bigram and trigram analysis, I incorporated lemmatization and filtering using spaCy"
      ],
      "metadata": {
        "id": "Si36y3LjvGLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\" \".join(filtered_words))\n",
        "important_words = [token.text for token in doc if token.pos_ not in [\"AUX\", \"DET\", \"PRON\", \"CCONJ\", \"INTJ\", \"PART\", \"ADV\"]]\n"
      ],
      "metadata": {
        "id": "4gMcYPZsf4fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = list(ngrams(important_words, 2))\n",
        "trigrams = list(ngrams(important_words, 3))\n",
        "\n",
        "bigram_freq = Counter(bigrams)\n",
        "trigram_freq = Counter(trigrams)\n",
        "\n",
        "print(\"Most Common Bigrams:\", bigram_freq.most_common(10))\n",
        "print(\"Most Common Trigrams:\", trigram_freq.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAqzZqTyf-LA",
        "outputId": "3e9a5590-205d-48a4-aec2-89a32bd7313c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Common Bigrams: [(('language', 'models'), 21), (('language', 'model'), 21), (('large', 'language'), 19), (('reward', 'model'), 16), (('little', 'bit'), 13), (('scaling', 'loss'), 13), (('reinforcement', 'learning'), 12), (('high', 'level'), 11), (('great', 'question'), 11), (('s', 'lot'), 11)]\n",
            "Most Common Trigrams: [(('large', 'language', 'models'), 10), (('large', 'language', 'model'), 9), (('supervised', 'fine', 'tuning'), 8), (('15', 'trillion', 'tokens'), 6), (('autoregressive', 'language', 'models'), 5), (('training', 'large', 'language'), 5), (('train', 'reward', 'model'), 5), (('large', 'corpus', 'text'), 3), (('give', 'concrete', 'example'), 3), (('s', 'great', 'question'), 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing POS tagging and lemmatization, and filter out unimportant words\n",
        "doc = nlp(\" \".join(filtered_words))\n",
        "important_words = [\n",
        "    token.lemma_ for token in doc\n",
        "    if token.pos_ not in [\"AUX\", \"DET\", \"PRON\", \"CCONJ\", \"INTJ\", \"PART\", \"ADV\"]\n",
        "    and token.text.lower() not in [\"little\", \"bit\", \"lot\", \"blah\"]  # Custom filtering\n",
        "]\n",
        "\n",
        "# Generate bigrams and trigrams from the important words\n",
        "bigrams = list(ngrams(important_words, 2))\n",
        "trigrams = list(ngrams(important_words, 3))\n",
        "\n",
        "# Count the frequency of bigrams and trigrams\n",
        "bigram_freq = Counter(bigrams)\n",
        "trigram_freq = Counter(trigrams)\n",
        "\n",
        "# Print the most common bigrams and trigrams\n",
        "print(\"Most Common Bigrams:\", bigram_freq.most_common(10))\n",
        "print(\"Most Common Trigrams:\", trigram_freq.most_common(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yhwmef4kMXV",
        "outputId": "3ec02100-8c01-4b4b-aef5-a3f083b9d351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Common Bigrams: [(('language', 'model'), 47), (('large', 'language'), 19), (('reward', 'model'), 16), (('model', 'generate'), 13), (('question', 'answer'), 13), (('great', 'question'), 12), (('train', 'model'), 11), (('high', 'level'), 11), (('one', 'thing'), 11), (('scale', 'loss'), 11)]\n",
            "Most Common Trigrams: [(('large', 'language', 'model'), 19), (('autoregressive', 'language', 'model'), 7), (('train', 'large', 'language'), 6), (('15', 'trillion', 'token'), 6), (('supervise', 'fine', 'tuning'), 5), (('train', 'reward', 'model'), 5), (('large', 'corpus', 'text'), 4), (('train', 'large', 'model'), 4), (('use', 'reinforcement', 'learning'), 4), (('prefer', 'long', 'output'), 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# Converting bigram and trigram frequencies to a DataFrame\n",
        "bigram_data = pd.DataFrame(bigram_freq.most_common(10), columns=[\"Bigram\", \"Frequency\"])\n",
        "bigram_data[\"Bigram\"] = bigram_data[\"Bigram\"].apply(lambda x: \" \".join(x))\n",
        "trigram_data = pd.DataFrame(trigram_freq.most_common(10), columns=[\"Trigram\", \"Frequency\"])\n",
        "trigram_data[\"Trigram\"] = trigram_data[\"Trigram\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot Bigram Frequencies\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(data=bigram_data, x=\"Frequency\", y=\"Bigram\", palette=\"viridis\")\n",
        "plt.title(\"Top 10 Bigrams in Lecture Content\", fontsize=14)\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"Bigram\")\n",
        "plt.show()\n",
        "\n",
        "# Plot Trigram Frequencies\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(data=trigram_data, x=\"Frequency\", y=\"Trigram\", palette=\"magma\")\n",
        "plt.title(\"Top 10 Trigrams in Lecture Content\", fontsize=14)\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"Trigram\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "j-22L0PyhmWR",
        "outputId": "3ad89f64-9123-4170-95eb-8847817ffd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<ipython-input-49-199aa73d3bc8>:15: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=bigram_data, x=\"Frequency\", y=\"Bigram\", palette=\"viridis\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-199aa73d3bc8>:23: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=trigram_data, x=\"Frequency\", y=\"Trigram\", palette=\"magma\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**:The frequency analysis of bigrams and trigrams provides valuable insights into the key concepts and themes of the lecture. The most common phrases, such as \"language model\" and \"large language model,\" highlight the main focus on topics related to language modeling and AI."
      ],
      "metadata": {
        "id": "pRm_uSsVugH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUMMARIZATION\n",
        "The summarization efficiently condenses large volumes of the given transcription  into a digestible format, making it easier to understand."
      ],
      "metadata": {
        "id": "5lW4hdePkBr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Function to compute sentence embedding\n",
        "def get_sentence_embedding(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    return np.mean([token.vector for token in doc if token.has_vector], axis=0)\n",
        "\n",
        "# Function to calculate cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return 1 - cosine(vec1, vec2)\n",
        "\n",
        "def extract_key_sentences(text, num_sentences):\n",
        "    sentences = sent_tokenize(text)\n",
        "    similarity_matrix = nx.Graph()\n",
        "    similarity_matrix.add_nodes_from(range(len(sentences)))\n",
        "\n",
        "    # Compute the similarity between each pair of sentences using word embeddings\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(i + 1, len(sentences)):\n",
        "            embedding_i = get_sentence_embedding(sentences[i])\n",
        "            embedding_j = get_sentence_embedding(sentences[j])\n",
        "\n",
        "            # Compute cosine similarity and add to the graph\n",
        "            if embedding_i is not None and embedding_j is not None:\n",
        "                similarity = cosine_similarity(embedding_i, embedding_j)\n",
        "                similarity_matrix.add_edge(i, j, weight=similarity)\n",
        "    scores = nx.pagerank(similarity_matrix)\n",
        "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "    # Extract the top-ranked sentences\n",
        "    key_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n",
        "    return \" \".join(key_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p4qvUcUmtaC",
        "outputId": "c8a88b37-a392-4da7-a036-11160880d906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def generate_abstractive_summary(text, input_length):\n",
        "    max_length = min(240, input_length // 2)\n",
        "    min_length = max(80, input_length // 4)\n",
        "\n",
        "    # Tokenize and encode the text\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=1.3, num_beams=6, early_stopping=True)\n",
        "\n",
        "    # Decode the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "Fxe-fB9co4cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desired_length = int(input(\"Enter the number of sentences you want in the summary: \"))\n",
        "key_sentences = extract_key_sentences(cleaned_text, num_sentences=desired_length)\n",
        "print(\"\\nKey Sentences: \\n\", key_sentences)\n",
        "input_length = len(key_sentences.split())\n",
        "abstractive_summary = generate_abstractive_summary(key_sentences, input_length)\n",
        "\n",
        "print(\"\\nAbstractive Summary: \\n\", abstractive_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruXMjoZDpLMN",
        "outputId": "53425107-dff0-4c02-e763-d01228648205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of sentences you want in the summary: 7\n",
            "\n",
            "Key Sentences: \n",
            "  so lets get started so ill be talking about building llms today so i think a lot of you have heard of llms before but just as a quick recap llms standing for large language models are basically all the chat bots that youve been hearing about recently so chad gpt from openai cloud from untropic gemini and lama and other type of models like this and today well be talking about how do they actually work so its going to be an overview because its only one lecture and its hard to compress everything but hopefully ill touch a little bit about all the components that are needed to train some of these llms also if you have questions please interrupt me and ask if you have a question most likely other people in the room or on zoom have the same question so please ask great so what matters when training llms so there are a few key components that matter one is the architecture so as you probably all know lms are neural networks and when you think about neural networks you have to think about what architecture youre using and another component which is really important is the training loss and the training algorithm so how you actually train these models then its data so what do you train these models on the evaluation which is how do you know whether youre actually making progress towards the goal of llms and then the system component so that is like how do you actually make these models run on modern hardware which is really important because these models are really large so now more than ever systems are actually really an important topic for llms so those five components you probably all know that llms and if you dont know lms are all based on transformers or at least some version of transformers im actually not going to talk about the architecture today one because i gave us here a lecture on transformers a few weeks ago and two because you can find so much information online on transformers but i think its theres much less information about the other four topics i really want to talk about those another thing to say is that most of academia actually focuses on architecture and training algorithm and losses as academics and ive done that for a lot big part of my career is simply we like thinking that this is like we make new architectures new models and it seems like its very important but in reality honestly what matters in practice is mostly the three other topics so data of evaluation and systems which is one of most of industry actually focuses on so thats also one of the reasons why i dont want to talk too much about architecture because really the rest is super important great so overview of the lecture ill be talking about pretraining so pretraining you probably heard that word this is the general word this is kind of the classical language modeling paradigm where you basically train a language model to essentially model all of internet and then theres a post training which is a more recent paradigm which is taking these large language models and making them essentially ai assistants so this is more of a recent trend since chatgpt so if you ever heard of gpt3 or gpt2 thats really pretraining land if you heard of chatgpt which you probably have this is really post training land so we talk about both but ill start with pretraining and specifically ill talk about what is the task of pretraining lms and what is the laws that people will actually use so language modeling this is a quick recap language models at a high level are simply models of probability distribution over sequences of tokens or words so its basically some model of p of x1 to excel where x1 is basically word wanted excel is the last word in the sequence or in the sentence so very concretely if you have a sentence like the mouse eight of the cheese what the language model gives you is simply a probability of this sentence being uttered by a human or being found online so if you have another sentence like the mouse eight cheese here theres grammatical mistakes so the model should have some syntactic knowledge so it should know that this has less likelihood of appearing online if you have another sentence like the cheese eight the mouse then the model should hopefully know about the fact that usually cheese dont eat mouse so theres some semantic knowledge and this is less likely to be the first sentence so this is basically at a high level what language models are one word that youve probably have been hearing a lot in the news are generative models so this is just something that can generate models that can generate sentences or can generate some data the reason so what we know why we say language models are genitive models is that once you have a model of a distribution you can simply sample from this model and then we can generate data so you can generate sentences using a language model so the type of models that people are all currently using are what we call autoregressive language models and the key idea of autoregressive language models is that you take this distribution over words and you basically decompose it into the distribution of the first word multiply it by the distribution of the likelihood of the second word given the first word multiply it by p of the third word given the first two words so theres no approximation here this is just a chain rule of probability which you hopefully all know about really no approximation this is just one way of modeling a distribution so slightly more concisely you can write it as a product of ps of the next word given everything which happened in the past so of the context so this is what we call autoregressive language models again this is really not the only way of modeling distribution this is just one way it has some benefits and some downsides one downside of autoregressive language models is that when you actually sample from this autoregressive language model you basically have a full loop which generates the next word then conditions on that next word and then regenerate in other words so basically if you have a longer sentence that you want to generate it takes more time to generate it so there are some downsides of this current paradigm but thats what we currently have so im going to talk about this one great so autoregressive language models at a high level what the task of autoregressive language model is is simply predicting the next word as i just said so if you have a sentence like she likely prefers one potential next word it might be dogs and the way we do it is that we first tokenize so you take these words or sub words you tokenize them and then you give an id for each token so here i have one two three then you pass it through this black box as i already said were not going to talk about the architecture you just pass it through a model and you then get a distribution a probability distribution over the next word or over the next token and then you sample from this distribution you get a new token and then you detokenize so you get a new id you get detokenize and thats how you basically sample from a language model one thing which is important to note is that the last two steps are actually only needed during inference when you do training you just need to predict the most likely token and you can just compare to the real token which happened in practice and then you basically change the weights of your model to increase the probability of generating that token great so our progressive neural language models so to be slightly more specific still without talking about the architecture the first thing we do is that we have all of these yes so here predicting the probability of the next token so this may be that your final output vector has to be the same dimensionality as the number of tokens that you have yes how do you deal with like if you have more to increase adding more tokens to your tokens is it a private sample yeah so were going to talk about tokenization actually later so you will get some sense of this you basically can deal with adding new tokens im kind of exaggerating there are methods for doing it but essentially people dont do it so its really important to think about how you tokenize your text and thats why well talk about that later but its a very good point to notice that you basically the vocabulary size to the number of tokens that you have is essentially the output of your language model so its actually pretty large ok so autoregressive new language models first thing you do is that you take every word or every token you embed them so you get some vector representation for each of these tokens you pass them through some neural network we said its the transformer then you get a representation for all the words in the context so its basically representation of the entire sentence you pass it through a linear layer as you just said to basically map it to the number so that the output the number of outputs is the number of tokens you then pass it through some softmax and you basically get probability distribution over the next words given every word in the context and the last that you use is basically its essentially a task of classifying the next token so its a very simple kind of machine learning task so you use the crosscentral p loss where you basically look at the actual target that happened which is a target distribution which is a onehot encoding which here in this case says i saw the real one that happened is cat so onehot distribution over cat and here this is the actual do you see my mouse oh yeah this is the distribution that you generate generated and we see you do cross entropy which really just increases the probability of generating cat and decreases all the the probability of generating all the other tokens one thing to notice is that as you all know again this is just equivalent to maximizing the text log like the text log likelihood because you can just rewrite the max over the probability of this autogressive language modeling task as just being this minimum over i just added the log here and minus which is just the minimum of the loss which is the cross entropy loss so basically minimizing the loss is the same thing as maximizing the likelihood of your text any question questions okay tokenizer so this is one thing that people usually dont talk that much about tokenizers are extremely important so its really important that you kind of understand at least what they do at a high level so why do we need tokenizers in the first place first its more general than words so one simple thing that you might think is oh were just going to take every word that we will have you just say every word is a token in its own but then what happens is if theres a typo in your word then you might not have any token associated with this word with a typo and then you dont know how to actually pass this word with a typo into a large language model so what do you do next and also even if you think about words words is a very like words are fine with latinbased languages but if you think about a language like thai you wont have a simple way of tokenizing by spaces because there are no spaces between words so really tokens are much more general than words first thing the second thing that you might think is that you might tokenize every sentence character by character you might say a is one token b is another token that would actually work and probably very well the issue is that then your sequence becomes super long and as you probably remember from the lecture on transformers the complexity grows quadratically with the length of sequences so you really dont want to have a super long sequence so tokenizers basically try to deal with those two problems and give common sub sequences a certain token and usually how you should be thinking about is around an average of every token is around three four letters and there are many algorithms for tokenization ill just talk about one of them to give you a high level which is what we call bytepaying coding which is actually pretty common one of the two most common tokenizers and the way that you train a tokenizer is that first you start with a very large corpus of text and here im really not talking about training a large language model yet this is purely for the tokenization step so this is my large corpus of text with these five words and then you associate every character in this corpus of text different token so here i just split it up character with a different token and i just call it all of those tokens and then what you do is that you go through your text and every time you see pairs of tokens that are very common the most common pair of token you just merge them so here you see three times the tokens t and o next to each other so youre just gonna say this is a new token and then you continue you repeat that so now you have t okay talk which happens three times talk with an e that happens sorry two times and token which happens twice and an ex which also happened twice so this is that if you were to train a tokenizer on this corpus of text which is very small thats how you would finish with a token with a treat like a trained tokenizer in reality you do it on on much larger corpus of text and this is the real tokenizer of actually i think this is gpt3 or chgpd and here you see how it would actually separate these words so basically you see the same thing as what we gave in the previous example token becomes its own token so tokenizer is actually split up into two tokens token andizer so yeah thats all about tokenizers any question on that yeah yeah yeah so actually theres a step before tokenizers which is what we call pre tokenizers which is exactly what you just said so this is mostly in theory theres no reason to deal with spaces and punctuation separately you could just say every space gets its own token every punctuation gets its own token and you could just do all the merging the problem is that so theres an efficiency question actually training these tokenizers takes a long time so youre better because you have to consider every pair of token so what you end up doing is saying if theres a space this is very like pre tokenizers are very english specific you say if theres a space were not going to start looking at the token that came before and the token that came afterwards so youre not merging in between spaces but this is just like a computation optimization you could theoretically just deal with it the same way as you do with any other character yeah when you merge tokens to the top the tokens that you merged are very at the same height as the smaller token you actually keep the smaller tokens i mean in reality it doesnt matter much because usually on large corpus of text you will have actually everything but you usually keep the small ones and the reason why you want to do that is because if in case theres a as we said before you have some grammatical mistakes or some typos you still want to be able to represent these words by character so yeah yes yes are the tokens unique so i mean say in this case token is there only one occurrence so that you need to need multiple occurrence so they can have it take on different meetings you see oh i see what you would say no its every token has its own unique id so this is a great question for example if you think about bank which could be bank for money or bank like water it will have the same token but the model will learn the transformer will learn that based on the words that are around it it will should associate that im saying im being very hindrower of you here but associate that with a representation that is either more like the bank money side or the bank water side but thats the transformer that does that its not a tokenizer yes yes we mentioned during tokenization too theres smaller tokens its not that were trying to say like we just have it at the t we keep the t and then you dont need to tokenize out to the external icon out and tokenize it so lets say maybe you didnt even tokenize it like in your data you are trying to encode token so how does the tokenizer know to code it with token or to react yes the great question you basically when you tokenize so thats after training of the tokenizer when you actually apply to tokenizer you basically always choose the largest token that you can apply so if you can do token you will never do t you will always do token but theres actually so people dont really talk that much about tokenizers but theres a lot of computational benefits or computational tricks that you can do for making these things faster so i really dont think we and honestly i think a lot of people think that we should just get away from tokenizers and just kind of tokenize character by character or bytes by bytes but as i said right now its this issue of length but maybe one day like in five or 10 years well have different architectures that dont scale credetically with the length of the sequence and maybe well move away from tokenizers so are you sure with us the drawback why do you give people one and move away from the tokenizer oh yeah so think one good example is math if you think about math actually numbers right now are not tokenized so for example 327 might have its own token which means that models when they see numbers they dont see them the same way as we do and this is very annoying because the reason why we can kind of generalize with math is because we can deal with every letter separately and we can then do composition where you know that basically if you add stuff its just the same thing as adding every one separately plus whatever the unit that you add so they can do that so then you have to do like special tokenization and like one of the big changes that gpt forwarded is changed the way that they tokenize code so for example if you have code you know you have often in python these four spaces at the beginning those were dealt with kind of strangely before and as a result the model couldnt really understand how to deal with code so tokenization actually matters a lot okay so ill move on right now but we can come back later on tokenizers great so we talked about the task the last tokenizer lets talk a little bit about evaluation so the way that llms are usually evaluated is what we call is using what we call poplexity at a high level its basically just your validation loss the slight difference with poplexity is that we use something that is slightly more vulnerable which is that we use the average per token loss and then you exponentiate it and the reason why you exponentiate it is because you want i mean the loss has a log inside and you like one humans are actually pretty bad at thinking in log space but two logs depend on the base of the log while when you exponentiate you basically have everything in the kind of the vocabulary size unit and the average for token is just so that your poplexity is independent of the length of your sequence so poplexity is just too to the power average of the loss of the sequence so perplexity is between one and the length of the vocabulary of your tokenizer one its simply well if you predict perfectly the thing which every word then every word will have basically product of ones so the best perplexity you can have is one if you really have no idea you basically predict with one divided by size of vocabulary and then you do simple math and you basically get perplexity of size of vocabulary so then tuition of perplexity is that its basically the number of tokens that youre model is kind of hesitating between so if youre model is perfect it doesnt hesitate it no exactly the word if it really has no idea then it hesitates between all of the vocabulary so perplexity really improved thats perplexity on a standard data set between 2017 and 2023 it went from a kind of 70 tokens to less than 10 tokens over these five six years so that means that the models were previously as dated between 70 words every time it was generating a word and now its as dating between like less than 10 words so thats much better but complexity is actually not used anymore in academic benchmarking more sick is it depends on the tokenizer that you use it depends on the actual data that people are evaluating on but its still very important for development of llms so when you actually train your own llm people will still really look at the complexity one common other way and now more common in academia of evaluating these llms is just by taking all the classical nlp benchmarks and ill give you a few examples later and just kind of aggregating everything so collect as many automatically evaluable benchmarks and just evaluate across all of them so one such or actually two such benchmarks of what we call helm which is from stanford another one is the hugging face open llm lead award which are probably two most common ones right now so just to give you an idea in how they are all of these type of tasks which are mostly things that can be easily evaluated like question answering so think about many different question answering tasks the benefit with question answering is that you usually know what is the real answer so you can the way that you evaluate these models ill give you a concrete example in one second is that you can just look at how likely the language model is to generate the real answer compared to some other answers and thats essentially at a high level how you evaluate these models so to give you a specific example mmlu is probably the most common academic benchmark for lms and this is just a collection of many question and answers in all of those domains for example college medicine college physics astronomy and these type of topics and the questions are things like so this is an astronomy what is true for type 1a supernova then you give 4 different potential answers and you just ask the model which one is more likely so there are many different ways of doing it either you can look at the likelihood of generating all these answers or you can ask the model which one is the most likely so there are different ways that you can prompt the model but at a high level you know which one is correct and there are three other mistakes yes creating is like unconstrained text thats not funny yeah how do you do a downtothemodel it gives something thats you know semantically completely identical but is not the exact totalist that you expect yeah so thats a great question ill talk more about that later here in this case we dont do unconstrained so the way you would evaluate mmlu is basically either you look you as the first question and then you look at the likelihood of the model generating a the likelihood of the model generating b c and d and you look at which one is the most likely oh you can ask the model out of abcd which one is the most likely and you look at the model look at what the most like in extokin is a b c o d so you can stream the model to say it can only answer these four things can you say you can stream the model yeah you can stream it with the prompt or do you mean of its whole probability distribution there outfits youre only comparing the outfits up like youre only comparing the atunkin yeah so in the second case i gave you you would do exactly the i will actually you would do both in the first model saying a b c o d plus you would consume to only look at these four tokens in the first case you dont even need to generate anything so in the first case you literally just look given its a language model it can give a distribution over sentences you just look at what is the likelihood of generating all of these words what is the likelihood of generating the second choice and you just look at whether the most likely sentence is actually the real answer so if youre actually sample from it you really just use p of x1 to xl does that make sense sense that being said evaluation of openended questions is something were going to talk about later and its actually really important and really challenging yes earlier i mentioned that metrics like complexity are not usually used because it depends on how you do it some design choices i also want to speak more to that oh yeah so think about complexity i told you complexity is between one and vocabulary size so now i imagine that chatgpt uses a tokenizer that has like 10000 tokens but gemini from google uses a tokenizer that had 100000 potential tokens then actually the gemini one will have like the upper bound of the the complexity that you can get is actually worse for gemini than for chatgpt does that make sense so thats just an idea its actually a little bit more complicated now but theres just like one first or the bit of where you can see that the tokenizer actually matters great ok so evaluation challenges there are many ill just talk about two really briefly one as i told you there are two ways of doing evaluation for these mml views actually there are many more than two but i give you two examples and it happens that for a long time even though that was a very classical benchmark that everyone used actually different companies and different organization were actually using different ways of evaluating mml view and as a result you get completely different results for example lamas 65b which was the first model of meta in the lamas series had on helm 637 accuracy but on this other benchmark had like 488 so really the way that you evaluate and this is not even talking about prompting this is really just kind of the way that you evaluate the models promoting is another issue so really there are a lot of inconsistencies its not as easy as it looks first thing yeah sorry how do we make sure that all these models arent trained on the bench model okay second thing this is a great question train test contamination this is something which i would say is really important in academia in given that the talk is mostly about training large language models for companies its maybe not that important because they know what they trained on for us we have no idea so far its a real problem so there are many different ways of trying to test set sorry whether the test set was actually in the training set one kind of cut trick that people in the lab in tetsus lab have found is that what you can do is that given that most of the data set online are not randomized you can just look at and in that language models what they do is just predict the next word you can just look at the entire test set what if you generate all the examples in order versus all the examples in a different order and if its more likely to generate the thing in order given that theres no real order there then it means that probably was in the training set does that make sense so there are many thats like one of them there are many other ways of doing it train test contamination again not that important for development really important for academic benchmarking great so there are many other challenges but ill move on for now great data so data is another really big topic at a high level people just say oh you basically train large language models on all of internet what does that even mean so people sometimes say all of clean internet which is even less fun so internet is very dirty and really not representative of what we were one in practice if i download a random website right now you would be shocked at what is in there its definitely not your wikipedia so ill go really briefly on what people do i can answer some questions but data is on its own its a huge topic basically first what you do is download all of internet what that means is that you use web crawlers that will go on every web page on internet or every web page that is on google and that is around 250 billion pages right now and thats around one petabyte of data so this is actually a common crawl is one web crawler so people will usually write their own web crawlers what they do is that they use standard web crawlers and a common crawl is one of them that basically every month adds all the new websites that were added on internet are found by google and they put it in a big basically a big data set so thats on common quall you have around 250 billion pages right now so 1 e6 gigabytes of data once you have this so this is a random web page like literally random from this common quall what you see is im one and really doesnt look at the type of things that you would usually see but actually so this is an html page its hard to see but if you look through you will see some content for example here test king world is your ultimate source for the system xhigh performance server and then you have three dots so you dont even the sentence is not even finished thats how a random internet looks like so of course its not that useful if you just train a large language model to generate things like this so what are some of the steps that i needed first one you extract the text from the html so thats what i just tried to do by looking at basically the correct text there are a lot of challenges by this for example extracting math is actually very common complicated but pretty important for training large language models or for example boilerplates a lot of your forums will have the same type of headers the same type of footers you dont want to repeat all of this in your data then you will filter undesirable content so not safe for work harmful content pii so usually every company has basically as a blacklist of websites that they dont want to train their models on that blacklist is very long and you basically say if it comes from there we dont train on this there are other ways of doing these things is that you can train a small model for classifying what is pii removing these things its hard every point here that im going to show you is like a hard amount of work but im going to go quickly through it so filter undesirable content second or fourth is the duplication as i said you might have things like headers and footers in forums that are always the same want to remove that another thing that you might have is a lot of urls that are different but actually show the same website and you might also have a lot of paragraphs that come from common books that are basically dedoubligated a thousand times or 10000 times on internet so you need to have to dedoubligate also very challenging because you have to do that at scale once you do dedoubligation you will do some heuristic filtering you will try to remove lowquality documents the way you do that are things like rulesbased filtering for example if you see that there are some outlier tokens if the distribution of tokens in the website is very different than the usual distribution of tokens then its probably some outlier if you see that the length of the words in this website is super long theres something strange going on on that website if you see that the website has only three words maybe is it worth training on it maybe not if it has 10 million words maybe theres something also wrong going on that page so a lot of rules like this yes what are our undesirable content from our data set instead of kind of its like a supervised mass can we not just say like heres this hate speech website thats actively trying to but to actively penalize them up for data well do exactly that but not at this step thats where the post training will come from pretraining the idea is just to say i want to model kind of how humans speak essentially and i want to remove all these like headers photos and menus and things like this but its a very good like idea that you just had in it thats exactly what well do later next step model base field training so once youve filtered a lot of data what you will do and thats actually a very cute trick you will take all of wikipedia and you will look at all the links that are linked through wikipedia pages because probably if something is by wikipedia its probably some highquality website and you will train a classifier to predict whether something comes from whether a document comes from one of these references from wikipedia or whether its from the random web and you will try to basically say i want more of the things that come from wikipedia references does that make sense so yeah so you will train a machine learning model usually also very simple models because you need to do that really at scale i mean just think about the 250 billion pages next one you will try to classify your data into different domains you will say ok this is entertainment this is books this is code this is like these type of domains and then you will try to either up or downweight some of the domains for example you might say you might see that actually if you train more on code then actually your model becomes better on reasoning so thats something that people people usually say in a very handwaver way if you train your model on code actually it helps reasoning so you want to upweight the coding distribution because that helps for general language modeling skills books is usually also another one that people usually upweight entertainment they usually downweight so things like this of course you want to do it so people used to do it maybe kind of heuristically now theres entire pipelines that well talk about of how to do these things slightly more automatically and then at the end of training usually training on all of this data that we saw usually train on very highquality data at the end of training your large language model where you decrease your learning rate and that basically means that youre kind of overfitting your model on a very highquality data so usually what you do there is like wikipedia you basically overfit on wikipedia and you overfit on like human data that was collected the other thing is like continue pretraining forgetting longer context im going to skip over all of these things but i just to give you a sense of how hard it is when people just say oh im going to train on internet thats a lot of work really we havent figured it out yet so collecting well data is a huge part of practical large language model some might say its actually the key yes no more data so theres a question so usually you would install the term where i write on data after i go to your masters suppose its a typical amount of you that you have been in and then how large it seems that its a big deal to go through all the data steps you took out so is a question how large is the data after you filter yes so you feel that its good to go through how large it seems you need to go through the field the order of future systems how slow is it how many people would you need oh what are you going to do this video ok thats a great question im going to somewhat answer about the data how large is the dataset at the end of this slide for number of people that work on it thats a great question im actually not quite sure but i would say yeah i actually dont quite know but i would say its probably even bigger than number of people that work on kind of the tuning of the pretraining of the model so the data is bigger than kind of the modeling aspect yeah i dont think i have a good sense i would say probably in lamas team which have like 70 hp people i would say maybe 15 work on data yeah all these things you dont need that many people you need a lot of computer also because for data you need a lot of cpus so yeah and ill answer the second question at the end of this slide so as i just kind of alluded to really we have installed data at all for pretraining so theres a lot of research that has to be done first how do you process these things super efficiently second how do you balance all of these different domains can you do synthetic data generation thats actually a big one right now because we dont have well talk about that later we dont have enough data on the internet can you use multimodal data instead of just text data and how does that improve even your text performance theres a lot of secrecy because really this is the key of most of the pretrained large language models so for competitive dynamics usually these companies dont talk about how they do the data collection and also theres a copyright liability issue they definitely dont want to tell you that theyve trained on books even though they did because if not you can sue them common academic benchmarks so that will kind of answer what you asked so those are the smaller ones the names are not that important but it you decide from a head around 150 billion tokens which are around 800 gigabytes of data and now its around 15 trillion tokens which is also the size of the models that are right now the best models are probably trained on that amount of data so 15 trillion tokens which is probably i guess two more to my bigger than that so 80 e3 gigabyte so that would be around 100 to 1000 times the filtering of the common crawl if im not mistaken so yeah one very famous one is the pile so this is an academic benchmark of the pile and we can just look at what distribution of the data they have it sings like archive pubmed central which is all the biology stuff here its wikipedia you see stack exchange some github and some books and things like this again this is on the smaller side so this is if we look at here this is on 280b so in reality its like 100 times bigger so you cannot have that much of github and on wikipedia in terms of closed source models just to give you an idea lamat 2 it was trained on two trillion tokens lamat 3 15 trillion tokens which is currently the best model that we know on how much it was trained on which is the same thing as the best academic or the biggest academic benchmark which is 15 trillion tokens in the gpd 4 we dont really know but its probably in the same order of magnitude or its probably around that actually its probably around 13 from leaks if the leaks are true great so scaling loss any other questions on data before you go to scaling loss sorry i know im giving you a lot of information but theres a lot into training and large language models great scaling loss so the idea is that what people saw around 2020 or at least from a long time but theyve been able to kind of theoretically show it or impurity show it since 2020 is that the more data you train your models on and the larger the models the better the performance this is actually pretty different than what youve seen in this class in this class we teach you about overfitting overfitting doesnt happen with large language models larger models better performance its something that really took a long time for the community who took this type of class to realize but for the exam overfitting exists so okay the idea of scaling loss is that if given that you know that more data and larger models will always give you better performance can we predict how much better your performance will be if you increase the amount of data and the size of your model and surprisingly it works so here you see three plus from a very famous paper called scaling loss from openai here you see on the xaxis compute so how much did you train like how much compute that you spent for training and here you see test loss so this is essentially i mean some perplexity but its your validation loss so its a log of the perplexity and if you put these two on log scale then you see that the performance like the sorry the scaling law is linear that means that if you increase your compute by a certain amount you can say by how much your test loss will actually decrease same thing with data and same thing for parameters if you increase the data set size your loss will decrease by an amount that is somewhat predictable if you increase the number of parameters it will decrease the loss will decrease by a amount which is somewhat predictable this is really amazing very surprising i mean it looks innocuous when you look at these type of plots but thats crazy because it means that you can predict how well were going to perform in two three years depending on how much compute we will add assuming that these things will hold theres nothing theoretical about it yes what is the loss of the user here as a proplexity so i said proplexity was like 2 to the power of the loss so this is the power of the proplexity and the second thing is when you dont increase the number of parameters so you increase the total data set size and the number of the application time doesnt that just increase your compute so all of this work is not just how many you do data oh yes no this is a great question so the compute here is actually a factor of two things the data and the parameter what im showing here is that you can well actually were going to talk about that in details but basically if you increase the number of parameters you should increase the number of data that you have so you actually dont go multiple times through the same data set no one does epochs at least not yet because we havent still kind of enough data so yeah this is all the same trend which is increased compute decreased loss yes have we seen the numbers for the last two years or is it still holding it is still holding i dont have like good numbers to show you but it is still holding surprisingly yes is there a draw evidence like a procoevent that youve never thought of but you cant draw it with expected value right no empirical evidence of plateauing any time soon why we dont know well it happened probably i mean it doesnt need to because its actually in log scale so its not like as if it had to go it had to plateau like mathematically it could continue decreasing like this i mean most people think that it will probably plateau at some point we dont know when okay so thats i will talk more about scaling loss now so why are scaling loss really cool imagine that i give you youre very fortunate i give you 10000 gpus for this month what model will you train how do you even go about answering that question i mean this is a hypothetical but thats exactly what these companies are faced with the old pipeline which was basically two high parameters on the big models so lets say i have 30 days i will train 30 models for one day each i will pick the best one and that will be the final model that i will use in production that means that the model that i actually used was only trained for one day the new pipeline is that you first find a scaling recipe so you find something that tells you for example one common thing is that if you increase the size of your model you should decrease your learning rate so you find a scaling recipe such that you know if i increase the size of my model heres what i should do with some high parameters then you tune your high parameters on smaller models of different sizes lets say i will say for three days of my 30 days i will train many different models and i will do highpreparameter tuning on these small models each of different sizes then i will fit a scaling law and try to extrapolate from these smaller models which one will be the best if i if i train it for much longer oh sorry if i train it for a larger model and then i will train the final huge model for 27 days instead of just one day so the new pipeline is not train things or do highpreparameter tuning on the real scale of the model that youre going to use in practice but do things on smaller ones at different scales try to predict how well they will perform once you make them bigger i will give that i will give you a very concrete example right now lets say transformers versus lstms and lets say youre you have yous 10000 gpus youre not sure which one you should be using should i be using transformable base model and an scm base model what i will do is i will train transformers at different scales so here you see different parameters on the xaxis yaxis is my test source i will then show you different lstms at different scales once i have these points i will see oh it kind of fits a scaling law i will fit my scaling law and then i will be able to predict oh if i had 10 times more compute heres how well i would perform for the lstm its actually slightly less linear for the lstm but like you could probably try to predict where you would end up and clearly from this plot you would see that transformers are better one thing to notice when you read these types of scaling laws is that there are two things that are important one is really your scaling rate which is kind of the slope of the scaling law the other thing is your intercept like you could start worse but actually become better over time it just happens that lstms are worse for both but i could show you another one where things you can predict that actually like after certain scale youre better off using that type of model than others so thats why scaling laws are actually really useful any questions on that yeah so these are all kind of very how sensitive art is to like small difference in architecture like one light transfer of architecture versus another transfer of architecture you basically have to like pick your own curve and basically say like oh scaling does tell you that should be some like logarithmic function yeah yeah so usually for example if youre an academic and you want to now at least thats like pretty recent and you want to propose a new like activation thats exactly what you will do you will fit a scaling law show another scaling law with the standard like i dont know gailu and you will say that its better in reality once you start thinking about it in scaling laws terms you really realize that actually all the architecture differences that we can make like the small minor ones all they do is maybe we changed a little bit the intercept but really that doesnt matter just train it for 10 hours longer or wait for the next gpus and these things are really secondary exactly why i was telling you originally people spend too much time on the architecture and losses in reality these things dont matter as much data though if you use good data you will have much better scaling loss than if you use bad data that really matters another really cool thing you can do with scaling loss is that you can ask yourself how to optimally allocate training resources should i train larger models because we thought its better when you train larger models but we thought its also better when you use more data which one should i do should i just train on more data a smaller model or should i train a larger model on less data so chintilla is a very famous paper that first showed this the way they did it i want to give you a little bit of a sense of what these plots are here you see training loss again on the xaxis you see parameter differences as sorry number of parameters so the size of the model and here all these curves are what we call isoflops which is that all the models on this curve have been trained with the same amount of compute the way that you do that is that you change so you vary the number of tokens that were trained on and the size of the models but you vary in such a way that a total compute is constant so all these curves that you see with different colors have different amount of compute that were trained on then you take the best one for each of those curves once you have the best one for each of those curves you can plot how much flops it was and on which curve were you on and how much parameters did you actually use for training that specific point you put that on the log log scale again and now you fit a scaling log again so now i have something which tells me if if i want to train a model of 10 to the power 23 flops heres exactly the number of parameters that i should be using 100 b and you can do the same thing with flops and tokens so now you can predict if i tell you exactly i have one month of compute what size of model should i be training figure scaling law and i tell you of course that all looks beautiful in reality theres a lot of small things of should you be counting embedding parameters theres a lot of complexities but if you do things well these things actually do hold so the optimal number of parameters that shinchilla people have found is to use 20 tokens for every parameter that you train so if you add one more parameter you should train your thing on your model on 20 more tokens so one caveat here is that this is optimal training resources so that is telling me if you have 10 to the power 23 flops or if you have like 100 i dont know how much that is 100 million 5 million or 10 no that would smudge less actually id say i have 5 million to train my best model that gets the lowest loss what would i train on in reality these companies need to think about inference also if you have a smaller model they will spend less over time so actually if you consider the inference cost you have other papers that try to show that its around 150 parameters sorry tokens per parameters because you prefer having a smaller model because over time youre going to actually spend less money on inference of these models so 150 to one thats around what the best models are trained on right now at least the ones that are used in practice in production great any question on chichol great im sorry how expensive is it or its really small and its really good to train actually very expensive i will not talk about it first because that would be another entire lecture but just think about chat gpt when they have i dont know how much it is now like 600 million people that use it like thats a lot so its actually very expensive theres a lot of optimization you can do for inference though and thats an entire other lecture so im going to skip that this time but its very interesting ok two things as i said there are many things that you can answer with scaling loss i just try to give you two examples but really there are many things what data do you use what mixer what data mixing waiting you use the data mixers thats what we talked about before what architecture you use whether you should make your models wider or deeper should you be paying for more gpus or actually collecting more data all these things are things you can try to answer with scaling loss one thing i want to say is the bitter lesson if you ever heard of richard sutton a very famous blog post in 2019 what he realized which i think not enough people realized i didnt definitely did not realize at that time is that once you see these type of scaling loss you know that the more compute you have the better models you will get so with scale you will get better model and you also know by mozilla or these type of variants of mozilla that you will always have better compute then the only thing that matters is just to have architectures that can leverage computation so what matters is basically systems data and less so the architecture like the small architecture differences like your activation and things like this so i think thats one of the reasons why most of research focuses on some things that for industry matters less and i was one of those researchers for a large part of me my career so dont spend time overcomplicating do you do the simple things do it well seal them thats really what openai taught us with chatgpt and with all the gps before ok i want to give you some backoftheenvelope computations so i might be off by a few factors here but i just want to give you a sense of how costly it is to train some of these models ill give as an example a lamat 300b which is currently the best open source model that you can get it was trained on 156 tokens it has 405 billion parameters so just now that you know what is like this optimal tokens parameter thats around 40 so thats a little bit more than chinchilla but less than this inference optimal model so they went for training optimality flops for this model so one simple way to compute flops is six times the number of parameters times the number of data that you train on so if you do the simple calculation here its 38e25 flops the reason why this is important is that if you follow the little bit of the news theres an executive order from biden that basically says i want you have 1e26 parameters sorry flops then you have special scrutiny on your models so they went 2x less than that so they really went right below this to not have special scrutiny so 3 8 i might be off by a little bit but its definitely under the 1e26 so p is parameters n is data number of tokens this is just an approximation yeah okay compute we know that they train it on 16000 h100s and we know the throughput they set it to so if you do the computation it takes around 70 days or 26 million gpu hours at least thats with my backoftheenvelope computation they actually said that they used 30 million instead of 26 million gpu hours so maybe they had like some challenges i dont really know but if you follow the simple computation its around 70 days cost i mean this is hard to approximate but im just going to say its kind of the rent like what if i were to rent h100s that many h100s for that many days how much will i pay h100 a lower bound on the renting cost of h100 is around two hours a 2 per hour so if you multiply this by 26 million hours you get 52 million so they probably pay less than that but not actually much less because all these services that actually rent gpus they dont make that much money so its probably slightly less but not that much less now salary i said 50 employees 500k per year yeah its probably the right bullpock 25 million so if you put all together around 75 million dollars for training this slammer model im probably out by like 10 million but thats kind of right bullpock carbon emitted a lot of people might ask like also the cost is not the only thing that is important so i did the computation its around 4000 tons of co2 equivalent that is actually only 2000 return tickets from jfk to london so right now carbon emitted is actually not i mean its huge but its not like meaningful yet i think in maybe gpt 6 gpt once you multiply this by 100 that might become a real issue right now its still not i think an issue in the grand scheme of things next model the way you should be thinking about these models is that every new generation the number of flops essentially multiplies 10x well at least thats what they try if they have enough energy and if they can buy enough gpus great any question on these backup dna envelope math okay so now we talked about pretraining i wanted to also chat about systems because now we know compute is really important so theres a question of how do you optimize your compute i will leave that for the end because im not sure how much time we will have i think its important but hopefully ill be able to talk about it later its slightly different than what weve been talking about right now so ill move on to posttraining for now so the task of posttraining the reason why we need to to do posttraining is as i told you before its to make ai assistance so language modeling is not really the thing that you want when you have an ai assistant for example if you ask to gpt3 which is a purely language model a pure language model not an aligned one if you ask a question i explain the moon landing to a sixyearold the conclusion that you would get is something like explain the theory of gravity to a sixyearold because what it learned is that on internet if you have one question you usually have maybe another bullet point of other similar questions you dont usually have question in an answer later this is not what you want from an ai assistant so how do we do this alignment which is this posttraining and making these models assistance so the goal of this alignment is to basically get lms follow the instructions that are given by users sign and maybe some designers kind of desires so think about moderation you dont want the model like openair definitely doesnt want the model to say stuff that is very toxic so here you see on the left hand side that when you ask a question it actually provides a real answer so its not like before the llm and on the right hand side you see that it would if you ask to write a tweet describing how as certain part of the population or evil it will say that it cannot do that so thats kind of this alignment the background here is that basically the data that you want for training some of these models is like we know what we want which is just asking humans this is a question this is the answer that you want but the thing is that its very expensive to collect that data and its hard to find it online in contrast pretraining data is not what you want but theres a lot of it so what we will do or the main idea is simply take a pretrained large language model pretrained all of internet and then you just fine tune so you just change a little bit of weights on the type of data that you actually want and hopefully given it youre already pretrained on all of internet it basically learns or knows how to speak in english and knows standard language syntax then you can really fine tune it with very little data ok sft so supervised fine tuning is really exactly what i just said which is the idea of fine tuning the large language model on basically the desired answers that are collected from humans so why is it called supervised fine tuning because you basically want to do language modeling on the real answers so language modeling is this like next word prediction and thats the fine tuning part and then you want to do it on desired answers given by humans so thats why we call it supervised so how do we collect this data well i just said it you can just ask humans to tell you this is the question this is the answer that you would want from something of these models so this is an example i cant read very well on my computer but my kid needs to do a science no lets read this one can you write a short introduction about the relevance of the term monopsony and then it says monopsony refers to a market structure blah blah blah and thats a human number with that so actually this is open assistant which was a way to collect data online by humans so this type of supervised fine tuning while im in is really the key of chat gpt this is what made the big jump from gpt3 which was mostly something that was known by ai researchers to chat gpt which became known by basically everyone so the problem with human data is that its very slow to collect and very expensive so one percent possible simple idea is to use lms to scale data collection so thats exactly what we did with alpaca one year ago what we did is we asked humans or we use a data set of human question answers so there were 175 question answers here and we asked the best more at the time so texas vincis user three to basically generate many more of these question and answers so all we did is like this is what humans would write now write similar answers and similar questions and we collected 52000 llm generated question answers and then what we did is simply we took lamas 7b which was the best pretrained model at the time and we just fine tuned this with supervised fine tuning as i told you and thats how we got the alpaca 7b model and this is the type of data that we collected so things like what does algorithm mean and algorithm is a step by step set of instruction you used to solve a problem or achieve a goal blah blah blah so the data is not actually its actually pretty good given it was lm gen generated by llms from essentially two generations ago so that really started at least for us kind of as an academic replication of chatgpt now it really is a big field of synthetic data generation of how to use llms to basically make development of llms faster and basically by decreasing the amount of human hours that you need quantity of data so we talked about what type of data and how we collected one thing which is surprising with sft is that you dont need that much data so what this paper showed this is called lima is that if you have if you scale the amount of data that you use from supervised fine training from 2000 to 32000 it really doesnt help much so here scaling loss definitely dont help so the intuition here is that all you learn is you learn how to format your desired answers another way of seeing it is that your pretrained models they essentially model the distribution of every user on internet one that might write bullet points another one that might answer question with an answer so all you tell your model is like wait you should actually be optimizing more for this type of user than another one so youre not actually teaching anything through this sft so supervised fine tuning all you do is you tell the model to kind of optimize for one type of user that its already in a pretrained dataset so the knowledge is already in a pretrained llm and you basically just specialize to one type of user great any question on sft yes so i know its a big issue with synthetic data where if you keep generating data from the same distribution eventually youre not learning a new distribution youre essentially playing with it it just puts track of that surely you cant scale that for a way you can keep going on in generating from the same data and hope to learn something new so its an active area of research and youve thought that you have around how people are maybe thinking around this and better ways to bootstrap or to give up on this idea and realize that the chart shows you dont need that many so just get humans to generate 2000 radiability yeah so thats a very good question so for the data stuff so im saying its not that important for sett but there will be another thing well talk about right after where actually data does matter my intuition based on not that much empirical results is that you can still get even though you use your lms if you use purely lm generated text and you do that for like three four generations of lms i agree with you that probably you wont improve much but for me what is important is how do you use human in the loop with lms not purely lms not purely humans but maybe what you can do is just have the model generate some new text and just humans write a few edits and its not much f faster than writing the entire text and i think that if you have that type of collaboration then from an information theoretical point of view you still get additional information but youre so much faster than if you use humans and i think that as a field well probably move towards these type of things which is really just finding the examples that are important and asking humans its kind of active learning just asking humans exactly when you need to get their inputs yes so youre just trying to make the same loss function the same general training after the supervised learning that we do for the pretraining right because the examples you showed i think the important thing for good examples is that theyre super actionoriented theres these more complex things still just like changing same loss so thats why here i didnt maybe didnt emphasize enough this is just language modeling finetune the language model on the desired answers so this is literally the same loss it will be different in two seconds but the first step of sft is literally the same loss where you just say okay i want to actually specialize on that type of data so theres even a question of like what is pretraining what is posttraining because in reality its just like a different data that you use the reason why we can usually call it posttraining is that the way we collect that data is very different great great questions yes maybe its the same question but why would these 2000 examples have such a overweighted influence of the internet so thats why we also thats another reason why we call it posttraining is that we use different type of hyper parameters so you know i told you basically at the end of pretraining you essentially end up with a learning rate of zero and here youre going to increase your learning rate to like 1 e minus 5 1 e minus yeah and so the way that you give to them is actually different ok second step or second part of this posttraining is what we call reinforcement learning from human feedback or all hf some of you might have heard of that the idea is that sft has a problem namely that you do behavioral cloning which means that you just try to clone what the humans would say and that has many issues one of them is that youre bound by human abilities so if humans actually humans wont generate the things that they think is actually the best thing to generate so if you ask me to write a book i mean i can definitely enjoy a book i can probably say one book is better than another but im definitely not going to be as good as writing the book that i want to read so youre going to be bound by the human ability to generate things even though the humans might be better at distinguishing between things thats one issue issue number two i find that actually pretty interesting is that if you ever heard of the word house cination so this is llms generating false information house cination might or these people have hypothesized that that can come from the supervised fine tuning even if you do supervised fine tuning on data that is correct and the reason why that is is that if given i told you that basically sft is with very little data and its with data that doesnt the model doesnt learn anything new so what if the human gives an answer that the model didnt know was true from the model perspective the human basically is telling the model generate this thing that seems plausible but actually i have no idea if its true or not so just to give you a very concrete example if we go back to this monopsony example can you write blah blah blah about monopsony imagine that there were human rotor reference on this type of book and that book might exist that might be a correct reference but what if the llm never saw this reference during pretraining then it doesnt know that its a correct reference to really what you tell the model is to generate a make up some plausibly sounding reference rather than actually tell the real reference that its arguing pretraining so hallucination might be like might be caused by this sft thats problem number two does that all make sense great problem number three price generating the ideal answers is very pricing and that comes back to your question of like humans writing an entire answer is actually pretty expensive so thats where all hf comes in the idea is that instead of cloning the behaviors of humans were going to maximize human preference and the way were going to do that so the pipeline is that for a certain for every instruction youre going to ask a model to generate two answers and usually you use a pretty good model so you usually dont use an llm here you use a sft fine tune you use a fine tune llm already to give like pretty good answers and then you ask labelers which of these two answers was better so select the preferred one and then with different type of algorithms were going to talk about the algorithms you just fine tune the model to generate more of the green thing than the red thing so more of the good stuff so now the question is how and were going to talk about that right now so there are two ways that were going to talk about and two that are mainly using the community the first one is simply the idea of using reinforcement learning so hopefully you all know what reinforcement learning is now so when you think about using reinforcement learning one important question is like what is the reward that we are optimizing so in this case there are really two options that i can think about the first one you could just say im going to compare the output generated by some baseline the output generated by my model and im just going to ask the human to say which one is better and im going to use this as a reward so if im better than the baseline this is a plus one if not thats a minus one so now its binary reward the problem of binary reward is that its very sparse you dont get much information out of it like maybe you answered was slightly better maybe it was way better and you dont really know from this how much better it was so option two is that you can train what we call a reward model which is simply a classifier so you use machine learning to classify how much better two outputs are from the perspective of the human so theres a little bit of better but what you basically do is that you train you take a real model r which is just a large also a large classifier and you basically ask this reward model you give it the input and the actual output that you have one of the two outputs and you just exponentially thats the softmax class that you all know about and now you divide by the the exponentialed reward on the first example sorry on the first output and its on the second output and you basically train so the reason why you do that is that you train your model you train this reward model to be able to classify how much better one output is to another one so another slightly lessconverted way of seeing it is that your reward model will output some reward that will be used as the logits of your softmax so now if you have high logits in your softmax it means that highly likely this output is better so thats what we call bradley terry model yes is this your reward model going to be the entire output or is it going to be like that so this takes the entire output at one so it takes all the input and all the output and it gives one number yes so im going to be talking about the value of an a human being so with the reward model where would that human be oh why so and sorry maybe i wasnt clear you train this reward model to fit this green and red preference from humans so basically you train a classifier to say whether the humans prefer red or green but instead of using the binary reward which is what the human will tell you you basically use the large bits of the softmax and the thing with the large bits is that large bits are continuous so now you know that if your reward model said it has high logents then in some ways the human highly preferred this answer to some other answer great so as i just said continuous information says better so thats what people use in practice or at least use to use in practice ill tell you about the other algorithm later so what you do at the end is that you basically try to just use reinforcement learning that you know about now we know we have our reward what you sample through is the generation from your large language model then you just use some regularization terms the reason why we do this regularization term is for avoiding what we call overoptimization this reward model might not be really represent like might not perfectly model human preferences so you dont want to maximize this thing to essentially infinity you do it using ppo which is a common reinforcement learning algorithm one thing to note here because it will be important for later is that when we use maximum likelihood im sorry now the large language models are actually a policy for your reinforcement learning its not maximizing maximum likelihood anymore which means that youre not modeling any distribution anymore and the reason why this is important is that models that went through this type of ppo actually dont give you likelihoods of text that are meaningful because what you optimize them to do is basically just optimize for generating the most likely thing not optimized for modeling like all the answers that humans might say another way of saying that is that theres nothing that incentivizes here the model to not give like a single possible generation nothing here says its good if you have some distribution with some entropy okay if you havent followed its not that important but just good to know great so ppo is exactly what chad gpt did originally so heres the on their blog posts or what they have is step one do supervised fine training which now you all know about step two train a reward model on human preferences step three do ppo multiple steps which is where you see this blue arrow so you train the model once with the ppo you collect new data you continue and thats exactly what chad gpt did and that was a big breakthrough between gp3 and chad gpt one thing to note is that ppo has many challenges reinforce learning something as super nice theoretically in practice anyone who ever worked with reinforcement learning knows its such a mess theres a lot of things like roll outs outofloop slipping so many complications so its messy this is the idealized ppouse4lm setting so thats already much more complicated than this expectation we saw before and in practice its actually much more complicated so we have one implementation of it that we had to do and im not going to go through it but basically you have like so much stuff that you have to think about when you implement that type of ppo algorithm so you have clipping everywhere you have a lot of complexities and things are not well documented all this to say that there was a new method that was proposed also from sanford one year ago called dpo which is essentially a simplification of ppo and the way what they did or the idea that they have is that instead of using reinforcement learning you can just maximize the probability of generating the stuff that you like and minimum the probability of the stuff that you dont like so if you think about the human preference the red and green maximize green minimize red so the loss is actually this one what you see this is simply some log of the model so this is the likelihood of the model generating the things that the human preferred given the inputs and what you try to do is basically maximize the likelihood of generating the things that you like minimize the likelihood of the things that you dont like all the rest of the terms here its not too important its actually really not that complicated to understand but at the high level its really just maximizing the things you like minimizing the rest and one thing to note which i was going to say just here is that actually all the rest is chosen such that the global minima of ppo and the global minima of this dpo under some assumptions essentially equivalent so this is the right thing to do mathematically im not going to go through the derivations but thats the right thing to do its pretty different with ppo in the sense that now with ppo what you had to do is collect their human preferences then train your reward model with maximum likelihood then use reinforcement learning now all you do is basically maximum likelihood much simpler yes i mean yeah its a simple thing this is a much simpler thing like what you just do to do with your business why did they start with this reward model what about them doing that i think its a great question i dont really know what i can tell you is that i dont put in the people who did basically this sorry who did chagy pt initially other ones who actually wrote ppo and i think there were just like there are a lot of reinforcement learning people and i think that for them it was very intuitive so theres also some additional potential benefits for example they dont yeah for example if you use the reward model the cool thing here we have reinforced learning is that you can use unlabeled data with the reward model so here you can only use the label data for doing dpo for ppo you first train your reward model and then you can use unlabeled data where the reward model will basically label this unlabeled data so theres additional kind of potential there could be potential improvements in practice it happens that they are known and i think just that a lot of people in this team were reinforcement learning experts including the main author of ppo which im told me so much simpler in ppo and it basically performs as well so now this is the standard thing that people use at least in the open source community i believe its actually the standard also in industry thats called dpo gains so those are older papers on the left here this is on a summarization task you see all i want to show you is that basically the pretrained models were okay and they approve of scale if you do supervised fine tuning you improve them a little bit more if you do ppo or something with all hf with human feedback you get performance that are as oftentimes depending on a benchmark even better than humans so this is the human reference summaries same thing is done on a paper that we have alpaca farm where we see the evaluation here is not too important but basically you see pretrained model you jump to sft and then you jump to ppo dpo and ppo have the exact same performance so basically all hf helps thats kind of the conclusion and dpo is simple data the way that you collect that type of data first idea is just use humans as we already talked about guidelines are very complicated for what humans should be labeling and its really not that easy see if you ever do some of the labeling you will see that its extremely complicated like if i zoom into this here i have a question tell me about selfdriving cars and you read both selfdriving cars of vehicles that are capable of detecting the surroundings blah blah blah blah selfdriving cars are cars that are equipped with sensors blah blah blah to navigate without the need for a driver and we both seem ok like which one is better its actually hard to say at the glance and as a result the problem with humans is that you will start optimizing a lot of highlevel features for example the second one is longer i can guarantee you that most humans will choose the second one even though i may do first one is better i dont know i havent read it carefully so challenges of humans first slow and expensive second as i just mentioned its hard to focus on things that matter like correctness and people usually look at things that dont matter as much like to form like length and as a result so what i show here is that when you do rhf the more you do have rhf the longer the output of the models become so if youve ever been annoyed at chat gpt answering you super long sentences this is because of all hf annotated distribution shift like the distribution of annotators that use matters a lot and you have to think like what is what is even the humans that we want to represent in these models another question is like crowdsourcing ethics like usually these basically a lot of the labeling that is done like the people who do them are not paid well and they have to go through a lot of toxic data because youre basically one the model to avoid saying the toxic data so crowdsourcing ethics too so many challenges with human data so what we did also last year is again the same thing as alpaca just the idea of like oh well now challenges with humans maybe we can just replace them with lms so what we did is simply replace oh i see that im just realizing that the slides are not centered anyways you replace human preference with lm preferences so here on this figure you see on the xaxis the price that we paid for collecting human data its around 300 for 1000 examples and this is on mechanical turquoise which are usually like cheaper than maybe some of the other companies that you could go through and on the yaxis its basically the agreement with other humans with the mode of other humans and what you see is that actually as i told you before labeling is really complicated humans agree with themselves only around 66 of the time im a binary task and its not that the humans are not good here because we were five main authors on this paper we tried to label this data ourselves and we only had like say 67 or 68 accuracy even though we talked for like three hours of how we should be doing labeling but really its complicated its not an easy task and here i just showed many different models and basically you see that models are much cheaper and they can actually get higher agreement of the mode of humans than humans themselves the reason why is because humans have a lot of variants models have no variants they might be a little bit more biased but have less variants it works surprisingly well now its kind of the standard and open source community i think even in an industry a lot of people use both humans and llms for improving the collection of all hf data this is the paper from last year but honestly now its more like that llms would be around this agreement and this cost so around i would say 50x cheaper than humans and better agreement with humans than humans themselves okay so that gets us to evaluation of posttraining and that goes back to your initial question at the beginning of the lecture how do you evaluate something like chargeup the answers that chargeup could give are basically unbounded and its not that theres one right answer there are many answers that are just as good so the main topic one you cant use validation loss because one method might use ppo the other one might use dpo validation loss is not comparable second you cant use sorry perplexity thats the thing i told you before these models are not calibrated they dont give distributions they just optimize for one thing so you cant use perplexity for actually evaluating these type of models once theyre aligned sorry once theyre aligned third theres a lot of diversity of questions that human might ask to these models generation open qa like some question answering some summarization and all of these things so theres so many things you have to cover then the tests are really openended so its very hard to automate so thats what you were alluding to before so the idea is that instead of trying to come up with really easily automated benchmarks its just were going to ask questions that users actually asked to these models in practice and were just going to ask annotators to say between these two models which one is better like whats the whats the better output so basically you do the exact same thing as basically the data from all hf but you use it now for evaluation yes im not sure i understand that i mean cant use procllexity not calibrated really hello im still doing like an exit token prediction so ipi procllexity please so think about the optimal solution after doing ppo is basically one model that gives you essentially a delta like basically says that theres only one sentence that is that could be generated for that question so now if you use it on something that is slightly semantically differently different it would actually give a likelihood of zero for that answer so in reality its not that extreme because as you say its still a distribution but it just shows you that theres a fundamental issue with procllexity once these models are not llms anymore they were not trained at least with ppo they were not trained to do maximum likelihood anymore they were trained to be ppo policies okay so probably the most common or the most yeah the most common benchmark or the most trusted one is what we call chatbot arena which is basically go on internet have random users on the internet blindly talk with two chatbots just ask many questions see the two answers and rate which one is better and you do that over 100000 of users and then you get the actual preferences and you get rankings of models so you can go right now on chatbot arena and actually interact with these models one potential issue just to highlight is that while people who want to do these type of things are usually more like tech driven or like tech savvy so a lot of the questions that you will ask are more like tech stuff discussing software errors inquiries about ai tools and all these things so another issue is cost and speed if you really want to use something like this for development process it will be too costly you will need to basically pay a lot of humans to do that so one simple idea is again as we said many times just use lm instead of humans you probably know the drill at this point steps for every instruction generate outputs by some baseline and a model that you want to evaluate so he imagined that i am comparing an answer from chad gpt and from mistro im just asking another model which one is better and i just basically averaged that out yeah i asked you gpt for which one is better i averaged that out of my entire distribution over my entire benchmark or data set and that gives me a win rate so win probability for one model compared to another one and now you can rank models and this is the alpequeeval leaderboard so the benefits of this is that actually we show we get 98 correlation with chad baragwina so very high correlation with humans so this is comparison with correlation with other benchmarks and it takes less than three minutes and less than 10 to run so its pretty cheap there are downsides though one of them is purist correlation so as we already saw before lms prefer this is one spurious correlation not many ill just talk about one lms prefer longer outputs actually humans also prefer longer outputs but the problem or the issue once you use lms is that once there is bias you will continue optimizing that humans at some point i can guarantee you if i ask a simple question and you give me five pages of answers ill be like no i dont like that answer but lms if they have this bias and they were trained for that they will continue preferring longer outputs so here we see the preference just showing that humans and models prefer longer outputs and here is another view of the initial apache val data set benchmark when when we asked when we rank gpt4 when we look at the run rate of gpt4 versus actually gpt4 itself if we if we use the standard gpd4 it gets 50 by definition if were comparing gpd4 versus gpd4 but if we ask a gpd4 to be slightly more verbose so we just say in the prompt be verbose in your answers then it gets a reinway of 644 so really theres a huge variance and if you ask it to be concise it gets 20 so theres a huge variance depending on whether you ask it to be concise of verbose thats very annoying so one possible solution which is what we did is just use some regression analysis im not going to go into details but basically use causal inference tools to control for length and right now actually length matters much less so if you ask it to be verbose you still get some gains but much less great so thats all about posttraining and now for the next eight minutes might talk about systems or just answer questions yes ok go back to your posttraining in terms of posttraining how did we tune those parameters using a small body of finetuning data and have such big effect on the model you mentioned earlier that theres a different set of hypergrammers are we changing just some of the weights the later weights or all the weights whats actually happening yeah i kind of skimmed through all of this you change all the weights actually industry would change all the weights in open source land you might have heard of laura which is going to change it basically only some of the weights or it actually to be more specific its going to add some differences to the output of every layer but in industry youre going to just finetune all the weights also to say something else about the data actually this last step rlhf youre usually going to collect a lot more data than with sft so if sff 50 is like 5000 10000 maybe 50000 with rlhf i think youre going to be more unlike the 1 million or the magnitude its still much less than pretraining though 15 trillion tokens i mean this is like thats not even a drop and then you influence the weight of the wall so you do it i mean you have to think that how you do it is you use i mean as i said the learning way that youre going to use is going to be different but also you only do that so just imagine if i trained even if i trained on one sentence but over and over again at some point in my model will only generate that sentence even if it was just one sentence instead of the 15 trillion tokens so if you use a large enough learning rate and for enough time you will basically overfit that sentence so the key thing to remember is that the data is not id its not as if you mix some posttraining data and some pretraining data you do pretraining and then you just start finetuning only on a posttraining so another way maybe another perspective is that the pretraining is just an initialization of your model and once you view it that way that this is just initialization of weights then theres nothing special you dont need to remember that you trained a lot of data before the only thing that matters is that you had initialization and now i actually trained a model so maybe think about it that way like theres a mark of property in some ways its just like you had your weights this is my initialization now im training that one does that kind of answer your question kind of but you said something just now about its almost a equivalent of just rerunning the fine tuning data many times is it actually is that what actually happens in order to give so much more preference you might have i actually dont know right now how they do it in industry when we did our packet we had to do three blocks so you did run it three times to it but i mean even the number of times that you run it through its actually not important the only thing is the effective learning rate that what matters so yeah great so i think five minutes right okay i might try to give a high level overview at least from one of the systems trick systems as we said for everyone bottleneck is a sorry compute is the huge bottleneck one question you might ask is why not buy more gpus gpus are expensive but also as case even if you have 10 million right now you cannot buy the best gpus theres also some physical limitations when you have multiple gpus you have to communicate between them that takes time so just buying more gpus is not that easy so its really important to think about how do you allocate resources and how do you optimize your pipeline so system 101 on gpus im sorry im going slightly faster i hope that some of you at least can follow gpus are basically optimized for throughput cpus are optimized for latency so gpus the way you have to think about it is that theres one command that is run on many many cores at the same time on different type of data so this is how you see gpu you see there are many different cores we call them streaming multiprocesses which is very different than the usual cpu architecture so just think high throughput powerization for gpus gpus are optimized for fast matrix multiplication so every time you will do something on gpu if you can do it with a matrix multiplication its going to be 10 times faster than with anything else that is a little bit annoying because it means that we are kind of bottlenecked to doing anything with matrix multiplications another thing to note with gpus is that compute has been improving faster than memory and communication so right now gpus usually are hard to keep like the data that you send at cpus is actually hard to keep up with the process so most of your gpus are actually going to be idle if you just run normal code if you dont optimize your code so communication and this will continue over time another thing to know about gpus is that theres a memory hierarchy this is the same thing i actually with cpus but basically the closer you are to your cores the less memory there is but the faster things run if you are further more memory slower ok im going to skip that ok actually im going to say it i told you about this defective communication the metric that people usually look at is model flop utilization so what is the theoretical maximum that gpu could run at no more flops that it could use per second divide the number of observes through per divided by this theoretical maximum and in general if you reach 50 youre very happy like facebook i looked at lama was at 45 for something like this so that means that data doesnt come fast enough even for these big companies so one simple thing trick and that might be the only one im going to tell you about is low precision one simple idea is that well if im going to put my floats in low precision then theres going to be fewer bits that i have to send to my gpus if theres fewer bits its faster communication lower memory consumption things are going to go faster and for deep planning it just happens that decimal is not that important so when you do matrix multiplication when you do like for example sgd it is already so much noise that if you update something by 001 or 0015 who cares so basically instead of using 32 bits per float which is what people use to use or 64 for example which is what we would use in other domains you use 16 bits for matrix multiplication so for every float you use 16 bits and for training you have this type of like what we call automatic mix precision which is that some of the things are in 32 bits others are in 16 bits generally the way you should be thinking about it is that your weights are stored of your model are stored in 32 bits but just before the computation you put everything in 16 16 bits like this you do computation super fast and at the end you update your weights in 32 bits and the reason why you do all the updates in 32 bits its just think that if youre learning weight for example is very small you still want to be able to like make a difference in your weights so all the computation is done in 16 bits but the weights are actually stored in 32 bits so thats like the standard way that people are doing it okay ill actually talk just about this and then ill skip all the rest operate a fusion because i think its actually pretty cool as i just said communication is very slow and actually every time you use a pie torch line it basically moves variable to global memory of your gpu so when you have something like this x dot cosine equal x1 and then you do x1 dot cosine what is happening behind the scenes is that you take the x which is data you ship it to your actual processes of your gpus you apply the cosine you ship it back to the main memory of your gpu and then you see the next line you ship it back to the gpu processor you apply another cosine and you ship it back again another way to see that is that you go from your dram which is your global memory in your gpu and you ship it to compute you ship it back for every line this is a naive way of doing it this seems very wasteful so the idea simple idea of operating a fusion is just communicate do all the computation ship it backwards and this is exactly what a few kernels are so if you ever want to make your computations in pytorch much faster just apply torchcomcom on your model this is going to make your model around two times faster and what it does is simply that it rewrites your code your pytorch code basically nc in cuda to do the communication only once then do all the operations then ship it back okay im not going to have time to talk about tiling tiling is important powerization powerization is important and mixture of experts mixture of experts is important outlook there are many things we havent talked about we havent talked about architectures we definitely havent talked about inference there are many other things that are important with llms what is the ui that you use i mean arguably chatgpt the big novelty was just have a simple ui to use it multimodality what are all the misuses you could have the fact that they might not be enough data on the internet to train all these models the quality of data collection so many other things if you are interested in all these topics i would suggest three classes cs224n is probably the one that touches the least on llms they give some background in historical context of all the llms that give kind of some some at jason matillo cs324 i think its called i think its called large language models more indepth reading and lectures on everything i talked about cs336 which is large language model from scratch you actually build your own llm its an amazing class also given by my two supervisors very heavy workloads so be careful great\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1282: UserWarning: Unfeasible length constraints: `min_length` (4544) is larger than the maximum possible length (240). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Abstractive Summary: \n",
            " Llms standing for large language models are basically all the chat bots that youve been hearing about recently so chad gpt from openai cloud from untropic gemini and lama and other type of models like this and today well be talking about how do they actually work. There are a few key components that matter one is the architecture so as you probably all know lms are neural networks. Another component which is really important is the training loss and the training algorithm so how you actually train these models then its data so what do you trainThese models on the evaluation which is how do you know whether youre actually making progress towards the goal of llms and then the system component so that is likeHow do you actually make these models run on modern hardware which isreally important because these models are really large so now more than ever systems are actually really an important topic for llms so those five components are what matters when training llms. We talk about pretraining so pretraining is kind of the classical language modeling paradigm where you basically train a language model to essentially model all of internet. We also talk about post training which is a more recent paradigm which is taking these\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abstractive_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "fDDZBiI-_azL",
        "outputId": "c1ab13db-e774-4762-b0fa-bee8fe6f4494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Llms standing for large language models are basically all the chat bots that youve been hearing about recently so chad gpt from openai cloud from untropic gemini and lama and other type of models like this and today well be talking about how do they actually work. There are a few key components that matter one is the architecture so as you probably all know lms are neural networks. Another component which is really important is the training loss and the training algorithm so how you actually train these models then its data so what do you trainThese models on the evaluation which is how do you know whether youre actually making progress towards the goal of llms and then the system component so that is likeHow do you actually make these models run on modern hardware which isreally important because these models are really large so now more than ever systems are actually really an important topic for llms so those five components are what matters when training llms. We talk about pretraining so pretraining is kind of the classical language modeling paradigm where you basically train a language model to essentially model all of internet. We also talk about post training which is a more recent paradigm which is taking these'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used a hybrid method for summarization to get the best of both worlds: pulling out key sentences directly from the text (extractive) while also rephrasing and making it sound more natural (abstractive). This way, the summary is short, clear, and still captures the main points in an easy-to-read way."
      ],
      "metadata": {
        "id": "TdoHQcOTNFU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing Keyword Identification on Summarized Data"
      ],
      "metadata": {
        "id": "gjlEC0OvOCdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=10)\n",
        "X = vectorizer.fit_transform([abstractive_summary])\n",
        "keywords = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Top Keywords:\", keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pL4WN0Vyw__",
        "outputId": "6fd0c2b4-1220-4442-ef68-9b4369683f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Keywords: ['actually' 'important' 'language' 'large' 'llms' 'models' 'paradigm'\n",
            " 'pretraining' 'really' 'training']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(abstractive_summary)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Ee_WylPSy6lP",
        "outputId": "629d7871-bb18-461c-f16c-b63ce0c254c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  \n",
        "\n",
        "*   I chose **KeyBERT** over **TF-IDF** because TF-IDF focuses only on word frequency, often highlighting irrelevant or generic terms.\n",
        "*   KeyBERT, powered by BERT, understands the semantic context of words, giving more accurate and meaningful keywords that truly represent the core themes, such as \"LLMs,\" \"models,\" and \"neural networks.\"\n",
        "This ensures a better and more relevant keyword extraction.\n",
        "\n"
      ],
      "metadata": {
        "id": "owfAOVuSJn8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kw_model = KeyBERT()\n",
        "keywords = kw_model.extract_keywords(abstractive_summary, top_n=10)\n",
        "\n",
        "print(\"Top Keywords:\", [word for word, score in keywords])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIIScXIBziil",
        "outputId": "65460418-65ce-4f07-92fc-05b4a593f5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Keywords: ['llms', 'lms', 'models', 'modeling', 'pretraining', 'language', 'architecture', 'model', 'chat', 'networks']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_dict = {word: score for word, score in keywords}\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    colormap='viridis',\n",
        "    prefer_horizontal=1.0\n",
        ").generate_from_frequencies(keyword_dict)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Important key words from summary')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "dDkqWqeh0C9W",
        "outputId": "93eb5c2e-1c99-4894-f592-9c3d98e227e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These keywords effectively capture the essential concepts ensuring a precise understanding of the main topics discussed."
      ],
      "metadata": {
        "id": "n9_MMZBeOR3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "qsXSU2RKEAhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOaSOuSvPVjf",
        "outputId": "78874243-cde3-4bc2-e582-fdb3a2d5dbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Rouge) (1.16.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: Rouge\n",
            "Successfully installed Rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(abstractive_summary, transcription)[0]\n",
        "rouge_scores = {\n",
        "    \"ROUGE-1\": {'r': scores['rouge-1']['r'], 'p': scores['rouge-1']['p'], 'f': scores['rouge-1']['f']},\n",
        "    \"ROUGE-2\": {'r': scores['rouge-2']['r'], 'p': scores['rouge-2']['p'], 'f': scores['rouge-2']['f']},\n",
        "    \"ROUGE-L\": {'r': scores['rouge-l']['r'], 'p': scores['rouge-l']['p'], 'f': scores['rouge-l']['f']}\n",
        "}\n"
      ],
      "metadata": {
        "id": "M6DGag_3PKz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = list(rouge_scores.keys())\n",
        "recall_scores = [rouge_scores[m]['r'] for m in metrics]\n",
        "precision_scores = [rouge_scores[m]['p'] for m in metrics]\n",
        "f1_scores = [rouge_scores[m]['f'] for m in metrics]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bar_width = 0.25\n",
        "index = range(len(metrics))\n",
        "\n",
        "ax.bar(index, recall_scores, bar_width, label='Recall', alpha=0.7)\n",
        "ax.bar([i + bar_width for i in index], precision_scores, bar_width, label='Precision', alpha=0.7)\n",
        "ax.bar([i + 2 * bar_width for i in index], f1_scores, bar_width, label='F1 Score', alpha=0.7)\n",
        "\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('ROUGE Evaluation Scores')\n",
        "ax.set_xticks([i + bar_width for i in index])\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "O0EYWO9kB6Ay",
        "outputId": "78e3525a-d7e6-42b3-b351-9c611ccc465d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of Results\n",
        "The bar chart shows high Precision scores across all metrics, meaning the summary includes **highly relevant content**. However, Recall scores are lower, indicating that more content from the original text could be included for better coverage. The moderate F1 scores suggest the need for further fine-tuning to improve recall while keeping precision high."
      ],
      "metadata": {
        "id": "hhQkGY56Clff"
      }
    }
  ]
}